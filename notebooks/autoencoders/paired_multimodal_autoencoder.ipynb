{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Dict, List, Tuple, Iterable, Union, Optional, Set, Sequence, Callable, DefaultDict, Any\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D, Concatenate, Add\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "\n",
    "\n",
    "# ml4h Imports\n",
    "from ml4h.TensorMap import TensorMap\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.models import make_multimodal_multitask_model, train_model_from_generators, make_hidden_layer_model, _conv_layer_from_kind_and_dimension\n",
    "from ml4h.tensor_generators import TensorGenerator, big_batch_from_minibatch_generator, test_train_valid_tensor_generators\n",
    "from ml4h.recipes import plot_predictions, infer_hidden_layer_multimodal_multitask\n",
    "\n",
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Tensor = tf.Tensor\n",
    "\n",
    "ACTIVATION_CLASSES = {\n",
    "    'leaky': LeakyReLU(),\n",
    "    'prelu': PReLU(),\n",
    "    'elu': ELU(),\n",
    "    'thresh_relu': ThresholdedReLU,\n",
    "}\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'swish': tf.nn.swish,\n",
    "    'gelu': tfa.activations.gelu,\n",
    "    'lisht': tfa.activations.lisht,\n",
    "    'mish': tfa.activations.mish,\n",
    "}\n",
    "NORMALIZATION_CLASSES = {\n",
    "    'batch_norm': BatchNormalization,\n",
    "    'layer_norm': LayerNormalization,\n",
    "    'instance_norm': tfa.layers.InstanceNormalization,\n",
    "    'poincare_norm': tfa.layers.PoincareNormalize,\n",
    "}\n",
    "CONV_REGULARIZATION_CLASSES = {\n",
    "    # class name -> (dimension -> class)\n",
    "    'spatial_dropout': {2: SpatialDropout1D, 3: SpatialDropout2D, 4: SpatialDropout3D},\n",
    "    'dropout': defaultdict(lambda _: Dropout),\n",
    "}\n",
    "DENSE_REGULARIZATION_CLASSES = {\n",
    "    'dropout': Dropout,  # TODO: add l1, l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _activation_layer(activation: str) -> Activation:\n",
    "    return (\n",
    "        ACTIVATION_CLASSES.get(activation, None)\n",
    "        or Activation(ACTIVATION_FUNCTIONS.get(activation, None) or activation)\n",
    "    )\n",
    "\n",
    "\n",
    "def _normalization_layer(norm: str) -> Layer:\n",
    "    if not norm:\n",
    "        return lambda x: x\n",
    "    return NORMALIZATION_CLASSES[norm]()\n",
    "\n",
    "\n",
    "def _regularization_layer(dimension: int, regularization_type: str, rate: float):\n",
    "    if not regularization_type:\n",
    "        return lambda x: x\n",
    "    if regularization_type in DENSE_REGULARIZATION_CLASSES:\n",
    "        return DENSE_REGULARIZATION_CLASSES[regularization_type](rate)\n",
    "    return CONV_REGULARIZATION_CLASSES[regularization_type][dimension](rate)\n",
    "\n",
    "\n",
    "def _calc_start_shape(\n",
    "        num_upsamples: int, output_shape: Tuple[int, ...], upsample_rates: Sequence[int], channels: int,\n",
    ") -> Tuple[int, ...]:\n",
    "    \"\"\"\n",
    "    Given the number of blocks in the decoder and the upsample rates, return required input shape to get to output shape\n",
    "    \"\"\"\n",
    "    upsample_rates = list(upsample_rates) + [1] * len(output_shape)\n",
    "    return tuple((shape // rate**num_upsamples for shape, rate in zip(output_shape[:-1], upsample_rates))) + (channels,)\n",
    "\n",
    "\n",
    "class FlatToStructure:\n",
    "    \"\"\"Takes a flat input, applies a dense layer, then restructures to output_shape\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_shape: Tuple[int, ...],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "    ):\n",
    "        self.input_shapes = output_shape\n",
    "        self.dense = Dense(units=int(np.prod(output_shape)))\n",
    "        self.activation = _activation_layer(activation)\n",
    "        self.reshape = Reshape(output_shape)\n",
    "        self.norm = _normalization_layer(normalization)\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return self.reshape(self.norm(self.activation(self.dense(x))))\n",
    "\n",
    "\n",
    "def _conv_layer_from_kind_and_dimension(\n",
    "        dimension: int, conv_layer_type: str, conv_x: List[int], conv_y: List[int], conv_z: List[int],\n",
    ") -> Tuple[Layer, List[Tuple[int, ...]]]:\n",
    "    if dimension == 4 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv3D\n",
    "        kernel = zip(conv_x, conv_y, conv_z)\n",
    "    elif dimension == 3 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'depth':\n",
    "        conv_layer = DepthwiseConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown convolution type: {conv_layer_type} for dimension: {dimension}')\n",
    "    return conv_layer, list(kernel)\n",
    "\n",
    "\n",
    "def _upsampler(dimension, pool_x, pool_y, pool_z):\n",
    "    if dimension == 4:\n",
    "        return UpSampling3D(size=(pool_x, pool_y, pool_z))\n",
    "    elif dimension == 3:\n",
    "        return UpSampling2D(size=(pool_x, pool_y))\n",
    "    elif dimension == 2:\n",
    "        return UpSampling1D(size=pool_x)\n",
    "    \n",
    "\n",
    "    \n",
    "def _one_by_n_kernel(dimension):\n",
    "    return tuple([1] * (dimension - 1))\n",
    "\n",
    "\n",
    "class DenseConvolutionalBlock:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            dimension: int,\n",
    "            block_size: int,\n",
    "            conv_layer_type: str,\n",
    "            filters: int,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "    ):\n",
    "        conv_layer, kernels = _conv_layer_from_kind_and_dimension(dimension, conv_layer_type, conv_x, conv_y, conv_z)\n",
    "        if isinstance(conv_layer, DepthwiseConv2D):\n",
    "            self.conv_layers = [conv_layer(kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        else:\n",
    "            self.conv_layers = [conv_layer(filters=filters, kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        self.activations = [_activation_layer(activation) for _ in range(block_size)]\n",
    "        self.normalizations = [_normalization_layer(normalization) for _ in range(block_size)]\n",
    "        self.regularizations = [_regularization_layer(dimension, regularization, regularization_rate) for _ in range(block_size)]\n",
    "        print(f'Dense Block Convolutional Layers (num_filters, kernel_size): {list(zip([filters]*len(kernels), kernels))}')\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        dense_connections = [x]\n",
    "        for i, (convolve, activate, normalize, regularize) in enumerate(\n",
    "            zip(\n",
    "                    self.conv_layers, self.activations, self.normalizations, self.regularizations,\n",
    "            ),\n",
    "        ):\n",
    "            x = normalize(regularize(activate(convolve(x))))\n",
    "            if i < len(self.conv_layers) - 1:  # output of block does not get concatenated to\n",
    "                dense_connections.append(x)\n",
    "                x = Concatenate()(dense_connections[:])  # [:] is necessary because of tf weirdness\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ConvDecoder2:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            tensor_map_out: TensorMap,\n",
    "            filters_per_dense_block: List[int],\n",
    "            conv_layer_type: str,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            block_size: int,\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "            upsample_x: int,\n",
    "            upsample_y: int,\n",
    "            upsample_z: int,\n",
    "    ):\n",
    "        dimension = tensor_map_out.axes()\n",
    "        self.dense_blocks = [\n",
    "            DenseConvolutionalBlock(\n",
    "                dimension=tensor_map_out.axes(), conv_layer_type=conv_layer_type, filters=filters, conv_x=[x]*block_size,\n",
    "                conv_y=[y]*block_size, conv_z=[z]*block_size, block_size=block_size, activation=activation, normalization=normalization,\n",
    "                regularization=regularization, regularization_rate=regularization_rate,\n",
    "            )\n",
    "            for filters, x, y, z in zip(filters_per_dense_block, conv_x, conv_y, conv_z)\n",
    "        ]\n",
    "        conv_layer, _ = _conv_layer_from_kind_and_dimension(dimension, 'conv', conv_x, conv_y, conv_z)\n",
    "        self.conv_label = conv_layer(tensor_map_out.shape[-1], _one_by_n_kernel(dimension), activation=tensor_map_out.activation, name=tensor_map_out.output_name())\n",
    "        self.upsamples = [_upsampler(dimension, upsample_x, upsample_y, upsample_z) for _ in range(len(filters_per_dense_block) + 1)]\n",
    "        print(f'Decode has: {list(enumerate(zip(self.dense_blocks, self.upsamples)))}')\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        for i, (dense_block, upsample) in enumerate(zip(self.dense_blocks, self.upsamples)):\n",
    "            \n",
    "            x = upsample(x)\n",
    "            x = dense_block(x)\n",
    "        return self.conv_label(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import acos\n",
    "\n",
    "def l2_norm(x, axis=None):\n",
    "    \"\"\"\n",
    "    takes an input tensor and returns the l2 norm along specified axis\n",
    "    \"\"\"\n",
    "\n",
    "    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)\n",
    "    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))\n",
    "\n",
    "    return norm\n",
    "\n",
    "def pairwise_cosine_difference(t1, t2):\n",
    "    \"\"\"\n",
    "    A [batch x n x d] tensor of n rows with d dimensions\n",
    "    B [batch x m x d] tensor of n rows with d dimensions\n",
    "\n",
    "    returns:\n",
    "    D [batch x n x m] tensor of cosine similarity scores between each point i<n, j<m\n",
    "    \"\"\"\n",
    "    t1_norm = t1 / l2_norm(t1, axis=-1)\n",
    "    t2_norm = t2 / l2_norm(t2, axis=-1)\n",
    "    dot = K.clip(K.batch_dot(t1, t2), -1, 1)\n",
    "    return acos(dot)\n",
    "\n",
    "class CosineLossLayer(Layer):\n",
    "    \"\"\"Layer that creates an Cosine loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(CosineLossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    def call(self, inputs):\n",
    "        # We use `add_loss` to create a regularization loss\n",
    "        # that depends on the inputs.\n",
    "        self.add_loss(self.weight * pairwise_cosine_difference(inputs[0], inputs[1]))\n",
    "        return inputs\n",
    "\n",
    "class L2LossLayer(Layer):\n",
    "    \"\"\"Layer that creates an L2 loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(L2LossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.add_loss(self.weight * tf.reduce_sum(tf.square(inputs[0] - inputs[1])))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_paired_autoencoder_model(\n",
    "    pairs: List[Tuple[TensorMap, TensorMap]],\n",
    "    pair_loss = 'cosine',\n",
    "    **kwargs\n",
    ") -> Model:\n",
    "    inputs = {tm: Input(shape=tm.shape, name=tm.input_name()) for tm in args.tensor_maps_in}\n",
    "    original_outputs = {tm:1 for tm in args.tensor_maps_out}\n",
    "    real_serial_layers = kwargs['model_layers']\n",
    "    args.model_layers = None\n",
    "    multimodal_activations = []\n",
    "    encoders = {}\n",
    "    decoders = {}\n",
    "    outputs = []\n",
    "    losses = []\n",
    "    for left, right in pairs:\n",
    "        args.tensor_maps_in = [left]\n",
    "        left_model = make_multimodal_multitask_model(**args.__dict__)\n",
    "        encode_left = make_hidden_layer_model(left_model, [left], args.hidden_layer)\n",
    "        h_left = encode_left(inputs[left])\n",
    "        \n",
    "        args.tensor_maps_in = [right]\n",
    "        right_model = make_multimodal_multitask_model(**args.__dict__)     \n",
    "        encode_right = make_hidden_layer_model(right_model, [right], args.hidden_layer)\n",
    "        h_right = encode_right(inputs[right])        \n",
    "        \n",
    "        if pair_loss == 'cosine':\n",
    "            loss_layer = CosineLossLayer(1.0)\n",
    "        elif pair_loss == 'euclid':\n",
    "            loss_layer = L2LossLayer(1.0)\n",
    "        \n",
    "        paired_embeddings = loss_layer([h_left, h_right])\n",
    "        multimodal_activations.extend(paired_embeddings)\n",
    "        if left not in encoders:\n",
    "            encoders[left] = encode_left\n",
    "        if right not in encoders:\n",
    "            encoders[right] = encode_right            \n",
    "        \n",
    "    multimodal_activation = Concatenate()(multimodal_activations)\n",
    "    encoder = Model(inputs=list(inputs.values()), outputs=[multimodal_activation], name='encoder')\n",
    "    \n",
    "    # build decoder models\n",
    "    latent_inputs = Input(shape=(args.dense_layers[0]*len(inputs)), name='input_concept_space')\n",
    "    pre_decoder_shapes: Dict[TensorMap, Optional[Tuple[int, ...]]] = {}\n",
    "    for tm in args.tensor_maps_out:\n",
    "        shape = _calc_start_shape(num_upsamples=len(args.dense_blocks), output_shape=tm.shape, \n",
    "                                  upsample_rates=[args.pool_x, args.pool_y, args.pool_z], \n",
    "                                  channels=args.dense_blocks[-1])    \n",
    "        \n",
    "        restructure = FlatToStructure(output_shape=shape, activation=args.activation, \n",
    "                                      normalization=args.dense_normalize)\n",
    "        \n",
    "        decode = ConvDecoder2(\n",
    "            tensor_map_out=tm,\n",
    "            filters_per_dense_block=args.dense_blocks[::-1],\n",
    "            conv_layer_type=args.conv_type,\n",
    "            conv_x=args.conv_x,\n",
    "            conv_y=args.conv_y,\n",
    "            conv_z=args.conv_z,\n",
    "            block_size=args.block_size,\n",
    "            activation=args.activation,\n",
    "            normalization=args.conv_normalize,\n",
    "            regularization=args.conv_regularize,\n",
    "            regularization_rate=args.conv_regularize_rate,\n",
    "            upsample_x=args.pool_x,\n",
    "            upsample_y=args.pool_y,\n",
    "            upsample_z=args.pool_z,\n",
    "        )\n",
    "        \n",
    "        reconstruction = decode(restructure(latent_inputs))\n",
    "        decoder = Model(latent_inputs, reconstruction, name=tm.output_name())\n",
    "        decoders[tm] = decoder\n",
    "        outputs.append(decoder(multimodal_activation))\n",
    "        losses.append(tm.loss)\n",
    "\n",
    "    args.tensor_maps_out =  list(original_outputs.keys())\n",
    "    args.tensor_maps_in = list(inputs.keys())\n",
    "    \n",
    "    m = Model(inputs=list(inputs.values()), outputs=outputs)\n",
    "    my_metrics = {tm.output_name(): tm.metrics for tm in args.tensor_maps_out}\n",
    "    opt = Adam(lr=kwargs['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    m.compile(optimizer=opt, loss=losses, metrics=my_metrics)\n",
    "    m.summary()\n",
    "    \n",
    "    if real_serial_layers is not None:\n",
    "        m.load_weights(kwargs['model_layers'], by_name=True)\n",
    "        print(f\"Loaded model weights from:{kwargs['model_layers']}\")\n",
    "        \n",
    "    return m, encoders, decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22 14:17:49,229 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/log_2020-09-22_14-17_0.log.\n",
      "2020-09-22 14:17:49,378 - arguments:444 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors /mnt/disks/sax-lax-40k-lvm/2020-01-29/ --input_tensors lax_2ch_diastole_slice0_3d lax_3ch_diastole_slice0_3d --output_tensors lax_2ch_diastole_slice0_3d lax_3ch_diastole_slice0_3d --activation swish --conv_layers 32 --conv_x 3 3 3 --conv_y 3 3 3 --conv_z 3 3 3 --dense_blocks 32 32 32 --block_size 3 --dense_layers 64 --pool_x 2 --pool_y 2 --batch_size 1 --patience 32 --epochs 292 --learning_rate 0.0001 --training_steps 256 --validation_steps 30 --test_steps 2 --num_workers 4 --inspect_model --tensormap_prefix ml4h.tensormap.ukb.mri --id lax_2ch_3ch_diastole_pair_cosine_loss\n",
      "\n",
      "2020-09-22 14:17:49,380 - arguments:445 - INFO - Arguments are Namespace(activation='swish', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=1, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_regularize_rate=0.0, conv_type='conv', conv_x=[3, 3, 3], conv_y=[3, 3, 3], conv_z=[3, 3, 3], debug=False, dense_blocks=[32, 32, 32], dense_layers=[64], dense_normalize=None, dense_regularize=None, dense_regularize_rate=0.0, dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', eager=False, embed_visualization=None, epochs=292, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='lax_2ch_3ch_diastole_pair_cosine_loss', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d'], inspect_model=True, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix='ukb_ecg_rest', learning_rate=0.0001, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./recipes_output/', output_tensors=['lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d'], padding='same', patience=32, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=[], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, save_last_model=False, t=48, tensor_maps_in=[TensorMap(lax_2ch_diastole_slice0_3d, (200, 160, 1), continuous), TensorMap(lax_3ch_diastole_slice0_3d, (200, 160, 1), continuous)], tensor_maps_out=[TensorMap(lax_3ch_diastole_slice0_3d, (200, 160, 1), continuous), TensorMap(lax_2ch_diastole_slice0_3d, (200, 160, 1), continuous)], tensor_maps_protected=[], tensormap_prefix='ml4h.tensormap.ukb.mri', tensors='/mnt/disks/sax-lax-40k-lvm/2020-01-29/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=2, text_file=None, text_one_hot=False, text_window=32, time_frequency='3M', time_tensor='partners_ecg_datetime', train_csv=None, training_steps=256, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=30, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "\n",
      "2020-09-22 14:17:49,397 - models:896 - WARNING - Number of x dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:49,398 - models:896 - WARNING - Number of y dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:49,399 - models:896 - WARNING - Number of z dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:49,412 - models:383 - INFO - Residual Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3))]\n",
      "2020-09-22 14:17:49,417 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,422 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,427 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,641 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,646 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,650 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,659 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,663 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:49,668 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lax_2ch_diastole_slice0_3 [(None, 200, 160, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 200, 160, 32) 320         input_lax_2ch_diastole_slice0_3d_\n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 200, 160, 32) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 100, 80, 32)  0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 80, 32)  9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 80, 32)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100, 80, 64)  0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 80, 32)  18464       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100, 80, 32)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 80, 96)  0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 80, 32)  27680       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 80, 32)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 40, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 50, 40, 32)   9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 50, 40, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 50, 40, 64)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 50, 40, 32)   18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 50, 40, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 50, 40, 96)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 50, 40, 32)   27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 50, 40, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 20, 32)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 20, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 20, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 25, 20, 64)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 20, 32)   18464       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 20, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 25, 20, 96)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 20, 32)   27680       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 20, 32)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16000)        0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1024064     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16000)        1040000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16000)        1040000     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16000)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 25, 20, 32)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 25, 20, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 20, 32)   9248        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 20, 32)   9248        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 20, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 20, 32)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 25, 20, 64)   0           reshape[0][0]                    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 25, 20, 64)   0           reshape_1[0][0]                  \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 20, 32)   18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 20, 32)   18464       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 20, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 20, 32)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 25, 20, 96)   0           reshape[0][0]                    \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 25, 20, 96)   0           reshape_1[0][0]                  \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 20, 32)   27680       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 20, 32)   27680       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 20, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 20, 32)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 50, 40, 32)   0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 50, 40, 32)   0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 50, 40, 32)   9248        up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 50, 40, 32)   9248        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 50, 40, 32)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 50, 40, 32)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 50, 40, 64)   0           up_sampling2d[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 50, 40, 64)   0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 50, 40, 32)   18464       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 50, 40, 32)   18464       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 50, 40, 32)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 50, 40, 32)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 50, 40, 96)   0           up_sampling2d[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 50, 40, 96)   0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 50, 40, 32)   27680       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 50, 40, 32)   27680       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 50, 40, 32)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 50, 40, 32)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 100, 80, 32)  0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 100, 80, 32)  0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 100, 80, 32)  9248        up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 100, 80, 32)  9248        up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 100, 80, 32)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 100, 80, 32)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 100, 80, 64)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 100, 80, 64)  0           up_sampling2d_5[0][0]            \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 100, 80, 32)  18464       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 100, 80, 32)  18464       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 100, 80, 32)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 100, 80, 32)  0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 100, 80, 96)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_19[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 100, 80, 96)  0           up_sampling2d_5[0][0]            \n",
      "                                                                 activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 100, 80, 32)  27680       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 100, 80, 32)  27680       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 100, 80, 32)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 100, 80, 32)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 200, 160, 32) 0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 200, 160, 32) 0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_3ch_diastole_slice0_ (None, 200, 160, 1)  33          up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_2ch_diastole_slice0_ (None, 200, 160, 1)  33          up_sampling2d_6[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,602,978\n",
      "Trainable params: 3,602,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22 14:17:51,918 - models:896 - WARNING - Number of x dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:51,920 - models:896 - WARNING - Number of y dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:51,920 - models:896 - WARNING - Number of z dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:17:51,924 - models:383 - INFO - Residual Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3))]\n",
      "2020-09-22 14:17:51,929 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,934 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,939 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,949 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,953 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,958 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,968 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,973 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:17:51,978 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lax_3ch_diastole_slice0_3 [(None, 200, 160, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 200, 160, 32) 320         input_lax_3ch_diastole_slice0_3d_\n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 200, 160, 32) 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 100, 80, 32)  0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 100, 80, 32)  9248        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 100, 80, 32)  0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 100, 80, 64)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 100, 80, 32)  18464       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 100, 80, 32)  0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 100, 80, 96)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 100, 80, 32)  27680       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 100, 80, 32)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 50, 40, 32)   0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 50, 40, 32)   9248        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 50, 40, 32)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 50, 40, 64)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 50, 40, 32)   18464       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 50, 40, 32)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 50, 40, 96)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 activation_35[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 50, 40, 32)   27680       concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 50, 40, 32)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 25, 20, 32)   0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 20, 32)   9248        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 25, 20, 32)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 25, 20, 64)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 20, 32)   18464       concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 25, 20, 32)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 25, 20, 96)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 20, 32)   27680       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 25, 20, 32)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16000)        0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1024064     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16000)        1040000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16000)        1040000     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16000)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16000)        0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 25, 20, 32)   0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 25, 20, 32)   0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 25, 20, 32)   9248        reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 20, 32)   9248        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 20, 32)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 25, 20, 32)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 25, 20, 64)   0           reshape_2[0][0]                  \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 25, 20, 64)   0           reshape_3[0][0]                  \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 25, 20, 32)   18464       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 20, 32)   18464       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 20, 32)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 25, 20, 32)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 25, 20, 96)   0           reshape_2[0][0]                  \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 25, 20, 96)   0           reshape_3[0][0]                  \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 25, 20, 32)   27680       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 20, 32)   27680       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 20, 32)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 25, 20, 32)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 50, 40, 32)   0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 50, 40, 32)   0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 50, 40, 32)   9248        up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 50, 40, 32)   9248        up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 50, 40, 32)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 50, 40, 32)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 50, 40, 64)   0           up_sampling2d_8[0][0]            \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 50, 40, 64)   0           up_sampling2d_12[0][0]           \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 50, 40, 32)   18464       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 50, 40, 32)   18464       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 50, 40, 32)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 50, 40, 32)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 50, 40, 96)   0           up_sampling2d_8[0][0]            \n",
      "                                                                 activation_47[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 50, 40, 96)   0           up_sampling2d_12[0][0]           \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 50, 40, 32)   27680       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 50, 40, 32)   27680       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 50, 40, 32)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 50, 40, 32)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 100, 80, 32)  0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 100, 80, 32)  0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 100, 80, 32)  9248        up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 100, 80, 32)  9248        up_sampling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 100, 80, 32)  0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 100, 80, 32)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 100, 80, 64)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 100, 80, 64)  0           up_sampling2d_13[0][0]           \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 100, 80, 32)  18464       concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 100, 80, 32)  18464       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 100, 80, 32)  0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 100, 80, 32)  0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 100, 80, 96)  0           up_sampling2d_9[0][0]            \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 100, 80, 96)  0           up_sampling2d_13[0][0]           \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 100, 80, 32)  27680       concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 100, 80, 32)  27680       concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 100, 80, 32)  0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 100, 80, 32)  0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 200, 160, 32) 0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 200, 160, 32) 0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_3ch_diastole_slice0_ (None, 200, 160, 1)  33          up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_2ch_diastole_slice0_ (None, 200, 160, 1)  33          up_sampling2d_14[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 3,602,978\n",
      "Trainable params: 3,602,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Decode has: [(0, (<__main__.DenseConvolutionalBlock object at 0x7fede84f0a20>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede84e9dd8>)), (1, (<__main__.DenseConvolutionalBlock object at 0x7fede84de438>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede84e9ef0>)), (2, (<__main__.DenseConvolutionalBlock object at 0x7fede84f4be0>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede84e9908>))]\n",
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "Decode has: [(0, (<__main__.DenseConvolutionalBlock object at 0x7fede83f05c0>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede8385630>)), (1, (<__main__.DenseConvolutionalBlock object at 0x7fede83794e0>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede8385710>)), (2, (<__main__.DenseConvolutionalBlock object at 0x7fede8379cf8>, <tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fede83857f0>))]\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_lax_2ch_diastole_slice0_3 [(None, 200, 160, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_lax_3ch_diastole_slice0_3 [(None, 200, 160, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 64)           1190560     input_lax_2ch_diastole_slice0_3d_\n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 64)           1190560     input_lax_3ch_diastole_slice0_3d_\n",
      "__________________________________________________________________________________________________\n",
      "cosine_loss_layer (CosineLossLa [(None, 64), (None,  0           model_1[1][0]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 128)          0           cosine_loss_layer[0][0]          \n",
      "                                                                 cosine_loss_layer[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_3ch_diastole_slice0_ (None, 200, 160, 1)  2230209     concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_lax_2ch_diastole_slice0_ (None, 200, 160, 1)  2230209     concatenate_36[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 6,841,538\n",
      "Trainable params: 6,841,538\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "2020-09-22 14:17:59,481 - tensor_generators:661 - INFO - Found 51591 train, 14804 validation, and 7298 testing tensors at: /mnt/disks/sax-lax-40k-lvm/2020-01-29/\n",
      "2020-09-22 14:18:00,207 - models:1422 - INFO - Saving architecture diagram to:./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/architecture_graph_lax_2ch_3ch_diastole_pair_cosine_loss.png\n",
      "2020-09-22 14:18:01,615 - tensor_generators:151 - INFO - Started 3 train workers with cache size 0.875GB.\n",
      "2020-09-22 14:18:01,720 - tensor_generators:151 - INFO - Started 1 validation workers with cache size 0.875GB.\n",
      "Train for 256 steps, validate for 1 steps\n",
      "256/256 [==============================] - 21s 82ms/step - loss: 0.5760 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2407 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2872 - val_loss: 0.4385 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1967 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2418\n",
      "2020-09-22 14:18:22,921 - models:1358 - INFO - Spent:21.42 seconds training, Samples trained on:256 Per sample training speed:0.084 seconds.\n",
      "32/32 [==============================] - 2s 67ms/step\n",
      "2020-09-22 14:18:25,158 - models:1366 - INFO - Spent:2.24 seconds predicting, Samples inferred:256 Per sample inference speed:0.0698 seconds.\n",
      "Train for 256 steps, validate for 30 steps\n",
      "Epoch 1/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4602 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2111 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2490\n",
      "Epoch 00001: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4601 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2111 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2490 - val_loss: 0.4467 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2015 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2452\n",
      "Epoch 2/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4560 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2089 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2453\n",
      "Epoch 00002: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4557 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2087 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2452 - val_loss: 0.4638 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2149 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2490\n",
      "Epoch 3/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5085 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2064 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2367\n",
      "Epoch 00003: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.5087 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2066 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2369 - val_loss: 0.4624 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2013 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2611\n",
      "Epoch 4/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4632 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2082 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2549\n",
      "Epoch 00004: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4631 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2083 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2548 - val_loss: 0.4317 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2028 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2289\n",
      "Epoch 5/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4398 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2020 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2378\n",
      "Epoch 00005: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4399 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2020 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2378 - val_loss: 0.4196 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1958 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4226 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1937 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2288\n",
      "Epoch 00006: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4226 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1938 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2288 - val_loss: 0.4306 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1957 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2349\n",
      "Epoch 7/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4394 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1899 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2248\n",
      "Epoch 00007: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4394 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1901 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2248 - val_loss: 0.5242 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1920 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2274\n",
      "Epoch 8/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4811 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1856 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2215\n",
      "Epoch 00008: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4809 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1858 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2215 - val_loss: 0.6161 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1838 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2229\n",
      "Epoch 9/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5692 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1761 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2206\n",
      "Epoch 00009: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.5685 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1762 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2205 - val_loss: 0.7018 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1739 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2137\n",
      "Epoch 10/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4392 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1923 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2417\n",
      "Epoch 00010: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4395 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1925 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2419 - val_loss: 0.4230 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1852 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2378\n",
      "Epoch 11/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4224 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1889 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2335\n",
      "Epoch 00011: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4222 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1888 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2334 - val_loss: 0.4089 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1849 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2239\n",
      "Epoch 12/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4100 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1852 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2248\n",
      "Epoch 00012: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4101 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1853 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2248 - val_loss: 0.3973 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1780 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2194\n",
      "Epoch 13/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3965 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1774 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2191\n",
      "Epoch 00013: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 26s 100ms/step - loss: 0.3961 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1772 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2189 - val_loss: 0.3898 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1738 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2160\n",
      "Epoch 14/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3939 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1785 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2155\n",
      "Epoch 00014: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 112ms/step - loss: 0.3939 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1784 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2156 - val_loss: 0.3775 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1681 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2094\n",
      "Epoch 15/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3879 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1749 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2129\n",
      "Epoch 00015: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 113ms/step - loss: 0.3881 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1751 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2129 - val_loss: 0.3858 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1763 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2094\n",
      "Epoch 16/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3780 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1703 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2077\n",
      "Epoch 00016: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 112ms/step - loss: 0.3782 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1705 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2077 - val_loss: 0.3917 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1765 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2152\n",
      "Epoch 17/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3763 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1701 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2062\n",
      "Epoch 00017: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 111ms/step - loss: 0.3765 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1702 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2063 - val_loss: 0.3683 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1660 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2023\n",
      "Epoch 18/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3743 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1684 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2059\n",
      "Epoch 00018: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 30s 117ms/step - loss: 0.3742 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1683 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2058 - val_loss: 0.3592 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1618 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1974\n",
      "Epoch 19/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3713 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1679 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2034\n",
      "Epoch 00019: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 111ms/step - loss: 0.3711 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1679 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2032 - val_loss: 0.3848 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1794 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2054\n",
      "Epoch 20/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3904 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1648 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2010\n",
      "Epoch 00020: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 27s 105ms/step - loss: 0.3901 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1647 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2008 - val_loss: 0.4724 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1647 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2030\n",
      "Epoch 21/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4007 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1644 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1993\n",
      "Epoch 00021: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 109ms/step - loss: 0.4007 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1645 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1994 - val_loss: 0.5606 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1597 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1915\n",
      "Epoch 22/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4320 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1618 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1963\n",
      "Epoch 00022: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 110ms/step - loss: 0.4440 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1617 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1964 - val_loss: 0.4605 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1605 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1953\n",
      "Epoch 23/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5055 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1638 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1938\n",
      "Epoch 00023: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 115ms/step - loss: 0.5049 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1638 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1938 - val_loss: 0.3536 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1604 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1932\n",
      "Epoch 24/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4272 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1595 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1937\n",
      "Epoch 00024: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.4268 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1595 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1937 - val_loss: 0.3310 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1499 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1811\n",
      "Epoch 25/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5080 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1576 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1902\n",
      "Epoch 00025: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 112ms/step - loss: 0.5072 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1575 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1902 - val_loss: 0.4506 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1597 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1862\n",
      "Epoch 26/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5284 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1560 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1876\n",
      "Epoch 00026: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 108ms/step - loss: 0.5403 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1561 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1879 - val_loss: 0.3433 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1568 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1866\n",
      "Epoch 27/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4986 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1517 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1867\n",
      "Epoch 00027: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 27s 107ms/step - loss: 0.4980 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1518 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1867 - val_loss: 0.4316 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1494 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1775\n",
      "Epoch 28/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.6307 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1526 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1824\n",
      "Epoch 00028: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 111ms/step - loss: 0.6294 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1526 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1823 - val_loss: 0.4276 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1444 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1785\n",
      "Epoch 29/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5056 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1514 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1817\n",
      "Epoch 00029: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 114ms/step - loss: 0.5048 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1514 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1817 - val_loss: 0.5469 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1559 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1815\n",
      "Epoch 30/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5277 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1498 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1807\n",
      "Epoch 00030: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.5268 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1498 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1806 - val_loss: 0.3298 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1487 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4709 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1457 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1773\n",
      "Epoch 00031: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.4705 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1458 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1774 - val_loss: 0.6338 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1390 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1807\n",
      "Epoch 32/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.5657 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1457 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1736\n",
      "Epoch 00032: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.5644 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1455 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1735 - val_loss: 0.3130 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1366 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1763\n",
      "Epoch 33/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 2.7681 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2063 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2006\n",
      "Epoch 00033: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 2.7712 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2063 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2006 - val_loss: 3.5463 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2103 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1944\n",
      "Epoch 34/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 3.3525 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2147 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1933\n",
      "Epoch 00034: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 3.3534 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2148 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1934 - val_loss: 2.9179 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2120 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1925\n",
      "Epoch 35/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 2.5535 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2082 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1892\n",
      "Epoch 00035: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 122ms/step - loss: 2.5572 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2082 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1892 - val_loss: 1.7530 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2031 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1886\n",
      "Epoch 36/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 1.1451 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2033 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1954\n",
      "Epoch 00036: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 123ms/step - loss: 1.1422 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2033 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1954 - val_loss: 0.4386 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2163 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2223\n",
      "Epoch 37/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4192 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2137 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2056\n",
      "Epoch 00037: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.4190 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2135 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2055 - val_loss: 0.4105 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2097 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.2008\n",
      "Epoch 38/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4066 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2097 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1970\n",
      "Epoch 00038: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 27s 104ms/step - loss: 0.4065 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2096 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1969 - val_loss: 0.3971 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2054 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1917\n",
      "Epoch 39/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.4014 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2072 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1942\n",
      "Epoch 00039: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 110ms/step - loss: 0.4013 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2072 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1941 - val_loss: 0.3994 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2057 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1938\n",
      "Epoch 40/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3950 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2031 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1918\n",
      "Epoch 00040: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 109ms/step - loss: 0.3950 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2031 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1919 - val_loss: 0.3918 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1988 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1930\n",
      "Epoch 41/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3895 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2001 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1894\n",
      "Epoch 00041: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.3894 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2000 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1894 - val_loss: 0.3906 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2003 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1903\n",
      "Epoch 42/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3887 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1997 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1891\n",
      "Epoch 00042: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.3893 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2000 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1893 - val_loss: 0.3761 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1949 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1811\n",
      "Epoch 43/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3918 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2010 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1908\n",
      "Epoch 00043: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 28s 108ms/step - loss: 0.3918 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.2010 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1908 - val_loss: 0.3810 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1926 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1884\n",
      "Epoch 44/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3786 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1931 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1855\n",
      "Epoch 00044: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 121ms/step - loss: 0.3787 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1932 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1855 - val_loss: 0.3816 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1963 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1853\n",
      "Epoch 45/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3759 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1894 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1865\n",
      "Epoch 00045: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.3758 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1893 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1865 - val_loss: 0.3578 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1785 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1793\n",
      "Epoch 46/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3714 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1871 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1843\n",
      "Epoch 00046: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 123ms/step - loss: 0.3716 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1872 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1844 - val_loss: 0.3669 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1845 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1824\n",
      "Epoch 47/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3619 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1794 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1825\n",
      "Epoch 00047: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.3618 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1793 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1825 - val_loss: 0.3712 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1850 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1862\n",
      "Epoch 48/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3635 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1798 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1837\n",
      "Epoch 00048: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 122ms/step - loss: 0.3636 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1799 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1837 - val_loss: 0.3626 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1780 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1846\n",
      "Epoch 49/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3566 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1726 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1840\n",
      "Epoch 00049: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 114ms/step - loss: 0.3565 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1724 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1840 - val_loss: 0.3510 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1730 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1779\n",
      "Epoch 50/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3548 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1727 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1821\n",
      "Epoch 00050: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.3547 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1726 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1821 - val_loss: 0.3551 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1746 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1806\n",
      "Epoch 51/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3484 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1689 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1794\n",
      "Epoch 00051: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 121ms/step - loss: 0.3486 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1689 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1797 - val_loss: 0.3498 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1715 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1783\n",
      "Epoch 52/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3490 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1673 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1817\n",
      "Epoch 00052: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 111ms/step - loss: 0.3488 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1672 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1816 - val_loss: 0.3341 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1567 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1775\n",
      "Epoch 53/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3410 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1611 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1799\n",
      "Epoch 00053: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.3410 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1611 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1800 - val_loss: 0.3371 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1577 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1794\n",
      "Epoch 54/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3341 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1572 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1769\n",
      "Epoch 00054: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.3341 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1571 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1770 - val_loss: 0.3274 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1548 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1726\n",
      "Epoch 55/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3382 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1584 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1798\n",
      "Epoch 00055: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.3383 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1585 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1798 - val_loss: 0.3413 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1641 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3296 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1533 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1763\n",
      "Epoch 00056: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 115ms/step - loss: 0.3292 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1532 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1761 - val_loss: 0.3213 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1473 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1740\n",
      "Epoch 57/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3354 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1582 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1771\n",
      "Epoch 00057: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.3355 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1583 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1772 - val_loss: 0.3306 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1588 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1719\n",
      "Epoch 58/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3199 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1478 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1722\n",
      "Epoch 00058: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 114ms/step - loss: 0.3200 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1477 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1723 - val_loss: 0.3221 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1525 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1696\n",
      "Epoch 59/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3181 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1466 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1715\n",
      "Epoch 00059: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 110ms/step - loss: 0.3177 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1464 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1713 - val_loss: 0.3199 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1449 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1750\n",
      "Epoch 60/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3197 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1462 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1735\n",
      "Epoch 00060: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 108ms/step - loss: 0.3198 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1463 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1735 - val_loss: 0.3220 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1445 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1775\n",
      "Epoch 61/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3158 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1457 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1701\n",
      "Epoch 00061: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 117ms/step - loss: 0.3161 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1459 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1702 - val_loss: 0.3227 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1515 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1712\n",
      "Epoch 62/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3139 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1429 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1710\n",
      "Epoch 00062: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 117ms/step - loss: 0.3139 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1429 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1710 - val_loss: 0.4193 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1413 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1733\n",
      "Epoch 63/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3146 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1434 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1712\n",
      "Epoch 00063: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 110ms/step - loss: 0.3144 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1433 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1711 - val_loss: 0.3136 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1417 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1719\n",
      "Epoch 64/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3071 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1395 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1676\n",
      "Epoch 00064: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.3072 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1396 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1676 - val_loss: 0.3241 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1474 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1767\n",
      "Epoch 65/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3172 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1377 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1672\n",
      "Epoch 00065: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 119ms/step - loss: 0.3171 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1377 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1671 - val_loss: 0.3018 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1336 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1682\n",
      "Epoch 66/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3135 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1352 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1660\n",
      "Epoch 00066: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 118ms/step - loss: 0.3134 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1352 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1660 - val_loss: 0.3066 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1399 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1667\n",
      "Epoch 67/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3006 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1356 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1651\n",
      "Epoch 00067: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 123ms/step - loss: 0.3008 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1356 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1652 - val_loss: 0.3022 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1327 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1695\n",
      "Epoch 68/292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/256 [============================>.] - ETA: 0s - loss: 0.2982 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1351 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1632\n",
      "Epoch 00068: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.2982 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1351 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1631 - val_loss: 0.3013 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1331 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1682\n",
      "Epoch 69/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3482 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1351 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1639\n",
      "Epoch 00069: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 30s 116ms/step - loss: 0.3481 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1351 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1639 - val_loss: 0.2967 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1362 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1605\n",
      "Epoch 70/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.2990 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1336 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1654\n",
      "Epoch 00070: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 115ms/step - loss: 0.2988 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1336 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1653 - val_loss: 0.3018 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1366 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1652\n",
      "Epoch 71/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.2985 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1337 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1648\n",
      "Epoch 00071: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 32s 125ms/step - loss: 0.2985 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1337 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1648 - val_loss: 0.2984 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1305 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1679\n",
      "Epoch 72/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3065 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1314 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1628\n",
      "Epoch 00072: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 31s 121ms/step - loss: 0.3065 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1314 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1628 - val_loss: 0.2824 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1261 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1563\n",
      "Epoch 73/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3058 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1315 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1619\n",
      "Epoch 00073: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 29s 113ms/step - loss: 0.3056 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1314 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1619 - val_loss: 0.2949 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1302 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1646\n",
      "Epoch 74/292\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.2887 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1273 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1613\n",
      "Epoch 00074: saving model to ./recipes_output/lax_2ch_3ch_diastole_pair_cosine_loss/lax_2ch_3ch_diastole_pair_cosine_loss.h5\n",
      "256/256 [==============================] - 28s 108ms/step - loss: 0.2886 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1273 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1613 - val_loss: 0.2744 - val_output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1213 - val_output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1531\n",
      "Epoch 75/292\n",
      "153/256 [================>.............] - ETA: 9s - loss: 0.2916 - output_lax_3ch_diastole_slice0_3d_continuous_loss: 0.1290 - output_lax_2ch_diastole_slice0_3d_continuous_loss: 0.1626"
     ]
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/sax-lax-40k-lvm/2020-01-29/', \n",
    "            '--input_tensors', 'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d', \n",
    "            '--output_tensors', 'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '32',\n",
    "            '--conv_x', '3', '3', '3',\n",
    "            '--conv_y', '3', '3', '3', \n",
    "            '--conv_z', '3', '3', '3', \n",
    "            '--dense_blocks', '32', '32', '32',\n",
    "            '--block_size', '3',\n",
    "            '--dense_layers', '64',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '1',\n",
    "            '--patience', '32',\n",
    "            '--epochs', '292',\n",
    "            '--learning_rate', '0.0001',\n",
    "            '--training_steps', '256',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '2',\n",
    "            '--num_workers', '4',\n",
    "            '--inspect_model',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb.mri',\n",
    "            '--id', 'lax_2ch_3ch_diastole_pair_cosine_loss']\n",
    "args = parse_args()\n",
    "pairs = [(args.tensor_maps_in[0], args.tensor_maps_in[1])]\n",
    "overparameterized_model, encoders, decoders = make_paired_autoencoder_model(pairs, pair_loss='cosine', **args.__dict__)\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "train_model_from_generators(\n",
    "        overparameterized_model, generate_train, generate_valid, args.training_steps, args.validation_steps, args.batch_size,\n",
    "        args.epochs, args.patience, args.output_folder, args.id, args.inspect_model, args.inspect_show_labels,\n",
    "        plot=False, save_last_model=True\n",
    ")\n",
    "for tm in encoders:\n",
    "    encoders[tm].save(f'{args.output_folder}{args.id}/encoder_{tm.name}.h5')\n",
    "for tm in decoders:\n",
    "    decoders[tm].save(f'{args.output_folder}{args.id}/decoder_{tm.name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/segmented-sax-lax/2020-07-07/', \n",
    "            '--input_tensors', 'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d', \n",
    "            '--output_tensors',  'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d', 'LVM',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '24',\n",
    "            '--conv_x', '3', '3', '3',\n",
    "            '--conv_y', '3', '3', '3',\n",
    "            '--conv_z', '3', '3', '3',\n",
    "            '--dense_blocks', '24',\n",
    "            '--block_size', '4',\n",
    "            '--dense_layers', '512',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '2',\n",
    "            '--patience', '32',\n",
    "            '--epochs', '292',\n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '256',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '2',\n",
    "            '--num_workers', '4',\n",
    "            '--hidden_layer', 'concatenate_12',\n",
    "            '--model_file', './recipes_output/lax_2ch_3ch_diastole_paired_autoencoder_swish/lax_2ch_3ch_diastole_paired_autoencoder_swish.h5',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb.mri',\n",
    "            '--id', 'lax_2ch_3ch_diastole_paired_autoencoder_swish']\n",
    "args = parse_args()\n",
    "#plot_predictions(args)\n",
    "infer_hidden_layer_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_inference = './recipes_output/lax_2ch_3ch_diastole_paired_autoencoder_swish/hidden_inference_lax_2ch_3ch_diastole_paired_autoencoder_swish.tsv'\n",
    "df = pd.read_csv('/home/sam/ml/trained_models/lax_4ch_diastole_autoencode_leaky_converge/tensors_all_union.csv')\n",
    "df['21003_Age-when-attended-assessment-centre_2_0'].plot.hist(bins=30)\n",
    "\n",
    "df2 = pd.read_csv(hidden_inference, sep='\\t')\n",
    "df['fpath'] = pd.to_numeric(df['fpath'], errors='coerce')\n",
    "df2['sample_id'] = pd.to_numeric(df2['sample_id'], errors='coerce')\n",
    "#df.info()\n",
    "latent_df = pd.merge(df, df2, left_on='fpath', right_on='sample_id', how='inner')\n",
    "# #latent_df.info()\n",
    "# df3 = pd.read_csv('/home/sam/tsvs/ttn_disease.tsv', sep='\\t')\n",
    "# df4 = pd.read_csv('/home/sam/csvs/has_exome.csv')\n",
    "# latent_df = pd.merge(df3, latent_df, left_on='sample_id', right_on='sample_id', how='right')\n",
    "# \n",
    "# print(latent_df['has_ttntv'].value_counts())\n",
    "latent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps*5)\n",
    "print(list(test_data.keys()))\n",
    "\n",
    "preds = overparameterized_model.predict(test_data)\n",
    "print([p.shape for p in preds])\n",
    "print([tm.name for tm in args.tensor_maps_out])\n",
    "print(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4h.plots import _plot_reconstruction\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_lax_2ch_diastole_slice0_3d_continuous'], preds[0], out_path, test_paths, num_samples=2)\n",
    "from ml4h.explorations import predictions_to_pngs\n",
    "predictions_to_pngs(preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, etm in enumerate(encoders):\n",
    "    embed = encoders[etm].predict(test_data[etm.input_name()])\n",
    "    double = np.tile(embed, 2)\n",
    "    print(f'embed shape: {embed.shape} double shape: {double.shape}')\n",
    "    for dtm in decoders:\n",
    "        predictions = decoders[dtm].predict(double)\n",
    "        print(f'prediction shape: {predictions.shape}')\n",
    "        out_path = os.path.join(args.output_folder, args.id, f'decoding_{dtm.name}_from_{etm.name}/')\n",
    "        if not os.path.exists(os.path.dirname(out_path)):\n",
    "            os.makedirs(os.path.dirname(out_path))\n",
    "        _plot_reconstruction(dtm, test_data[dtm.input_name()], predictions.copy(), out_path, test_paths, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_on_matrix(matrix, pca_components):\n",
    "    pca = PCA()\n",
    "    pca.fit(matrix)\n",
    "    print(f'PCA explains {100*np.sum(pca.explained_variance_ratio_[:pca_components]):0.1f}% of variance with {pca_components} top PCA components.')\n",
    "    matrix_reduced = pca.transform(matrix)[:, :pca_components]\n",
    "    print(f'PCA reduces matrix shape:{matrix_reduced.shape} from matrix shape: {matrix.shape}')\n",
    "    plot_scree(pca_components, 100*pca.explained_variance_ratio_)\n",
    "    return pca, matrix_reduced\n",
    "\n",
    "def plot_scree(pca_components, percent_explained):\n",
    "    _ = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(len(percent_explained)), percent_explained, 'g.-', linewidth=1)\n",
    "    plt.axvline(x=pca_components, c='r', linewidth=3)\n",
    "    label = f'{np.sum(percent_explained[:pca_components]):0.1f}% of variance explained by top {pca_components} of {len(percent_explained)} components'\n",
    "    plt.text(pca_components+0.02*len(percent_explained), percent_explained[1], label)\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('% of Variance Explained by Each Component')\n",
    "    figure_path = f'./results/pca_{pca_components}_of_{len(percent_explained)}_testimonials.png'\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path)\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def directions_in_latent_space(stratify_column, stratify_thresh, split_column, split_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    strat_vector = hit_mean_vector - miss_mean_vector\n",
    "    \n",
    "    hit1 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    miss1 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    hit2 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss2 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss_mean_vector1 = np.mean(miss1, axis=0)\n",
    "    hit_mean_vector1 = np.mean(hit1, axis=0)\n",
    "    angle1 = angle_between(miss_mean_vector1, hit_mean_vector1)\n",
    "    miss_mean_vector2 = np.mean(miss2, axis=0)\n",
    "    hit_mean_vector2 = np.mean(hit2, axis=0)\n",
    "    angle2 = angle_between(miss_mean_vector2, hit_mean_vector2)\n",
    "    h1_vector = hit_mean_vector1-miss_mean_vector1\n",
    "    h2_vector = hit_mean_vector2-miss_mean_vector2\n",
    "    angle3 = angle_between(h1_vector, h2_vector)\n",
    "    angle4 = angle_between(strat_vector, h1_vector)\n",
    "    angle5 = angle_between(strat_vector, h2_vector)\n",
    "    print(f'\\n Between {stratify_column}, and splits: {split_column}\\n',\n",
    "          f'Angles: {angle1:.4f}, {angle2:.4f} \\n'\n",
    "          f'stratify threshold: {stratify_thresh}, split thresh: {split_thresh}, \\n'\n",
    "          f'hit_mean_vector2 shape {miss_mean_vector1.shape}, miss1:{hit_mean_vector2.shape} \\n'\n",
    "          f'Hit1 shape {hit1.shape}, miss1:{miss1.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Hit2 shape {hit2.shape}, miss2:{miss2.shape}\\n')\n",
    "\n",
    "def stratify_latent_space(stratify_column, stratify_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "    print(f'Angle between {stratify_column} and all others: {angle}, \\n'\n",
    "          f'Hit shape {hit.shape}, miss:{miss.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Distance: {np.linalg.norm(hit_mean_vector-miss_mean_vector):.3f}, Hit std {np.std(hit, axis=1).mean():.3f}, miss std:{np.std(miss, axis=1).mean():.3f}\\n')\n",
    "    \n",
    "def plot_pcs(sides, color_key):\n",
    "    f, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        colors = latent_df[color_key].to_numpy()\n",
    "        points = ax.scatter(matrix_reduce[:, i], matrix_reduce[:, i+1], c=colors)\n",
    "        f.colorbar(points, ax=ax)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 3500000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 1250000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ch2_encode = df2[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "ch3_encode = df2[latent_cols].to_numpy()\n",
    "sqr_diff = (ch2_encode - ch3_encode) * (ch2_encode - ch3_encode)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ch2_encode[:5,:5]} \\n{ch3_encode[:5,:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_random = np.random.random((4452, 256))\n",
    "ch3_random = np.random.random((4452, 256))\n",
    "sqr_diff = (ch2_random - ch3_random) * (ch2_random - ch3_random)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ch2_encode = df2[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{98+i}' for i in range(latent_dimension)]\n",
    "ch3_encode = df2[latent_cols].to_numpy()\n",
    "sqr_diff = (ch2_encode - ch3_encode) * (ch2_encode - ch3_encode)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
