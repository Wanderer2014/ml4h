{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Dict, List, Tuple, Iterable, Union, Optional, Set, Sequence, Callable, DefaultDict, Any\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D, Concatenate, Add\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "\n",
    "\n",
    "# ml4h Imports\n",
    "from ml4h.TensorMap import TensorMap\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.models import make_multimodal_multitask_model, train_model_from_generators, make_hidden_layer_model, _conv_layer_from_kind_and_dimension\n",
    "from ml4h.tensor_generators import TensorGenerator, big_batch_from_minibatch_generator, test_train_valid_tensor_generators\n",
    "from ml4h.recipes import plot_predictions, infer_hidden_layer_multimodal_multitask\n",
    "\n",
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Tensor = tf.Tensor\n",
    "\n",
    "ACTIVATION_CLASSES = {\n",
    "    'leaky': LeakyReLU(),\n",
    "    'prelu': PReLU(),\n",
    "    'elu': ELU(),\n",
    "    'thresh_relu': ThresholdedReLU,\n",
    "}\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'swish': tf.nn.swish,\n",
    "    'gelu': tfa.activations.gelu,\n",
    "    'lisht': tfa.activations.lisht,\n",
    "    'mish': tfa.activations.mish,\n",
    "}\n",
    "NORMALIZATION_CLASSES = {\n",
    "    'batch_norm': BatchNormalization,\n",
    "    'layer_norm': LayerNormalization,\n",
    "    'instance_norm': tfa.layers.InstanceNormalization,\n",
    "    'poincare_norm': tfa.layers.PoincareNormalize,\n",
    "}\n",
    "CONV_REGULARIZATION_CLASSES = {\n",
    "    # class name -> (dimension -> class)\n",
    "    'spatial_dropout': {2: SpatialDropout1D, 3: SpatialDropout2D, 4: SpatialDropout3D},\n",
    "    'dropout': defaultdict(lambda _: Dropout),\n",
    "}\n",
    "DENSE_REGULARIZATION_CLASSES = {\n",
    "    'dropout': Dropout,  # TODO: add l1, l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _activation_layer(activation: str) -> Activation:\n",
    "    return (\n",
    "        ACTIVATION_CLASSES.get(activation, None)\n",
    "        or Activation(ACTIVATION_FUNCTIONS.get(activation, None) or activation)\n",
    "    )\n",
    "\n",
    "\n",
    "def _normalization_layer(norm: str) -> Layer:\n",
    "    if not norm:\n",
    "        return lambda x: x\n",
    "    return NORMALIZATION_CLASSES[norm]()\n",
    "\n",
    "\n",
    "def _regularization_layer(dimension: int, regularization_type: str, rate: float):\n",
    "    if not regularization_type:\n",
    "        return lambda x: x\n",
    "    if regularization_type in DENSE_REGULARIZATION_CLASSES:\n",
    "        return DENSE_REGULARIZATION_CLASSES[regularization_type](rate)\n",
    "    return CONV_REGULARIZATION_CLASSES[regularization_type][dimension](rate)\n",
    "\n",
    "\n",
    "def _calc_start_shape(\n",
    "        num_upsamples: int, output_shape: Tuple[int, ...], upsample_rates: Sequence[int], channels: int,\n",
    ") -> Tuple[int, ...]:\n",
    "    \"\"\"\n",
    "    Given the number of blocks in the decoder and the upsample rates, return required input shape to get to output shape\n",
    "    \"\"\"\n",
    "    upsample_rates = list(upsample_rates) + [1] * len(output_shape)\n",
    "    return tuple((shape // rate**num_upsamples for shape, rate in zip(output_shape[:-1], upsample_rates))) + (channels,)\n",
    "\n",
    "\n",
    "class FlatToStructure:\n",
    "    \"\"\"Takes a flat input, applies a dense layer, then restructures to output_shape\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_shape: Tuple[int, ...],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "    ):\n",
    "        self.input_shapes = output_shape\n",
    "        self.dense = Dense(units=int(np.prod(output_shape)))\n",
    "        self.activation = _activation_layer(activation)\n",
    "        self.reshape = Reshape(output_shape)\n",
    "        self.norm = _normalization_layer(normalization)\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return self.reshape(self.norm(self.activation(self.dense(x))))\n",
    "\n",
    "\n",
    "def _conv_layer_from_kind_and_dimension(\n",
    "        dimension: int, conv_layer_type: str, conv_x: List[int], conv_y: List[int], conv_z: List[int],\n",
    ") -> Tuple[Layer, List[Tuple[int, ...]]]:\n",
    "    if dimension == 4 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv3D\n",
    "        kernel = zip(conv_x, conv_y, conv_z)\n",
    "    elif dimension == 3 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'depth':\n",
    "        conv_layer = DepthwiseConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown convolution type: {conv_layer_type} for dimension: {dimension}')\n",
    "    return conv_layer, list(kernel)\n",
    "\n",
    "\n",
    "def _upsampler(dimension, pool_x, pool_y, pool_z):\n",
    "    if dimension == 4:\n",
    "        return UpSampling3D(size=(pool_x, pool_y, pool_z))\n",
    "    elif dimension == 3:\n",
    "        return UpSampling2D(size=(pool_x, pool_y))\n",
    "    elif dimension == 2:\n",
    "        return UpSampling1D(size=pool_x)\n",
    "    \n",
    "\n",
    "    \n",
    "def _one_by_n_kernel(dimension):\n",
    "    return tuple([1] * (dimension - 1))\n",
    "\n",
    "\n",
    "class DenseConvolutionalBlock:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            dimension: int,\n",
    "            block_size: int,\n",
    "            conv_layer_type: str,\n",
    "            filters: int,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "    ):\n",
    "        conv_layer, kernels = _conv_layer_from_kind_and_dimension(dimension, conv_layer_type, conv_x, conv_y, conv_z)\n",
    "        if isinstance(conv_layer, DepthwiseConv2D):\n",
    "            self.conv_layers = [conv_layer(kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        else:\n",
    "            self.conv_layers = [conv_layer(filters=filters, kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        self.activations = [_activation_layer(activation) for _ in range(block_size)]\n",
    "        self.normalizations = [_normalization_layer(normalization) for _ in range(block_size)]\n",
    "        self.regularizations = [_regularization_layer(dimension, regularization, regularization_rate) for _ in range(block_size)]\n",
    "        print(f'Dense Block Convolutional Layers (num_filters, kernel_size): {list(zip([filters]*len(kernels), kernels))}')\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        dense_connections = [x]\n",
    "        for i, (convolve, activate, normalize, regularize) in enumerate(\n",
    "            zip(\n",
    "                    self.conv_layers, self.activations, self.normalizations, self.regularizations,\n",
    "            ),\n",
    "        ):\n",
    "            x = normalize(regularize(activate(convolve(x))))\n",
    "            if i < len(self.conv_layers) - 1:  # output of block does not get concatenated to\n",
    "                dense_connections.append(x)\n",
    "                x = Concatenate()(dense_connections[:])  # [:] is necessary because of tf weirdness\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ConvDecoder2:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            tensor_map_out: TensorMap,\n",
    "            filters_per_dense_block: List[int],\n",
    "            conv_layer_type: str,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            block_size: int,\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "            upsample_x: int,\n",
    "            upsample_y: int,\n",
    "            upsample_z: int,\n",
    "    ):\n",
    "        dimension = tensor_map_out.axes()\n",
    "        self.dense_blocks = [\n",
    "            DenseConvolutionalBlock(\n",
    "                dimension=tensor_map_out.axes(), conv_layer_type=conv_layer_type, filters=filters, conv_x=[x]*block_size,\n",
    "                conv_y=[y]*block_size, conv_z=[z]*block_size, block_size=block_size, activation=activation, normalization=normalization,\n",
    "                regularization=regularization, regularization_rate=regularization_rate,\n",
    "            )\n",
    "            for filters, x, y, z in zip(filters_per_dense_block, conv_x, conv_y, conv_z)\n",
    "        ]\n",
    "        conv_layer, _ = _conv_layer_from_kind_and_dimension(dimension, 'conv', conv_x, conv_y, conv_z)\n",
    "        self.conv_label = conv_layer(tensor_map_out.shape[-1], _one_by_n_kernel(dimension), activation=tensor_map_out.activation, name=tensor_map_out.output_name())\n",
    "        self.upsamples = [_upsampler(dimension, upsample_x, upsample_y, upsample_z) for _ in range(len(filters_per_dense_block) + 1)]\n",
    "        print(f'Decode has: {list(enumerate(zip(self.dense_blocks, self.upsamples)))}')\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        for i, (dense_block, upsample) in enumerate(zip(self.dense_blocks, self.upsamples)):\n",
    "            \n",
    "            x = upsample(x)\n",
    "            x = dense_block(x)\n",
    "        return self.conv_label(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import acos\n",
    "\n",
    "def l2_norm(x, axis=None):\n",
    "    \"\"\"\n",
    "    takes an input tensor and returns the l2 norm along specified axis\n",
    "    \"\"\"\n",
    "\n",
    "    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)\n",
    "    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))\n",
    "\n",
    "    return norm\n",
    "\n",
    "def pairwise_cosine_difference(t1, t2):\n",
    "    \"\"\"\n",
    "    A [batch x n x d] tensor of n rows with d dimensions\n",
    "    B [batch x m x d] tensor of n rows with d dimensions\n",
    "\n",
    "    returns:\n",
    "    D [batch x n x m] tensor of cosine similarity scores between each point i<n, j<m\n",
    "    \"\"\"\n",
    "    t1_norm = t1 / l2_norm(t1, axis=-1)\n",
    "    t2_norm = t2 / l2_norm(t2, axis=-1)\n",
    "    dot = K.clip(K.batch_dot(t1, t2), -1, 1)\n",
    "    return acos(dot)\n",
    "\n",
    "class CosineLossLayer(Layer):\n",
    "    \"\"\"Layer that creates an Cosine loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(CosineLossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    def call(self, inputs):\n",
    "        # We use `add_loss` to create a regularization loss\n",
    "        # that depends on the inputs.\n",
    "        self.add_loss(self.weight * pairwise_cosine_difference(inputs[0], inputs[1]))\n",
    "        return inputs\n",
    "\n",
    "class L2LossLayer(Layer):\n",
    "    \"\"\"Layer that creates an L2 loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(L2LossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.add_loss(self.weight * tf.reduce_sum(tf.square(inputs[0] - inputs[1])))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_paired_autoencoder_model(\n",
    "    pairs: List[Tuple[TensorMap, TensorMap]],\n",
    "    pair_loss = 'cosine',\n",
    "    **kwargs\n",
    ") -> Model:\n",
    "    inputs = {tm: Input(shape=tm.shape, name=tm.input_name()) for tm in args.tensor_maps_in}\n",
    "    original_outputs = {tm:1 for tm in args.tensor_maps_out}\n",
    "    real_serial_layers = kwargs['model_layers']\n",
    "    args.model_layers = None\n",
    "    multimodal_activations = []\n",
    "    encoders = {}\n",
    "    decoders = {}\n",
    "    outputs = []\n",
    "    losses = []\n",
    "    for left, right in pairs:\n",
    "        args.tensor_maps_in = [left]\n",
    "        left_model = make_multimodal_multitask_model(**args.__dict__)\n",
    "        encode_left = make_hidden_layer_model(left_model, [left], args.hidden_layer)\n",
    "        h_left = encode_left(inputs[left])\n",
    "        \n",
    "        args.tensor_maps_in = [right]\n",
    "        right_model = make_multimodal_multitask_model(**args.__dict__)     \n",
    "        encode_right = make_hidden_layer_model(right_model, [right], args.hidden_layer)\n",
    "        h_right = encode_right(inputs[right])        \n",
    "        \n",
    "        if pair_loss == 'cosine':\n",
    "            loss_layer = CosineLossLayer(1.0)\n",
    "        elif pair_loss == 'euclid':\n",
    "            loss_layer = L2LossLayer(1.0)\n",
    "        \n",
    "        paired_embeddings = loss_layer([h_left, h_right])\n",
    "        multimodal_activations.extend(paired_embeddings)\n",
    "        if left not in encoders:\n",
    "            encoders[left] = encode_left\n",
    "        if right not in encoders:\n",
    "            encoders[right] = encode_right            \n",
    "        \n",
    "    multimodal_activation = Concatenate()(multimodal_activations)\n",
    "    encoder = Model(inputs=list(inputs.values()), outputs=[multimodal_activation], name='encoder')\n",
    "    \n",
    "    # build decoder models\n",
    "    latent_inputs = Input(shape=(args.dense_layers[0]*len(inputs)), name='input_concept_space')\n",
    "    pre_decoder_shapes: Dict[TensorMap, Optional[Tuple[int, ...]]] = {}\n",
    "    for tm in args.tensor_maps_out:\n",
    "        shape = _calc_start_shape(num_upsamples=len(args.dense_blocks), output_shape=tm.shape, \n",
    "                                  upsample_rates=[args.pool_x, args.pool_y, args.pool_z], \n",
    "                                  channels=args.dense_blocks[-1])    \n",
    "        \n",
    "        restructure = FlatToStructure(output_shape=shape, activation=args.activation, \n",
    "                                      normalization=args.dense_normalize)\n",
    "        \n",
    "        decode = ConvDecoder2(\n",
    "            tensor_map_out=tm,\n",
    "            filters_per_dense_block=args.dense_blocks[::-1],\n",
    "            conv_layer_type=args.conv_type,\n",
    "            conv_x=args.conv_x,\n",
    "            conv_y=args.conv_y,\n",
    "            conv_z=args.conv_z,\n",
    "            block_size=args.block_size,\n",
    "            activation=args.activation,\n",
    "            normalization=args.conv_normalize,\n",
    "            regularization=args.conv_regularize,\n",
    "            regularization_rate=args.conv_regularize_rate,\n",
    "            upsample_x=args.pool_x,\n",
    "            upsample_y=args.pool_y,\n",
    "            upsample_z=args.pool_z,\n",
    "        )\n",
    "        \n",
    "        reconstruction = decode(restructure(latent_inputs))\n",
    "        decoder = Model(latent_inputs, reconstruction, name=tm.output_name())\n",
    "        decoders[tm] = decoder\n",
    "        outputs.append(decoder(multimodal_activation))\n",
    "        losses.append(tm.loss)\n",
    "\n",
    "    args.tensor_maps_out =  list(original_outputs.keys())\n",
    "    args.tensor_maps_in = list(inputs.keys())\n",
    "    \n",
    "    m = Model(inputs=list(inputs.values()), outputs=outputs)\n",
    "    my_metrics = {tm.output_name(): tm.metrics for tm in args.tensor_maps_out}\n",
    "    opt = Adam(lr=kwargs['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    m.compile(optimizer=opt, loss=losses, metrics=my_metrics)\n",
    "    m.summary()\n",
    "    \n",
    "    if real_serial_layers is not None:\n",
    "        m.load_weights(kwargs['model_layers'], by_name=True)\n",
    "        print(f\"Loaded model weights from:{kwargs['model_layers']}\")\n",
    "        \n",
    "    return m, encoders, decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22 14:43:51,484 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/ecg_lax_4c_diastole_pair_euclid_loss/log_2020-09-22_14-43_0.log.\n",
      "2020-09-22 14:43:52,086 - arguments:444 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors /mnt/disks/sax-lax-40k-lvm/2020-01-29/ --input_tensors ecg.ecg_rest mri.lax_4ch_diastole_slice0_224_3d --output_tensors ecg.ecg_rest mri.lax_4ch_diastole_slice0_224_3d --activation swish --conv_layers 32 --conv_x 3 3 3 --conv_y 3 3 3 --conv_z 3 3 3 --dense_blocks 32 32 32 --block_size 3 --dense_layers 256 --pool_x 2 --pool_y 2 --batch_size 1 --patience 132 --epochs 692 --learning_rate 0.0001 --training_steps 256 --validation_steps 30 --test_steps 2 --num_workers 4 --inspect_model --tensormap_prefix ml4h.tensormap.ukb --id ecg_lax_4c_diastole_pair_euclid_loss\n",
      "\n",
      "2020-09-22 14:43:52,088 - arguments:445 - INFO - Arguments are Namespace(activation='swish', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=1, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_regularize_rate=0.0, conv_type='conv', conv_x=[3, 3, 3], conv_y=[3, 3, 3], conv_z=[3, 3, 3], debug=False, dense_blocks=[32, 32, 32], dense_layers=[256], dense_normalize=None, dense_regularize=None, dense_regularize_rate=0.0, dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', eager=False, embed_visualization=None, epochs=692, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='ecg_lax_4c_diastole_pair_euclid_loss', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d'], inspect_model=True, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix='ukb_ecg_rest', learning_rate=0.0001, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./recipes_output/', output_tensors=['ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d'], padding='same', patience=132, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=[], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, save_last_model=False, t=48, tensor_maps_in=[TensorMap(strip, (5000, 12), continuous), TensorMap(lax_4ch_diastole_slice0_224_3d, (160, 224, 1), continuous)], tensor_maps_out=[TensorMap(strip, (5000, 12), continuous), TensorMap(lax_4ch_diastole_slice0_224_3d, (160, 224, 1), continuous)], tensor_maps_protected=[], tensormap_prefix='ml4h.tensormap.ukb', tensors='/mnt/disks/sax-lax-40k-lvm/2020-01-29/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=2, text_file=None, text_one_hot=False, text_window=32, time_frequency='3M', time_tensor='partners_ecg_datetime', train_csv=None, training_steps=256, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=30, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "\n",
      "2020-09-22 14:43:52,106 - models:896 - WARNING - Number of x dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:43:52,107 - models:896 - WARNING - Number of y dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:43:52,108 - models:896 - WARNING - Number of z dimensions for convolutional kernel sizes (3) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-09-22 14:43:52,125 - models:383 - INFO - Residual Block Convolutional Layers (num_filters, kernel_size): [(32, (3,))]\n",
      "2020-09-22 14:43:52,131 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,137 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,143 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,157 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,163 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,170 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-09-22 14:43:52,179 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:43:52,184 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n",
      "2020-09-22 14:43:52,189 - models:421 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3, 3)), (32, (3, 3)), (32, (3, 3))]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[256,20000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: dense/kernel/Initializer/random_uniform/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-232290211301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_maps_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_maps_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0moverparameterized_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_paired_autoencoder_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mgenerate_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_train_valid_tensor_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m train_model_from_generators(\n",
      "\u001b[0;32m<ipython-input-4-2d17b0a6defb>\u001b[0m in \u001b[0;36mmake_paired_autoencoder_model\u001b[0;34m(pairs, pair_loss, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_maps_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mleft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_multimodal_multitask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mencode_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_hidden_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mh_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/models.py\u001b[0m in \u001b[0;36mmake_multimodal_multitask_model\u001b[0;34m(tensor_maps_in, tensor_maps_out, activation, learning_rate, bottleneck_type, optimizer, dense_layers, dense_normalize, dense_regularize, dense_regularize_rate, conv_layers, dense_blocks, block_size, conv_type, conv_normalize, conv_regularize, conv_regularize_rate, conv_x, conv_y, conv_z, conv_dilate, u_connect, pool_x, pool_y, pool_z, pool_type, training_steps, learning_rate_schedule, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_multimodal_multitask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;31m# load layers for transfer learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/models.py\u001b[0m in \u001b[0;36m_make_multimodal_multitask_model\u001b[0;34m(encoders, bottle_neck, decoders)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mencoder_intermediates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mbottle_neck_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottle_neck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/models.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, encoder_outputs)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_tm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_normalize_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         return {\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrestructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestructure\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_restructures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/models.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_tm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_normalize_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         return {\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrestructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestructure\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestructures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_restructures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtm\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/models.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2594\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2596\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2597\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1540\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1542\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1544\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    121\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m       \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    786\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m     return op(\n\u001b[0;32m--> 788\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,20000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: dense/kernel/Initializer/random_uniform/"
     ]
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/sax-lax-40k-lvm/2020-01-29/', \n",
    "            '--input_tensors', 'ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d', \n",
    "            '--output_tensors', 'ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '32',\n",
    "            '--conv_x', '3', '3', '3',\n",
    "            '--conv_y', '3', '3', '3', \n",
    "            '--conv_z', '3', '3', '3', \n",
    "            '--dense_blocks', '32', '32', '32',\n",
    "            '--block_size', '3',\n",
    "            '--dense_layers', '256',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '1',\n",
    "            '--patience', '132',\n",
    "            '--epochs', '692',\n",
    "            '--learning_rate', '0.0001',\n",
    "            '--training_steps', '256',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '2',\n",
    "            '--num_workers', '4',\n",
    "            '--inspect_model',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb',\n",
    "            '--id', 'ecg_lax_4c_diastole_pair_euclid_loss']\n",
    "args = parse_args()\n",
    "pairs = [(args.tensor_maps_in[0], args.tensor_maps_in[1])]\n",
    "overparameterized_model, encoders, decoders = make_paired_autoencoder_model(pairs, pair_loss='euclid', **args.__dict__)\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "train_model_from_generators(\n",
    "        overparameterized_model, generate_train, generate_valid, args.training_steps, args.validation_steps, args.batch_size,\n",
    "        args.epochs, args.patience, args.output_folder, args.id, args.inspect_model, args.inspect_show_labels,\n",
    "        plot=False, save_last_model=True\n",
    ")\n",
    "for tm in encoders:\n",
    "    encoders[tm].save(f'{args.output_folder}{args.id}/encoder_{tm.name}.h5')\n",
    "for tm in decoders:\n",
    "    decoders[tm].save(f'{args.output_folder}{args.id}/decoder_{tm.name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/segmented-sax-lax/2020-07-07/', \n",
    "            '--input_tensors', 'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d', \n",
    "            '--output_tensors',  'lax_2ch_diastole_slice0_3d', 'lax_3ch_diastole_slice0_3d', 'LVM',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '24',\n",
    "            '--conv_x', '3', '3', '3',\n",
    "            '--conv_y', '3', '3', '3',\n",
    "            '--conv_z', '3', '3', '3',\n",
    "            '--dense_blocks', '24',\n",
    "            '--block_size', '4',\n",
    "            '--dense_layers', '512',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '2',\n",
    "            '--patience', '32',\n",
    "            '--epochs', '292',\n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '256',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '2',\n",
    "            '--num_workers', '4',\n",
    "            '--hidden_layer', 'concatenate_12',\n",
    "            '--model_file', './recipes_output/lax_2ch_3ch_diastole_paired_autoencoder_swish/lax_2ch_3ch_diastole_paired_autoencoder_swish.h5',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb.mri',\n",
    "            '--id', 'lax_2ch_3ch_diastole_paired_autoencoder_swish']\n",
    "args = parse_args()\n",
    "#plot_predictions(args)\n",
    "infer_hidden_layer_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_inference = './recipes_output/lax_2ch_3ch_diastole_paired_autoencoder_swish/hidden_inference_lax_2ch_3ch_diastole_paired_autoencoder_swish.tsv'\n",
    "df = pd.read_csv('/home/sam/ml/trained_models/lax_4ch_diastole_autoencode_leaky_converge/tensors_all_union.csv')\n",
    "df['21003_Age-when-attended-assessment-centre_2_0'].plot.hist(bins=30)\n",
    "\n",
    "df2 = pd.read_csv(hidden_inference, sep='\\t')\n",
    "df['fpath'] = pd.to_numeric(df['fpath'], errors='coerce')\n",
    "df2['sample_id'] = pd.to_numeric(df2['sample_id'], errors='coerce')\n",
    "#df.info()\n",
    "latent_df = pd.merge(df, df2, left_on='fpath', right_on='sample_id', how='inner')\n",
    "# #latent_df.info()\n",
    "# df3 = pd.read_csv('/home/sam/tsvs/ttn_disease.tsv', sep='\\t')\n",
    "# df4 = pd.read_csv('/home/sam/csvs/has_exome.csv')\n",
    "# latent_df = pd.merge(df3, latent_df, left_on='sample_id', right_on='sample_id', how='right')\n",
    "# \n",
    "# print(latent_df['has_ttntv'].value_counts())\n",
    "latent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps*5)\n",
    "print(list(test_data.keys()))\n",
    "\n",
    "preds = overparameterized_model.predict(test_data)\n",
    "print([p.shape for p in preds])\n",
    "print([tm.name for tm in args.tensor_maps_out])\n",
    "print(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4h.plots import _plot_reconstruction\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_lax_2ch_diastole_slice0_3d_continuous'], preds[0], out_path, test_paths, num_samples=2)\n",
    "from ml4h.explorations import predictions_to_pngs\n",
    "predictions_to_pngs(preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, etm in enumerate(encoders):\n",
    "    embed = encoders[etm].predict(test_data[etm.input_name()])\n",
    "    double = np.tile(embed, 2)\n",
    "    print(f'embed shape: {embed.shape} double shape: {double.shape}')\n",
    "    for dtm in decoders:\n",
    "        predictions = decoders[dtm].predict(double)\n",
    "        print(f'prediction shape: {predictions.shape}')\n",
    "        out_path = os.path.join(args.output_folder, args.id, f'decoding_{dtm.name}_from_{etm.name}/')\n",
    "        if not os.path.exists(os.path.dirname(out_path)):\n",
    "            os.makedirs(os.path.dirname(out_path))\n",
    "        _plot_reconstruction(dtm, test_data[dtm.input_name()], predictions.copy(), out_path, test_paths, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_on_matrix(matrix, pca_components):\n",
    "    pca = PCA()\n",
    "    pca.fit(matrix)\n",
    "    print(f'PCA explains {100*np.sum(pca.explained_variance_ratio_[:pca_components]):0.1f}% of variance with {pca_components} top PCA components.')\n",
    "    matrix_reduced = pca.transform(matrix)[:, :pca_components]\n",
    "    print(f'PCA reduces matrix shape:{matrix_reduced.shape} from matrix shape: {matrix.shape}')\n",
    "    plot_scree(pca_components, 100*pca.explained_variance_ratio_)\n",
    "    return pca, matrix_reduced\n",
    "\n",
    "def plot_scree(pca_components, percent_explained):\n",
    "    _ = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(len(percent_explained)), percent_explained, 'g.-', linewidth=1)\n",
    "    plt.axvline(x=pca_components, c='r', linewidth=3)\n",
    "    label = f'{np.sum(percent_explained[:pca_components]):0.1f}% of variance explained by top {pca_components} of {len(percent_explained)} components'\n",
    "    plt.text(pca_components+0.02*len(percent_explained), percent_explained[1], label)\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('% of Variance Explained by Each Component')\n",
    "    figure_path = f'./results/pca_{pca_components}_of_{len(percent_explained)}_testimonials.png'\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path)\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def directions_in_latent_space(stratify_column, stratify_thresh, split_column, split_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    strat_vector = hit_mean_vector - miss_mean_vector\n",
    "    \n",
    "    hit1 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    miss1 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    hit2 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss2 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss_mean_vector1 = np.mean(miss1, axis=0)\n",
    "    hit_mean_vector1 = np.mean(hit1, axis=0)\n",
    "    angle1 = angle_between(miss_mean_vector1, hit_mean_vector1)\n",
    "    miss_mean_vector2 = np.mean(miss2, axis=0)\n",
    "    hit_mean_vector2 = np.mean(hit2, axis=0)\n",
    "    angle2 = angle_between(miss_mean_vector2, hit_mean_vector2)\n",
    "    h1_vector = hit_mean_vector1-miss_mean_vector1\n",
    "    h2_vector = hit_mean_vector2-miss_mean_vector2\n",
    "    angle3 = angle_between(h1_vector, h2_vector)\n",
    "    angle4 = angle_between(strat_vector, h1_vector)\n",
    "    angle5 = angle_between(strat_vector, h2_vector)\n",
    "    print(f'\\n Between {stratify_column}, and splits: {split_column}\\n',\n",
    "          f'Angles: {angle1:.4f}, {angle2:.4f} \\n'\n",
    "          f'stratify threshold: {stratify_thresh}, split thresh: {split_thresh}, \\n'\n",
    "          f'hit_mean_vector2 shape {miss_mean_vector1.shape}, miss1:{hit_mean_vector2.shape} \\n'\n",
    "          f'Hit1 shape {hit1.shape}, miss1:{miss1.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Hit2 shape {hit2.shape}, miss2:{miss2.shape}\\n')\n",
    "\n",
    "def stratify_latent_space(stratify_column, stratify_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "    print(f'Angle between {stratify_column} and all others: {angle}, \\n'\n",
    "          f'Hit shape {hit.shape}, miss:{miss.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Distance: {np.linalg.norm(hit_mean_vector-miss_mean_vector):.3f}, Hit std {np.std(hit, axis=1).mean():.3f}, miss std:{np.std(miss, axis=1).mean():.3f}\\n')\n",
    "    \n",
    "def plot_pcs(sides, color_key):\n",
    "    f, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        colors = latent_df[color_key].to_numpy()\n",
    "        points = ax.scatter(matrix_reduce[:, i], matrix_reduce[:, i+1], c=colors)\n",
    "        f.colorbar(points, ax=ax)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 3500000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 1250000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ch2_encode = df2[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "ch3_encode = df2[latent_cols].to_numpy()\n",
    "sqr_diff = (ch2_encode - ch3_encode) * (ch2_encode - ch3_encode)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ch2_encode[:5,:5]} \\n{ch3_encode[:5,:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_random = np.random.random((4452, 256))\n",
    "ch3_random = np.random.random((4452, 256))\n",
    "sqr_diff = (ch2_random - ch3_random) * (ch2_random - ch3_random)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ch2_encode = df2[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{98+i}' for i in range(latent_dimension)]\n",
    "ch3_encode = df2[latent_cols].to_numpy()\n",
    "sqr_diff = (ch2_encode - ch3_encode) * (ch2_encode - ch3_encode)\n",
    "print(sqr_diff.shape)\n",
    "sum_sqr_diff = np.mean(np.sqrt(np.sum(sqr_diff, axis=-1)))\n",
    "print(sum_sqr_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
