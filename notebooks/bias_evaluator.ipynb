{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import h5py\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import hashlib\n",
    "import operator\n",
    "from textwrap import wrap\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from itertools import islice, product\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from typing import Iterable, DefaultDict, Dict, List, Tuple, Optional, Callable\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n",
    "from biosppy.signals import ecg\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy import stats\n",
    "\n",
    "from ml4cvd.TensorMap import TensorMap\n",
    "from ml4cvd.metrics import concordance_index, coefficient_of_determination\n",
    "from ml4cvd.defines import IMAGE_EXT, JOIN_CHAR, PDF_EXT, TENSOR_EXT, ECG_REST_LEADS, PARTNERS_DATETIME_FORMAT, PARTNERS_DATE_FORMAT\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Need this to write images from the GSA servers.  Order matters:\n",
    "import matplotlib.pyplot as plt  # First import matplotlib, then use Agg, then import plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "\n",
    "RECALL_LABEL = 'Recall | Sensitivity | True Positive Rate | TP/(TP+FN)'\n",
    "FALLOUT_LABEL = 'Fallout | 1 - Specificity | False Positive Rate | FP/(FP+TN)'\n",
    "PRECISION_LABEL = 'Precision | Positive Predictive Value | TP/(TP+FP)'\n",
    "\n",
    "SUBPLOT_SIZE = 8\n",
    "\n",
    "COLOR_ARRAY = [\n",
    "    'tan', 'indigo', 'cyan', 'pink', 'purple', 'blue', 'chartreuse', 'deepskyblue', 'green', 'salmon', 'aqua', 'magenta', 'aquamarine', 'red',\n",
    "    'coral', 'tomato', 'grey', 'black', 'maroon', 'hotpink', 'steelblue', 'orange', 'papayawhip', 'wheat', 'chocolate', 'darkkhaki', 'gold',\n",
    "    'orange', 'crimson', 'slategray', 'violet', 'cadetblue', 'midnightblue', 'darkorchid', 'paleturquoise', 'plum', 'lime',\n",
    "    'teal', 'peru', 'silver', 'darkgreen', 'rosybrown', 'firebrick', 'saddlebrown', 'dodgerblue', 'orangered',\n",
    "]\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D\n",
    "\n",
    "\n",
    "from ml4cvd.defines import StorageType\n",
    "from ml4cvd.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap, Interpretation\n",
    "from ml4cvd.tensor_generators import test_train_valid_tensor_generators, big_batch_from_minibatch_generator\n",
    "from ml4cvd.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model, train_model_from_generators, make_hidden_layer_model\n",
    "from ml4cvd.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps, _predict_and_evaluate\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Constants\n",
    "HD5_FOLDER = '/mnt/disks/ecg-rest-38k-tensors/2020-03-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 16:01:54,964 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/ecg_rest_bias/log_2020-06-16_16-01_0.log.\n",
      "2020-06-16 16:01:54,966 - arguments:405 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors /mnt/disks/ecg-rest-38k-tensors/2020-03-14/ --input_tensors ecg_rest genetic_caucasian --output_tensors poor_data_quality --protected_tensors sex genetic_caucasian age_0 --training_steps 96 --validation_steps 24 --test_steps 24 --epochs 6 --batch_size 24 --id ecg_rest_bias\n",
      "\n",
      "2020-06-16 16:01:54,967 - arguments:406 - INFO - Total TensorMaps: 624 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=24, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_x=3, conv_y=3, conv_z=2, debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', dropout=0.0, eager=False, embed_visualization=None, epochs=6, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='ecg_rest_bias', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['ecg_rest', 'genetic_caucasian'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix=None, learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./recipes_output/', output_tensors=['poor_data_quality'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=['sex', 'genetic_caucasian', 'age_0'], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, t=48, tensor_maps_in=[TensorMap(strip, (5000, 12), continuous), TensorMap(Genetic-ethnic-grouping_Caucasian_0_0, (2,), categorical)], tensor_maps_out=[TensorMap(poor_data_quality, (2,), categorical)], tensor_maps_protected=[TensorMap(Sex_Male_0_0, (2,), categorical), TensorMap(Genetic-ethnic-grouping_Caucasian_0_0, (2,), categorical), TensorMap(21003_Age-when-attended-assessment-centre_0_0, (1,), continuous)], tensors='/mnt/disks/ecg-rest-38k-tensors/2020-03-14/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=24, time_tensor='partners_ecg_datetime', train_csv=None, training_steps=96, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=24, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/')\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'ecg_rest', 'genetic_caucasian',\n",
    "            '--output_tensors', 'poor_data_quality',\n",
    "            '--protected_tensors', 'sex', 'genetic_caucasian', 'age_0',\n",
    "            '--training_steps', '96',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '24',\n",
    "            '--epochs', '6',\n",
    "            '--batch_size', '24',\n",
    "            '--id', 'ecg_rest_bias'\n",
    "           ]\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 16:01:58,960 - tensor_generators:653 - INFO - Found 25955 train, 7575 validation, and 3710 testing tensors at: /mnt/disks/ecg-rest-38k-tensors/2020-03-14/\n",
      "2020-06-16 16:01:58,979 - tensor_generators:238 - INFO - Stopped 4 workers. \n"
     ]
    }
   ],
   "source": [
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_strip_continuous (InputLa [(None, 5000, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 5000, 32)     1184        input_strip_continuous[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5000, 32)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 2500, 32)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2500, 32)     3104        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2500, 32)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2500, 64)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2500, 32)     6176        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 2500, 32)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2500, 96)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 2500, 32)     9248        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2500, 32)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1250, 32)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1250, 24)     2328        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1250, 24)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 1250, 56)     0           max_pooling1d_5[0][0]            \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1250, 24)     4056        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1250, 24)     0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 1250, 80)     0           max_pooling1d_5[0][0]            \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1250, 24)     5784        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1250, 24)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 625, 24)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 625, 16)      1168        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 625, 16)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 625, 40)      0           max_pooling1d_6[0][0]            \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 625, 16)      1936        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 625, 16)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 625, 56)      0           max_pooling1d_6[0][0]            \n",
      "                                                                 activation_23[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_Genetic-ethnic-grouping_C [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 625, 16)      2704        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           96          input_Genetic-ethnic-grouping_Cau\n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 625, 16)      0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10000)        0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 10032)        0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           160528      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1088        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_poor_data_quality_catego (None, 2)            130         activation_28[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 199,530\n",
      "Trainable params: 199,530\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 16:01:59,763 - tensor_generators:151 - INFO - Started 4 train workers with cache size 0.875 GB.\n",
      "2020-06-16 16:02:00,588 - tensor_generators:151 - INFO - Started 2 validation workers with cache size 0.875 GB.\n",
      "Train for 96 steps, validate for 24 steps\n",
      "Epoch 1/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1142 - categorical_accuracy: 0.8237 - no_poor_data_quality_precision: 0.9727 - Poor_data_quality_precision: 0.0159 - no_poor_data_quality_recall: 0.8394 - Poor_data_quality_recall: 0.0474\n",
      "Epoch 00001: val_loss improved from inf to 0.15283, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 25s 257ms/step - loss: 0.1148 - categorical_accuracy: 0.8251 - no_poor_data_quality_precision: 0.9726 - Poor_data_quality_precision: 0.0157 - no_poor_data_quality_recall: 0.8411 - Poor_data_quality_recall: 0.0469 - val_loss: 0.1528 - val_categorical_accuracy: 0.9618 - val_no_poor_data_quality_precision: 0.9618 - val_Poor_data_quality_precision: 0.0000e+00 - val_no_poor_data_quality_recall: 1.0000 - val_Poor_data_quality_recall: 0.0000e+00\n",
      "Epoch 2/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1333 - categorical_accuracy: 0.8127 - no_poor_data_quality_precision: 0.9746 - Poor_data_quality_precision: 0.0842 - no_poor_data_quality_recall: 0.8305 - Poor_data_quality_recall: 0.1754\n",
      "Epoch 00002: val_loss improved from 0.15283 to 0.13339, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 22s 227ms/step - loss: 0.1324 - categorical_accuracy: 0.8142 - no_poor_data_quality_precision: 0.9749 - Poor_data_quality_precision: 0.0834 - no_poor_data_quality_recall: 0.8318 - Poor_data_quality_recall: 0.1736 - val_loss: 0.1334 - val_categorical_accuracy: 0.9601 - val_no_poor_data_quality_precision: 0.9734 - val_Poor_data_quality_precision: 0.1875 - val_no_poor_data_quality_recall: 0.9854 - val_Poor_data_quality_recall: 0.2083\n",
      "Epoch 3/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1216 - categorical_accuracy: 0.7912 - no_poor_data_quality_precision: 0.9819 - Poor_data_quality_precision: 0.0704 - no_poor_data_quality_recall: 0.8002 - Poor_data_quality_recall: 0.2754\n",
      "Epoch 00003: val_loss improved from 0.13339 to 0.10880, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 23s 235ms/step - loss: 0.1215 - categorical_accuracy: 0.7917 - no_poor_data_quality_precision: 0.9821 - Poor_data_quality_precision: 0.0718 - no_poor_data_quality_recall: 0.8004 - Poor_data_quality_recall: 0.2830 - val_loss: 0.1088 - val_categorical_accuracy: 0.8819 - val_no_poor_data_quality_precision: 0.9818 - val_Poor_data_quality_precision: 0.1076 - val_no_poor_data_quality_recall: 0.8941 - val_Poor_data_quality_recall: 0.2639\n",
      "Epoch 4/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1042 - categorical_accuracy: 0.7965 - no_poor_data_quality_precision: 0.9850 - Poor_data_quality_precision: 0.1159 - no_poor_data_quality_recall: 0.8027 - Poor_data_quality_recall: 0.3281\n",
      "Epoch 00004: val_loss improved from 0.10880 to 0.10255, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 22s 233ms/step - loss: 0.1038 - categorical_accuracy: 0.7973 - no_poor_data_quality_precision: 0.9851 - Poor_data_quality_precision: 0.1173 - no_poor_data_quality_recall: 0.8034 - Poor_data_quality_recall: 0.3351 - val_loss: 0.1025 - val_categorical_accuracy: 0.8125 - val_no_poor_data_quality_precision: 0.9835 - val_Poor_data_quality_precision: 0.0971 - val_no_poor_data_quality_recall: 0.8210 - val_Poor_data_quality_recall: 0.2917\n",
      "Epoch 5/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1069 - categorical_accuracy: 0.7535 - no_poor_data_quality_precision: 0.9852 - Poor_data_quality_precision: 0.0881 - no_poor_data_quality_recall: 0.7560 - Poor_data_quality_recall: 0.3930\n",
      "Epoch 00005: val_loss did not improve from 0.10255\n",
      "96/96 [==============================] - 22s 231ms/step - loss: 0.1081 - categorical_accuracy: 0.7500 - no_poor_data_quality_precision: 0.9844 - Poor_data_quality_precision: 0.0872 - no_poor_data_quality_recall: 0.7527 - Poor_data_quality_recall: 0.3889 - val_loss: 0.1159 - val_categorical_accuracy: 0.5556 - val_no_poor_data_quality_precision: 0.9841 - val_Poor_data_quality_precision: 0.0467 - val_no_poor_data_quality_recall: 0.5512 - val_Poor_data_quality_recall: 0.3958\n",
      "Epoch 6/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0976 - categorical_accuracy: 0.8101 - no_poor_data_quality_precision: 0.9876 - Poor_data_quality_precision: 0.1467 - no_poor_data_quality_recall: 0.8136 - Poor_data_quality_recall: 0.4193\n",
      "Epoch 00006: val_loss improved from 0.10255 to 0.09119, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 23s 238ms/step - loss: 0.0971 - categorical_accuracy: 0.8099 - no_poor_data_quality_precision: 0.9878 - Poor_data_quality_precision: 0.1452 - no_poor_data_quality_recall: 0.8134 - Poor_data_quality_recall: 0.4149 - val_loss: 0.0912 - val_categorical_accuracy: 0.8906 - val_no_poor_data_quality_precision: 0.9900 - val_Poor_data_quality_precision: 0.1986 - val_no_poor_data_quality_recall: 0.8954 - val_Poor_data_quality_recall: 0.4167\n",
      "2020-06-16 16:04:18,393 - tensor_generators:238 - INFO - Stopped 4 workers. \n",
      "2020-06-16 16:04:18,403 - tensor_generators:238 - INFO - Stopped 2 workers. \n",
      "2020-06-16 16:04:18,404 - models:1092 - INFO - Model weights saved at: ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "2020-06-16 16:04:20,056 - plots:214 - INFO - Saved learning curves at:./recipes_output/ecg_rest_bias/metric_history_ecg_rest_bias.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f04af6a4588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1728x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "train_model_from_generators(model, generate_train, generate_valid, args.training_steps, args.validation_steps, \n",
    "                            args.batch_size, args.epochs, args.patience, args.output_folder, args.id, \n",
    "                            args.inspect_model, args.inspect_show_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(\n",
    "    tm: TensorMap, y_predictions: np.ndarray, y_truth: np.ndarray, protected: Dict[TensorMap, np.ndarray], title: str, folder: str, test_paths: List[str] = None,\n",
    "    max_melt: int = 150000, rocs: List[Tuple[np.ndarray, np.ndarray, Dict[str, int]]] = [],\n",
    "    scatters: List[Tuple[np.ndarray, np.ndarray, str, List[str]]] = [],\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\" Evaluate predictions for a given TensorMap with truth data and plot the appropriate metrics.\n",
    "    Accumulates data in the rocs and scatters lists to facilitate subplotting.\n",
    "\n",
    "    :param tm: The TensorMap predictions to evaluate\n",
    "    :param y_predictions: The predictions\n",
    "    :param y_truth: The truth\n",
    "    :param title: A title for the plots\n",
    "    :param folder: The folder to save the plots at\n",
    "    :param test_paths: The tensor paths that were predicted\n",
    "    :param max_melt: For multi-dimensional prediction the maximum number of prediction to allow in the flattened array\n",
    "    :param protected: TensorMaps and tensors sensitive to bias\n",
    "    :param rocs: (output) List of Tuples which are inputs for ROC curve plotting to allow subplotting downstream\n",
    "    :param scatters: (output) List of Tuples which are inputs for scatter plots to allow subplotting downstream\n",
    "    :return: Dictionary of performance metrics with string keys for labels and float values\n",
    "    \"\"\"\n",
    "    performance_metrics = {}\n",
    "    if tm.is_categorical() and tm.axes() == 1:\n",
    "        logging.info(f\"For tm:{tm.name} with channel map:{tm.channel_map} examples:{y_predictions.shape[0]}\")\n",
    "        logging.info(f\"\\nSum Truth:{np.sum(y_truth, axis=0)} \\nSum pred :{np.sum(y_predictions, axis=0)}\")\n",
    "        performance_metrics.update(subplot_roc_per_class(y_predictions, y_truth, tm.channel_map, protected, \n",
    "                                                      title, folder))\n",
    "        rocs.append((y_predictions, y_truth, tm.channel_map))\n",
    "\n",
    "    return performance_metrics\n",
    "\n",
    "\n",
    "def get_fpr_tpr_roc_pred(y_pred, test_truth, labels):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for k in labels:\n",
    "        cur_idx = labels[k]\n",
    "        aser = roc_curve(test_truth[:, cur_idx], y_pred[:, cur_idx])\n",
    "        fpr[labels[k]], tpr[labels[k]], _ = aser\n",
    "        roc_auc[labels[k]] = auc(fpr[labels[k]], tpr[labels[k]])\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "def _hash_string_to_color(string):\n",
    "    \"\"\"Hash a string to color (using hashlib and not the built-in hash for consistency between runs)\"\"\"\n",
    "    return COLOR_ARRAY[int(hashlib.sha1(string.encode('utf-8')).hexdigest(), 16) % len(COLOR_ARRAY)]\n",
    "\n",
    "\n",
    "def _text_on_plot(axes, x, y, text, alpha=0.8, background='white'):\n",
    "    t = axes.text(x, y, text)\n",
    "    t.set_bbox({'facecolor': background, 'alpha': alpha, 'edgecolor': background})\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def new_predict_and_evaluate(model, test_data, test_labels, tensor_maps_in, tensor_maps_out, \n",
    "                             tensor_maps_protected, batch_size, hidden_layer, plot_path, \n",
    "                             test_paths, embed_visualization, alpha):\n",
    "    layer_names = [layer.name for layer in model.layers]\n",
    "    performance_metrics = {}\n",
    "    scatters = []\n",
    "    rocs = []\n",
    "    \n",
    "    protected_data = {tm: test_labels[tm.output_name()] for tm in tensor_maps_protected}\n",
    "    print(f'tm prot {len(protected_data)}')\n",
    "    \n",
    "    y_predictions = model.predict(test_data, batch_size=batch_size)\n",
    "    for y, tm in zip(y_predictions, tensor_maps_out):\n",
    "        if tm.output_name() not in layer_names:\n",
    "            continue\n",
    "        if not isinstance(y_predictions, list):  # When models have a single output model.predict returns a ndarray otherwise it returns a list\n",
    "            y = y_predictions\n",
    "        y_truth = np.array(test_labels[tm.output_name()])\n",
    "        performance_metrics.update(evaluate_predictions(tm, y, y_truth, protected_data, tm.name, plot_path, \n",
    "                                                        test_paths, rocs=rocs, scatters=scatters))\n",
    "        if tm.is_language():\n",
    "            sample_from_language_model(tensor_maps_in, tm, model, test_data, max_samples=16)\n",
    "\n",
    "    if len(rocs) > 1:\n",
    "        subplot_rocs(rocs, plot_path)\n",
    "    if len(scatters) > 1:\n",
    "        subplot_scatters(scatters, plot_path)\n",
    "\n",
    "    test_labels_1d = {tm: np.array(test_labels[tm.output_name()]) for tm in tensor_maps_out if tm.output_name() in test_labels}\n",
    "    if embed_visualization == \"tsne\":\n",
    "        _tsne_wrapper(model, hidden_layer, alpha, plot_path, test_paths, test_labels_1d, test_data=test_data, tensor_maps_in=tensor_maps_in, batch_size=batch_size)\n",
    "\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_roc_per_class(prediction, truth, labels, protected, title, prefix='./figures/'):\n",
    "    lw = 2\n",
    "    col = 0\n",
    "    row = 1\n",
    "    labels_to_areas = {}\n",
    "    true_sums = np.sum(truth, axis=0)\n",
    "    total_plots = len(protected) + 1\n",
    "    cols = max(2, int(math.ceil(math.sqrt(total_plots))))\n",
    "    rows = max(2, int(math.ceil(total_plots / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*SUBPLOT_SIZE, rows*SUBPLOT_SIZE))\n",
    "    fpr, tpr, roc_auc = get_fpr_tpr_roc_pred(prediction, truth, labels)\n",
    "    \n",
    "    for p in protected:\n",
    "        print(f'\\n name {p.name} truth shape {truth.shape} IN ROCCCC {p.name} and {p.shape} and {protected[p].shape}')\n",
    "        \n",
    "        axes[row, col].plot([0, 1], [0, 1], 'k:', lw=0.5)\n",
    "        axes[row, col].set_title(f'Protected {p.name}')\n",
    "        for key in labels:    \n",
    "            if p.is_categorical():\n",
    "                idx2key = {v: k for k, v in p.channel_map.items()}\n",
    "                protected_indexes = protected[p][:, 0] == 1\n",
    "                print(f'\\n\\n protected_indexes shape {protected_indexes.shape}')\n",
    "\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                            truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} n={np.sum(protected_indexes):.0f}'\n",
    "\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "            elif p.is_continuous():\n",
    "                threshold = np.median(protected[p])\n",
    "                protected_indexes = (protected[p] > threshold)[:, 0]\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                                truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} Highest  n={np.sum(protected_indexes):.0f}'\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "                print(f'\\n\\n median {threshold} protected_indexes shape {protected[p].shape}')                \n",
    "                axes[row, col].set_xlim([0.0, 1.0])\n",
    "        axes[row, col].set_ylim([-0.02, 1.03])\n",
    "        axes[row, col].set_ylabel(RECALL_LABEL)\n",
    "        axes[row, col].set_xlabel(FALLOUT_LABEL)\n",
    "        axes[row, col].legend(loc='lower right')\n",
    "        row += 1\n",
    "        if row == rows:\n",
    "            row = 0\n",
    "            col += 1\n",
    "            if col >= cols:\n",
    "                break\n",
    "                    \n",
    "    for key in labels:\n",
    "        labels_to_areas[key] = roc_auc[labels[key]]\n",
    "        if 'no_' in key and len(labels) == 2:\n",
    "            continue\n",
    "        color = _hash_string_to_color(key)\n",
    "        label_text = f'{key} area: {roc_auc[labels[key]]:.3f} n={true_sums[labels[key]]:.0f}'\n",
    "        axes[0, 0].plot(fpr[labels[key]], tpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "        logging.info(f'ROC Label {label_text} Truth shape {truth.shape}, true sums {true_sums}')\n",
    "\n",
    "    axes[0, 0].set_title(f'ROC {title} n={truth.shape[0]:.0f}\\n')\n",
    "    axes[0, 0].legend(loc='lower right')\n",
    "    figure_path = os.path.join(prefix, 'per_class_roc_' + title + IMAGE_EXT)\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    logging.info(f\"Saved ROC curve at: {figure_path} with {len(protected)} protected TensorMaps.\")\n",
    "    return labels_to_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-16 16:04:20,417 - tensor_generators:151 - INFO - Started 4 test workers with cache size 0.000 GB.\n",
      "2020-06-16 16:04:26,323 - tensor_generators:504 - INFO - Made a big batch of tensors with key:input_strip_continuous and shape:(576, 5000, 12).\n",
      "2020-06-16 16:04:26,324 - tensor_generators:504 - INFO - Made a big batch of tensors with key:input_Genetic-ethnic-grouping_Caucasian_0_0_categorical and shape:(576, 2).\n",
      "2020-06-16 16:04:26,328 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_poor_data_quality_categorical and shape:(576, 2).\n",
      "2020-06-16 16:04:26,333 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_Sex_Male_0_0_categorical and shape:(576, 2).\n",
      "2020-06-16 16:04:26,334 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_Genetic-ethnic-grouping_Caucasian_0_0_categorical and shape:(576, 2).\n",
      "2020-06-16 16:04:26,336 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_21003_Age-when-attended-assessment-centre_0_0_continuous and shape:(576, 1).\n",
      "tm prot 3\n",
      "2020-06-16 16:04:27,545 - <ipython-input-14-185d3acdf7b4>:23 - INFO - For tm:poor_data_quality with channel map:{'no_poor_data_quality': 0, 'Poor data quality': 1} examples:576\n",
      "2020-06-16 16:04:27,550 - <ipython-input-14-185d3acdf7b4>:24 - INFO - \n",
      "Sum Truth:[557.  19.] \n",
      "Sum pred :[424.26706 151.73296]\n",
      "\n",
      " name Sex_Male_0_0 truth shape (576, 2) IN ROCCCC Sex_Male_0_0 and (2,) and (576, 2)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      " name Genetic-ethnic-grouping_Caucasian_0_0 truth shape (576, 2) IN ROCCCC Genetic-ethnic-grouping_Caucasian_0_0 and (2,) and (576, 2)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      " name 21003_Age-when-attended-assessment-centre_0_0 truth shape (576, 2) IN ROCCCC 21003_Age-when-attended-assessment-centre_0_0 and (1,) and (576, 1)\n",
      "\n",
      "\n",
      " median -0.18881021440029144 protected_indexes shape (576, 1)\n",
      "\n",
      "\n",
      " median -0.18881021440029144 protected_indexes shape (576, 1)\n",
      "2020-06-16 16:04:27,716 - <ipython-input-15-57fad4f78ecf>:58 - INFO - ROC Label Poor data quality area: 0.873 n=19 Truth shape (576, 2), true sums [557.  19.]\n",
      "2020-06-16 16:04:29,364 - <ipython-input-15-57fad4f78ecf>:67 - INFO - Saved ROC curve at: ./recipes_output/ecg_rest_bias/per_class_roc_poor_data_quality.png with 3 protected TensorMaps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no_poor_data_quality': 0.8732873476329963,\n",
       " 'Poor data quality': 0.8732873476329962}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "new_predict_and_evaluate(model, test_data, test_labels, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                      args.tensor_maps_protected, args.batch_size, args.hidden_layer, out_path, \n",
    "                      test_paths, args.embed_visualization, args.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
