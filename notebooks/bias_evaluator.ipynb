{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import h5py\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import hashlib\n",
    "import operator\n",
    "from textwrap import wrap\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from itertools import islice, product\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from typing import Iterable, DefaultDict, Dict, List, Tuple, Optional, Callable\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n",
    "from biosppy.signals import ecg\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy import stats\n",
    "\n",
    "from ml4cvd.TensorMap import TensorMap\n",
    "from ml4cvd.metrics import concordance_index, coefficient_of_determination\n",
    "from ml4cvd.defines import IMAGE_EXT, JOIN_CHAR, PDF_EXT, TENSOR_EXT, ECG_REST_LEADS, PARTNERS_DATETIME_FORMAT, PARTNERS_DATE_FORMAT\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Need this to write images from the GSA servers.  Order matters:\n",
    "import matplotlib.pyplot as plt  # First import matplotlib, then use Agg, then import plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "\n",
    "RECALL_LABEL = 'Recall | Sensitivity | True Positive Rate | TP/(TP+FN)'\n",
    "FALLOUT_LABEL = 'Fallout | 1 - Specificity | False Positive Rate | FP/(FP+TN)'\n",
    "PRECISION_LABEL = 'Precision | Positive Predictive Value | TP/(TP+FP)'\n",
    "\n",
    "SUBPLOT_SIZE = 8\n",
    "\n",
    "COLOR_ARRAY = [\n",
    "    'tan', 'indigo', 'cyan', 'pink', 'purple', 'blue', 'chartreuse', 'deepskyblue', 'green', 'salmon', 'aqua', 'magenta', 'aquamarine', 'red',\n",
    "    'coral', 'tomato', 'grey', 'black', 'maroon', 'hotpink', 'steelblue', 'orange', 'papayawhip', 'wheat', 'chocolate', 'darkkhaki', 'gold',\n",
    "    'orange', 'crimson', 'slategray', 'violet', 'cadetblue', 'midnightblue', 'darkorchid', 'paleturquoise', 'plum', 'lime',\n",
    "    'teal', 'peru', 'silver', 'darkgreen', 'rosybrown', 'firebrick', 'saddlebrown', 'dodgerblue', 'orangered',\n",
    "]\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D\n",
    "\n",
    "\n",
    "from ml4cvd.defines import StorageType\n",
    "from ml4cvd.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap, Interpretation\n",
    "from ml4cvd.tensor_generators import test_train_valid_tensor_generators, big_batch_from_minibatch_generator\n",
    "from ml4cvd.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model, train_model_from_generators, make_hidden_layer_model\n",
    "from ml4cvd.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps, _predict_and_evaluate\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Constants\n",
    "HD5_FOLDER = '/mnt/disks/ecg-rest-38k-tensors/2020-03-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:27:44,353 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/ecg_rest_bias/log_2020-07-14_13-27_0.log.\n",
      "2020-07-14 13:27:44,355 - arguments:418 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors /mnt/disks/ecg-rest-38k-tensors/2020-03-14/ --input_tensors ecg_rest --output_tensors poor_data_quality --protected_tensors sex genetic_caucasian age_0 --training_steps 96 --validation_steps 24 --test_steps 24 --epochs 6 --batch_size 24 --id ecg_rest_bias\n",
      "\n",
      "2020-07-14 13:27:44,356 - arguments:419 - INFO - Total TensorMaps: 6534 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=24, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_x=[3], conv_y=[3], conv_z=[2], debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', dropout=0.0, eager=False, embed_visualization=None, epochs=6, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='ecg_rest_bias', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['ecg_rest'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix=None, learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./recipes_output/', output_tensors=['poor_data_quality'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=['sex', 'genetic_caucasian', 'age_0'], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, t=48, tensor_maps_in=[TensorMap(strip, (5000, 12), continuous)], tensor_maps_out=[TensorMap(poor_data_quality, (2,), categorical)], tensor_maps_protected=[TensorMap(Sex_Male_0_0, (2,), categorical), TensorMap(Genetic-ethnic-grouping_Caucasian_0_0, (2,), categorical), TensorMap(21003_Age-when-attended-assessment-centre_0_0, (1,), continuous)], tensors='/mnt/disks/ecg-rest-38k-tensors/2020-03-14/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=24, text_file=None, text_one_hot=False, text_window=32, time_tensor='partners_ecg_datetime', train_csv=None, training_steps=96, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=24, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/')\n"
     ]
    }
   ],
   "source": [
    "### classification task\n",
    "\n",
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'ecg_rest',\n",
    "            '--output_tensors', 'poor_data_quality',\n",
    "            '--protected_tensors', 'sex', 'genetic_caucasian', 'age_0',\n",
    "            '--training_steps', '96',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '24',\n",
    "            '--epochs', '6',\n",
    "            '--batch_size', '24',\n",
    "            '--id', 'ecg_rest_bias'\n",
    "           ]\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:15:11,631 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/ecg_rest_bias/log_2020-07-14_13-15_0.log.\n",
      "2020-07-14 13:15:11,633 - arguments:418 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors /mnt/disks/ecg-rest-38k-tensors/2020-03-14/ --input_tensors ecg_rest --output_tensors ventricular-rate --protected_tensors sex genetic_caucasian age_0 --training_steps 48 --validation_steps 24 --test_steps 24 --epochs 80 --batch_size 8 --id ecg_rest_bias --patience 24\n",
      "\n",
      "2020-07-14 13:15:11,635 - arguments:419 - INFO - Total TensorMaps: 586 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=8, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_x=[3], conv_y=[3], conv_z=[2], debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', dropout=0.0, eager=False, embed_visualization=None, epochs=80, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='ecg_rest_bias', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['ecg_rest'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix=None, learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./recipes_output/', output_tensors=['ventricular-rate'], padding='same', patience=24, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=['sex', 'genetic_caucasian', 'age_0'], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, t=48, tensor_maps_in=[TensorMap(strip, (5000, 12), continuous)], tensor_maps_out=[TensorMap(VentricularRate, (1,), continuous)], tensor_maps_protected=[TensorMap(Sex_Male_0_0, (2,), categorical), TensorMap(Genetic-ethnic-grouping_Caucasian_0_0, (2,), categorical), TensorMap(21003_Age-when-attended-assessment-centre_0_0, (1,), continuous)], tensors='/mnt/disks/ecg-rest-38k-tensors/2020-03-14/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=24, text_file=None, text_one_hot=False, text_window=32, time_tensor='partners_ecg_datetime', train_csv=None, training_steps=48, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=24, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/')\n"
     ]
    }
   ],
   "source": [
    "### regression task\n",
    "\n",
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'ecg_rest',\n",
    "            '--output_tensors', 'ventricular-rate',\n",
    "            '--protected_tensors', 'sex', 'genetic_caucasian', 'age_0',\n",
    "            '--training_steps', '48',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '24',\n",
    "            '--epochs', '80',\n",
    "            '--batch_size', '8',\n",
    "            '--id', 'ecg_rest_bias',\n",
    "            '--patience', '24'\n",
    "           ]\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:27:55,257 - tensor_generators:651 - INFO - Found 25955 train, 7575 validation, and 3710 testing tensors at: /mnt/disks/ecg-rest-38k-tensors/2020-03-14/\n",
      "2020-07-14 13:27:55,283 - tensor_generators:238 - INFO - Stopped 4 workers. \n"
     ]
    }
   ],
   "source": [
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:27:55,332 - models:808 - WARNING - Number of x dimensions for convolutional kernel sizes (1) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-07-14 13:27:55,342 - models:808 - WARNING - Number of y dimensions for convolutional kernel sizes (1) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-07-14 13:27:55,344 - models:808 - WARNING - Number of z dimensions for convolutional kernel sizes (1) do not match number of convolutional layers/blocks (4), matching values to fit 4 convolutional layers/blocks.\n",
      "2020-07-14 13:27:55,345 - models:344 - INFO - Conv layer is <class 'tensorflow.python.keras.layers.convolutional.Conv1D'> and kernels [(3,)]\n",
      "2020-07-14 13:27:55,347 - models:346 - INFO -  Filters is 32 and kernel is (3,) at step 0\n",
      "2020-07-14 13:27:55,351 - models:358 - INFO - Residual Block Convolutional Layers (num_filters, kernel_size): [(32, (3,))]\n",
      "2020-07-14 13:27:55,365 - models:396 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(32, (3,)), (32, (3,)), (32, (3,))]\n",
      "2020-07-14 13:27:55,387 - models:396 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(24, (3,)), (24, (3,)), (24, (3,))]\n",
      "2020-07-14 13:27:55,392 - models:396 - INFO - Dense Block Convolutional Layers (num_filters, kernel_size): [(16, (3,)), (16, (3,)), (16, (3,))]\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_strip_continuous (InputLa [(None, 5000, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 5000, 32)     1184        input_strip_continuous[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5000, 32)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 2500, 32)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 2500, 32)     3104        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2500, 32)     0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 2500, 64)     0           max_pooling1d_12[0][0]           \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 2500, 32)     6176        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2500, 32)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 2500, 96)     0           max_pooling1d_12[0][0]           \n",
      "                                                                 activation_40[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 2500, 32)     9248        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2500, 32)     0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1250, 32)     0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1250, 24)     2328        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1250, 24)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 1250, 56)     0           max_pooling1d_13[0][0]           \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1250, 24)     4056        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1250, 24)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 1250, 80)     0           max_pooling1d_13[0][0]           \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1250, 24)     5784        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1250, 24)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 625, 24)      0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 625, 16)      1168        max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 625, 16)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 625, 40)      0           max_pooling1d_14[0][0]           \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 625, 16)      1936        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 625, 16)      0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 625, 56)      0           max_pooling1d_14[0][0]           \n",
      "                                                                 activation_46[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 625, 16)      2704        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 625, 16)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 10000)        0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           160016      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1088        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_poor_data_quality_catego (None, 2)            130         activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 198,922\n",
      "Trainable params: 198,922\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:27:56,027 - tensor_generators:151 - INFO - Started 3 train workers with cache size 0.875 GB.\n",
      "2020-07-14 13:27:56,591 - tensor_generators:151 - INFO - Started 1 validation workers with cache size 0.875 GB.\n",
      "Train for 96 steps, validate for 24 steps\n",
      "Epoch 1/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.8360 - no_poor_data_quality_precision: 0.9761 - Poor_data_quality_precision: 0.0986 - no_poor_data_quality_recall: 0.8522 - Poor_data_quality_recall: 0.2061\n",
      "Epoch 00001: val_loss improved from inf to 0.10291, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 25s 256ms/step - loss: 0.1289 - categorical_accuracy: 0.8377 - no_poor_data_quality_precision: 0.9763 - Poor_data_quality_precision: 0.0976 - no_poor_data_quality_recall: 0.8537 - Poor_data_quality_recall: 0.2040 - val_loss: 0.1029 - val_categorical_accuracy: 0.9792 - val_no_poor_data_quality_precision: 0.9808 - val_Poor_data_quality_precision: 0.0833 - val_no_poor_data_quality_recall: 0.9983 - val_Poor_data_quality_recall: 0.0625\n",
      "Epoch 2/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1370 - categorical_accuracy: 0.8456 - no_poor_data_quality_precision: 0.9758 - Poor_data_quality_precision: 0.1155 - no_poor_data_quality_recall: 0.8623 - Poor_data_quality_recall: 0.2667\n",
      "Epoch 00002: val_loss did not improve from 0.10291\n",
      "96/96 [==============================] - 19s 201ms/step - loss: 0.1375 - categorical_accuracy: 0.8411 - no_poor_data_quality_precision: 0.9761 - Poor_data_quality_precision: 0.1156 - no_poor_data_quality_recall: 0.8571 - Poor_data_quality_recall: 0.2743 - val_loss: 0.1266 - val_categorical_accuracy: 0.4826 - val_no_poor_data_quality_precision: 0.9888 - val_Poor_data_quality_precision: 0.0617 - val_no_poor_data_quality_recall: 0.4675 - val_Poor_data_quality_recall: 0.5625\n",
      "Epoch 3/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1211 - categorical_accuracy: 0.6684 - no_poor_data_quality_precision: 0.9866 - Poor_data_quality_precision: 0.0977 - no_poor_data_quality_recall: 0.6656 - Poor_data_quality_recall: 0.4632\n",
      "Epoch 00003: val_loss improved from 0.10291 to 0.09516, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 19s 203ms/step - loss: 0.1202 - categorical_accuracy: 0.6710 - no_poor_data_quality_precision: 0.9867 - Poor_data_quality_precision: 0.0966 - no_poor_data_quality_recall: 0.6682 - Poor_data_quality_recall: 0.4583 - val_loss: 0.0952 - val_categorical_accuracy: 0.8368 - val_no_poor_data_quality_precision: 0.9827 - val_Poor_data_quality_precision: 0.0913 - val_no_poor_data_quality_recall: 0.8456 - val_Poor_data_quality_recall: 0.2986\n",
      "Epoch 4/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.6531 - no_poor_data_quality_precision: 0.9848 - Poor_data_quality_precision: 0.0883 - no_poor_data_quality_recall: 0.6505 - Poor_data_quality_recall: 0.4184\n",
      "Epoch 00004: val_loss did not improve from 0.09516\n",
      "96/96 [==============================] - 20s 204ms/step - loss: 0.1206 - categorical_accuracy: 0.6545 - no_poor_data_quality_precision: 0.9840 - Poor_data_quality_precision: 0.0874 - no_poor_data_quality_recall: 0.6527 - Poor_data_quality_recall: 0.4141 - val_loss: 0.1192 - val_categorical_accuracy: 0.8490 - val_no_poor_data_quality_precision: 0.9794 - val_Poor_data_quality_precision: 0.1299 - val_no_poor_data_quality_recall: 0.8611 - val_Poor_data_quality_recall: 0.3958\n",
      "Epoch 5/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0924 - categorical_accuracy: 0.7969 - no_poor_data_quality_precision: 0.9899 - Poor_data_quality_precision: 0.1141 - no_poor_data_quality_recall: 0.7982 - Poor_data_quality_recall: 0.3921\n",
      "Epoch 00005: val_loss did not improve from 0.09516\n",
      "96/96 [==============================] - 21s 214ms/step - loss: 0.0932 - categorical_accuracy: 0.7973 - no_poor_data_quality_precision: 0.9895 - Poor_data_quality_precision: 0.1156 - no_poor_data_quality_recall: 0.7989 - Poor_data_quality_recall: 0.3932 - val_loss: 0.1046 - val_categorical_accuracy: 0.8819 - val_no_poor_data_quality_precision: 0.9859 - val_Poor_data_quality_precision: 0.1437 - val_no_poor_data_quality_recall: 0.8906 - val_Poor_data_quality_recall: 0.3264\n",
      "Epoch 6/6\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0914 - categorical_accuracy: 0.7763 - no_poor_data_quality_precision: 0.9892 - Poor_data_quality_precision: 0.1097 - no_poor_data_quality_recall: 0.7789 - Poor_data_quality_recall: 0.3930\n",
      "Epoch 00006: val_loss improved from 0.09516 to 0.07868, saving model to ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "96/96 [==============================] - 19s 203ms/step - loss: 0.0912 - categorical_accuracy: 0.7743 - no_poor_data_quality_precision: 0.9893 - Poor_data_quality_precision: 0.1085 - no_poor_data_quality_recall: 0.7768 - Poor_data_quality_recall: 0.3889 - val_loss: 0.0787 - val_categorical_accuracy: 0.6840 - val_no_poor_data_quality_precision: 0.9979 - val_Poor_data_quality_precision: 0.0545 - val_no_poor_data_quality_recall: 0.6775 - val_Poor_data_quality_recall: 0.3750\n",
      "2020-07-14 13:30:00,684 - tensor_generators:238 - INFO - Stopped 3 workers. \n",
      "2020-07-14 13:30:00,698 - tensor_generators:238 - INFO - Stopped 1 workers. \n",
      "2020-07-14 13:30:00,699 - models:1126 - INFO - Model weights saved at: ./recipes_output/ecg_rest_bias/ecg_rest_bias.h5\n",
      "2020-07-14 13:30:02,224 - plots:215 - INFO - Saved learning curves at:./recipes_output/ecg_rest_bias/metric_history_ecg_rest_bias.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x7f899434cb38>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1728x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "train_model_from_generators(model, generate_train, generate_valid, args.training_steps, args.validation_steps, \n",
    "                            args.batch_size, args.epochs, args.patience, args.output_folder, args.id, \n",
    "                            args.inspect_model, args.inspect_show_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(\n",
    "    tm: TensorMap, y_predictions: np.ndarray, y_truth: np.ndarray, protected: Dict[TensorMap, np.ndarray], title: str, folder: str, test_paths: List[str] = None,\n",
    "    max_melt: int = 150000, rocs: List[Tuple[np.ndarray, np.ndarray, Dict[str, int]]] = [],\n",
    "    scatters: List[Tuple[np.ndarray, np.ndarray, str, List[str]]] = [],\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\" Evaluate predictions for a given TensorMap with truth data and plot the appropriate metrics.\n",
    "    Accumulates data in the rocs and scatters lists to facilitate subplotting.\n",
    "\n",
    "    :param tm: The TensorMap predictions to evaluate\n",
    "    :param y_predictions: The predictions\n",
    "    :param y_truth: The truth\n",
    "    :param title: A title for the plots\n",
    "    :param folder: The folder to save the plots at\n",
    "    :param test_paths: The tensor paths that were predicted\n",
    "    :param max_melt: For multi-dimensional prediction the maximum number of prediction to allow in the flattened array\n",
    "    :param protected: TensorMaps and tensors sensitive to bias\n",
    "    :param rocs: (output) List of Tuples which are inputs for ROC curve plotting to allow subplotting downstream\n",
    "    :param scatters: (output) List of Tuples which are inputs for scatter plots to allow subplotting downstream\n",
    "    :return: Dictionary of performance metrics with string keys for labels and float values\n",
    "    \"\"\"\n",
    "    performance_metrics = {}\n",
    "    if tm.is_categorical() and tm.axes() == 1:\n",
    "        logging.info(f\"For tm:{tm.name} with channel map:{tm.channel_map} examples:{y_predictions.shape[0]}\")\n",
    "        logging.info(f\"\\nSum Truth:{np.sum(y_truth, axis=0)} \\nSum pred :{np.sum(y_predictions, axis=0)}\")\n",
    "        performance_metrics.update(subplot_roc_per_class(y_predictions, y_truth, tm.channel_map, protected, \n",
    "                                                      title, folder))\n",
    "        rocs.append((y_predictions, y_truth, tm.channel_map))\n",
    "    elif tm.is_continuous() and tm.axes() ==1:\n",
    "        performance_metrics.update(subplot_pearson_per_class(y_predictions, y_truth, tm.channel_map, protected, \n",
    "                                                      title, folder))\n",
    "\n",
    "    return performance_metrics\n",
    "\n",
    "\n",
    "def get_fpr_tpr_roc_pred(y_pred, test_truth, labels):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for k in labels:\n",
    "        cur_idx = labels[k]\n",
    "        aser = roc_curve(test_truth[:, cur_idx], y_pred[:, cur_idx])\n",
    "        fpr[labels[k]], tpr[labels[k]], _ = aser\n",
    "        roc_auc[labels[k]] = auc(fpr[labels[k]], tpr[labels[k]])\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "def _hash_string_to_color(string):\n",
    "    \"\"\"Hash a string to color (using hashlib and not the built-in hash for consistency between runs)\"\"\"\n",
    "    return COLOR_ARRAY[int(hashlib.sha1(string.encode('utf-8')).hexdigest(), 16) % len(COLOR_ARRAY)]\n",
    "\n",
    "\n",
    "def _text_on_plot(axes, x, y, text, alpha=0.8, background='white'):\n",
    "    t = axes.text(x, y, text)\n",
    "    t.set_bbox({'facecolor': background, 'alpha': alpha, 'edgecolor': background})\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def new_predict_and_evaluate(model, test_data, test_labels, tensor_maps_in, tensor_maps_out, \n",
    "                             tensor_maps_protected, batch_size, hidden_layer, plot_path, \n",
    "                             test_paths, embed_visualization, alpha):\n",
    "    layer_names = [layer.name for layer in model.layers]\n",
    "    performance_metrics = {}\n",
    "    scatters = []\n",
    "    rocs = []\n",
    "    \n",
    "    protected_data = {tm: test_labels[tm.output_name()] for tm in tensor_maps_protected}\n",
    "    print(f'tm prot {len(protected_data)}')\n",
    "    \n",
    "    y_predictions = model.predict(test_data, batch_size=batch_size)\n",
    "    for y, tm in zip(y_predictions, tensor_maps_out):\n",
    "        if tm.output_name() not in layer_names:\n",
    "            continue\n",
    "        if not isinstance(y_predictions, list):  # When models have a single output model.predict returns a ndarray otherwise it returns a list\n",
    "            y = y_predictions\n",
    "        y_truth = np.array(test_labels[tm.output_name()])\n",
    "        performance_metrics.update(evaluate_predictions(tm, y, y_truth, protected_data, tm.name, plot_path, \n",
    "                                                        test_paths, rocs=rocs, scatters=scatters))\n",
    "        if tm.is_language():\n",
    "            sample_from_language_model(tensor_maps_in, tm, model, test_data, max_samples=16)\n",
    "\n",
    "    if len(rocs) > 1:\n",
    "        subplot_rocs(rocs, plot_path)\n",
    "    if len(scatters) > 1:\n",
    "        subplot_scatters(scatters, plot_path)\n",
    "\n",
    "    test_labels_1d = {tm: np.array(test_labels[tm.output_name()]) for tm in tensor_maps_out if tm.output_name() in test_labels}\n",
    "    if embed_visualization == \"tsne\":\n",
    "        _tsne_wrapper(model, hidden_layer, alpha, plot_path, test_paths, test_labels_1d, test_data=test_data, tensor_maps_in=tensor_maps_in, batch_size=batch_size)\n",
    "\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_roc_per_class(prediction, truth, labels, protected, title, prefix='./figures/'):\n",
    "    lw = 2\n",
    "    col = 0\n",
    "    row = 1\n",
    "    labels_to_areas = {}\n",
    "    true_sums = np.sum(truth, axis=0)\n",
    "    total_plots = len(protected) + 1\n",
    "    cols = max(2, int(math.ceil(math.sqrt(total_plots))))\n",
    "    rows = max(2, int(math.ceil(total_plots / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*SUBPLOT_SIZE, rows*SUBPLOT_SIZE))\n",
    "    fpr, tpr, roc_auc = get_fpr_tpr_roc_pred(prediction, truth, labels)\n",
    "    \n",
    "    for p in protected:\n",
    "        print(f'\\n name {p.name} truth shape {truth.shape} IN ROCCCC {p.name} and {p.shape} and {protected[p].shape}')\n",
    "        \n",
    "        axes[row, col].plot([0, 1], [0, 1], 'k:', lw=0.5)\n",
    "        axes[row, col].set_title(f'Protected {p.name}')\n",
    "        for key in labels:    \n",
    "            if p.is_categorical():\n",
    "                idx2key = {v: k for k, v in p.channel_map.items()}\n",
    "                protected_indexes = protected[p][:, 0] == 1\n",
    "                print(f'\\n\\n protected_indexes shape {protected_indexes.shape}')\n",
    "\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                            truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} n={np.sum(protected_indexes):.0f}'\n",
    "\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "            elif p.is_continuous():\n",
    "                threshold = np.median(protected[p])\n",
    "                protected_indexes = (protected[p] > threshold)[:, 0]\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                                truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} Highest  n={np.sum(protected_indexes):.0f}'\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "                print(f'\\n\\n median {threshold} protected_indexes shape {protected[p].shape}')                \n",
    "                axes[row, col].set_xlim([0.0, 1.0])\n",
    "        axes[row, col].set_ylim([-0.02, 1.03])\n",
    "        axes[row, col].set_ylabel(RECALL_LABEL)\n",
    "        axes[row, col].set_xlabel(FALLOUT_LABEL)\n",
    "        axes[row, col].legend(loc='lower right')\n",
    "        row += 1\n",
    "        if row == rows:\n",
    "            row = 0\n",
    "            col += 1\n",
    "            if col >= cols:\n",
    "                break\n",
    "                    \n",
    "    for key in labels:\n",
    "        labels_to_areas[key] = roc_auc[labels[key]]\n",
    "        if 'no_' in key and len(labels) == 2:\n",
    "            continue\n",
    "        color = _hash_string_to_color(key)\n",
    "        label_text = f'{key} area: {roc_auc[labels[key]]:.3f} n={true_sums[labels[key]]:.0f}'\n",
    "        axes[0, 0].plot(fpr[labels[key]], tpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "        logging.info(f'ROC Label {label_text} Truth shape {truth.shape}, true sums {true_sums}')\n",
    "\n",
    "    axes[0, 0].set_title(f'ROC {title} n={truth.shape[0]:.0f}\\n')\n",
    "    axes[0, 0].legend(loc='lower right')\n",
    "    figure_path = os.path.join(prefix, 'per_class_roc_' + title + IMAGE_EXT)\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    logging.info(f\"Saved ROC curve at: {figure_path} with {len(protected)} protected TensorMaps.\")\n",
    "    return labels_to_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_pearson_per_class(prediction, truth, labels, protected, title, prefix='./figures/'):\n",
    "    \n",
    "    ### labels are tm.channel_map. Looks like this: {'no_poor_data_quality': 0, 'Poor data quality': 1}\n",
    "    \n",
    "    lw = 2\n",
    "    col = 0\n",
    "    row = 1\n",
    "    alpha=0.5\n",
    "    labels_to_areas = {}\n",
    "    true_sums = np.sum(truth, axis=0)\n",
    "    total_plots = len(protected) + 1 \n",
    "    cols = max(2, int(math.ceil(math.sqrt(total_plots))))\n",
    "    rows = max(2, int(math.ceil(total_plots / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*SUBPLOT_SIZE, rows*SUBPLOT_SIZE))\n",
    "\n",
    "    for p in protected: \n",
    "\n",
    "        axes[row, col].plot([0, 1], [0, 1], 'k:', lw=0.5)\n",
    "        axes[row, col].set_title(f'Protected {p.name}')\n",
    "        for key in labels:    \n",
    "            if p.is_categorical():\n",
    "                idx2key = {v: k for k, v in p.channel_map.items()}\n",
    "                protected_indexes = protected[p][:, 0] == 1 \n",
    "                print(f'\\n\\n protected_indexes shape {protected_indexes.shape}')\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot([np.min(truth), np.max(truth)], [np.min(truth), np.max(truth)], linewidth=2)\n",
    "                axes[row, col].plot([np.min(prediction), np.max(prediction)], [np.min(prediction), np.max(prediction)], linewidth=4)\n",
    "                pearson = np.corrcoef(prediction[protected_indexes].flatten(), truth[protected_indexes].flatten())[1, 0]\n",
    "                big_r_squared = coefficient_of_determination(truth[protected_indexes], prediction[protected_indexes])\n",
    "                axes[row, col].scatter(prediction[protected_indexes], truth[protected_indexes], color=color, lw=lw,label=f'Pearson:{pearson:0.3f} r^2:{pearson*pearson:0.3f} R^2:{big_r_squared:0.3f} Highest n={np.sum(protected_indexes):.0f}', marker='.', alpha=alpha)\n",
    "\n",
    "\n",
    "            elif p.is_continuous(): #### top/bottom quantile\n",
    "                threshold = np.median(protected[p])\n",
    "                protected_indexes = (protected[p] > threshold)[:, 0]\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot([np.min(truth), np.max(truth)], [np.min(truth), np.max(truth)], linewidth=2)\n",
    "                axes[row, col].plot([np.min(prediction), np.max(prediction)], [np.min(prediction), np.max(prediction)], linewidth=4)\n",
    "                pearson = np.corrcoef(prediction[protected_indexes].flatten(), truth[protected_indexes].flatten())[1, 0]\n",
    "                big_r_squared = coefficient_of_determination(truth[protected_indexes], prediction[protected_indexes])\n",
    "                axes[row, col].scatter(prediction[protected_indexes], truth[protected_indexes], color=color, lw=lw,label=f'Pearson:{pearson:0.3f} r^2:{pearson*pearson:0.3f} R^2:{big_r_squared:0.3f} Highest n={np.sum(protected_indexes):.0f}', marker='.', alpha=alpha)\n",
    "\n",
    "\n",
    "\n",
    "                print(f'\\n\\n median {threshold} protected_indexes shape {protected[p].shape}')\n",
    "\n",
    "\n",
    "        axes[row, col].set_ylabel('Predictions')\n",
    "        axes[row, col].set_xlabel('Actual')\n",
    "        axes[row, col].legend(loc='lower right')\n",
    "        row += 1\n",
    "        if row == rows:\n",
    "            row = 0\n",
    "            col += 1\n",
    "            if col >= cols:\n",
    "                break\n",
    "\n",
    "            \n",
    "            \n",
    "    axes[0,0].plot([np.min(truth), np.max(truth)], [np.min(truth), np.max(truth)], linewidth=2)\n",
    "    axes[0,0].plot([np.min(prediction), np.max(prediction)], [np.min(prediction), np.max(prediction)], linewidth=4)\n",
    "    pearson = np.corrcoef(prediction.flatten(), truth.flatten())[1, 0]\n",
    "    big_r_squared = coefficient_of_determination(truth, prediction)  \n",
    "    label_text = f'Pearson:{pearson:0.3f} r^2:{pearson*pearson:0.3f} R^2:{big_r_squared:0.3f} n={truth.shape[0]:.0f}'\n",
    "    axes[0, 0].scatter(prediction, truth, color=color, lw=lw,label=label_text, marker='.', alpha=alpha)\n",
    "    axes[0, 0].legend(loc='lower right')\n",
    "    axes[0, 0].set_title(f'Pearson {title}')\n",
    "\n",
    "    figure_path = os.path.join(prefix, 'per_class_pearson_' + title + IMAGE_EXT)\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    logging.info(f\"Saved Pearson correlations at: {figure_path} with {len(protected)} protected TensorMaps.\")\n",
    "    return labels_to_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-14 13:35:45,919 - tensor_generators:151 - INFO - Started 4 test workers with cache size 0.000 GB.\n",
      "2020-07-14 13:35:52,071 - tensor_generators:504 - INFO - Made a big batch of tensors with key:input_strip_continuous and shape:(576, 5000, 12).\n",
      "2020-07-14 13:35:52,073 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_poor_data_quality_categorical and shape:(576, 2).\n",
      "2020-07-14 13:35:52,075 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_Sex_Male_0_0_categorical and shape:(576, 2).\n",
      "2020-07-14 13:35:52,076 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_Genetic-ethnic-grouping_Caucasian_0_0_categorical and shape:(576, 2).\n",
      "2020-07-14 13:35:52,078 - tensor_generators:504 - INFO - Made a big batch of tensors with key:output_21003_Age-when-attended-assessment-centre_0_0_continuous and shape:(576, 1).\n",
      "tm prot 3\n",
      "2020-07-14 13:35:53,250 - <ipython-input-27-bc1ddedc3fe6>:23 - INFO - For tm:poor_data_quality with channel map:{'no_poor_data_quality': 0, 'Poor data quality': 1} examples:576\n",
      "2020-07-14 13:35:53,258 - <ipython-input-27-bc1ddedc3fe6>:24 - INFO - \n",
      "Sum Truth:[561.  15.] \n",
      "Sum pred :[325.02774 250.97238]\n",
      "\n",
      " name Sex_Male_0_0 truth shape (576, 2) IN ROCCCC Sex_Male_0_0 and (2,) and (576, 2)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      " name Genetic-ethnic-grouping_Caucasian_0_0 truth shape (576, 2) IN ROCCCC Genetic-ethnic-grouping_Caucasian_0_0 and (2,) and (576, 2)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      "\n",
      " protected_indexes shape (576,)\n",
      "\n",
      " name 21003_Age-when-attended-assessment-centre_0_0 truth shape (576, 2) IN ROCCCC 21003_Age-when-attended-assessment-centre_0_0 and (1,) and (576, 1)\n",
      "\n",
      "\n",
      " median -0.06528154760599136 protected_indexes shape (576, 1)\n",
      "\n",
      "\n",
      " median -0.06528154760599136 protected_indexes shape (576, 1)\n",
      "2020-07-14 13:35:53,421 - <ipython-input-28-57fad4f78ecf>:58 - INFO - ROC Label Poor data quality area: 0.854 n=15 Truth shape (576, 2), true sums [561.  15.]\n",
      "2020-07-14 13:35:55,069 - <ipython-input-28-57fad4f78ecf>:67 - INFO - Saved ROC curve at: ./recipes_output/ecg_rest_bias/per_class_roc_poor_data_quality.png with 3 protected TensorMaps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no_poor_data_quality': 0.853713606654783,\n",
       " 'Poor data quality': 0.8537136066547831}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "new_predict_and_evaluate(model, test_data, test_labels, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                      args.tensor_maps_protected, args.batch_size, args.hidden_layer, out_path, \n",
    "                      test_paths, args.embed_visualization, args.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
