{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from ml4cvd.defines import StorageType\n",
    "from ml4cvd.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap, Interpretation\n",
    "from ml4cvd.tensor_generators import test_train_valid_tensor_generators\n",
    "from ml4cvd.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model, train_model_from_generators, make_hidden_layer_model\n",
    "from ml4cvd.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps\n",
    "\n",
    "# Constants\n",
    "HD5_FOLDER = '/mnt/disks/brains-all-together/2020-02-11/'\n",
    "MODEL_FOLDER = './models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 't2_20_slices_1',\n",
    "            '--output_tensors', 'sex',\n",
    "            '--training_steps', '96',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '24',\n",
    "            '--batch_size', '2',\n",
    "            '--id', 't2_20_slices_1_slice_share',\n",
    "            '--inspect_model',\n",
    "           ]\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_axis = -1\n",
    "volume_tm = args.tensor_maps_in[0]\n",
    "slices = volume_tm.shape[slice_axis]\n",
    "slice_shape = list(volume_tm.shape)\n",
    "del slice_shape[slice_axis]\n",
    "slice_tm = TensorMap(f'slice_{volume_tm.input_name()}', shape=slice_shape)\n",
    "print(f'Slice name: {slice_tm.name} slice shape: {slice_shape} slices: {slices} original shape: {volume_tm.shape}')\n",
    "args.tensor_maps_in = [slice_tm]\n",
    "slice_model = make_multimodal_multitask_model(**args.__dict__)\n",
    "embed_slice_model = make_hidden_layer_model(slice_model, args.tensor_maps_in, 'embed')\n",
    "embed_slice_model.summary()\n",
    "\n",
    "in_volume = Input(shape=volume_tm.shape, name=volume_tm.input_name())\n",
    "embeddings = []\n",
    "for i in range(slices):\n",
    "    if slice_axis == -3 or volume_tm.axes() - slice_axis == 2:\n",
    "        embeddings.append(embed_slice_model(in_volume[..., i, :, :]))\n",
    "    elif slice_axis == -2 or volume_tm.axes() - slice_axis == 1:\n",
    "        embeddings.append(embed_slice_model(in_volume[..., i, :]))\n",
    "    elif slice_axis == -1 or volume_tm.axes() - slice_axis == 0:\n",
    "        embeddings.append(embed_slice_model(in_volume[..., i]))\n",
    "    else:\n",
    "        raise ValueError(f'Can not handle slice axis {slice_axis} with original shape {volume_tm.shape}')\n",
    "multimodal_activation = concatenate(embeddings, axis=-1)\n",
    "for units in args.dense_layers:\n",
    "    multimodal_activation = Dense(units=units, activation=args.activation)(multimodal_activation)\n",
    "\n",
    "# build decoders\n",
    "losses = []\n",
    "my_metrics = {}\n",
    "loss_weights = []\n",
    "output_predictions = {}\n",
    "tensor_maps_out = args.tensor_maps_out\n",
    "output_tensor_maps_to_process = tensor_maps_out.copy()\n",
    "while len(output_tensor_maps_to_process) > 0:\n",
    "    tm = output_tensor_maps_to_process.pop(0)\n",
    "    losses.append(tm.loss)\n",
    "    loss_weights.append(tm.loss_weight)\n",
    "    my_metrics[tm.output_name()] = tm.metrics\n",
    "    if tm.is_categorical():\n",
    "        output_predictions[tm] = Dense(units=tm.shape[0], activation='softmax', name=tm.output_name())(multimodal_activation)\n",
    "    elif tm.axes() == 1:\n",
    "        output_predictions[tm] = Dense(units=tm.shape[0], activation=tm.activation, name=tm.output_name())(multimodal_activation)\n",
    "\n",
    "m = Model(inputs=[in_volume], outputs=[output_predictions[tm] for tm in tensor_maps_out])\n",
    "m.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "m.compile(optimizer=opt, loss=losses, loss_weights=loss_weights, metrics=my_metrics)\n",
    "train_model_from_generators(m, generate_train, generate_valid, args.training_steps, args.validation_steps, \n",
    "                            args.batch_size, args.epochs, args.patience, args.output_folder, args.id, \n",
    "                            args.inspect_model, args.inspect_show_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
