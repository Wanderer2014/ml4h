{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ml4cvd.arguments import _get_tmap\n",
    "from ml4cvd.tensor_generators import get_test_train_valid_paths\n",
    "from ml4cvd.tensor_maps_by_hand import TMAPS\n",
    "\n",
    "train_paths, valid_paths, test_paths = get_test_train_valid_paths('/mnt/disks/ecg-rest-37k-tensors/2019-11-04/', 0.1, 0.1, 10, None)\n",
    "all_paths = train_paths+valid_paths+test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import time\n",
    "df_dic = {'full_path': [], 'patient_id': [], 'ecg_rest_text': [], \n",
    "          'rr': [], 'pp': [], 'pr': [], 'qrs': [],  'qt': [], 'qtc': [], 'paxis': [], 'raxis': [], 'taxis': []\n",
    "         }\n",
    "cnt = 0\n",
    "for path in all_paths:\n",
    "    hd5 = h5py.File(path, 'r')\n",
    "    df_dic['full_path'].append(path)\n",
    "    df_dic['patient_id'].append(path.split('/')[-1].split('.hd5')[0])\n",
    "    time_start = time.time()\n",
    "    df_dic['ecg_rest_text'].append(hd5['ecg_rest_text'][0])\n",
    "    time_string = time.time()\n",
    "    try:\n",
    "        df_dic['rr'].append(hd5['continuous']['RRInterval'][0])    \n",
    "    except:\n",
    "        print(f\"{df_dic['patient_id'][-1]} does not have RR measure tensorized\")\n",
    "        df_dic['rr'].append(np.nan)\n",
    "    time_rr = time.time()\n",
    "    try:\n",
    "        df_dic['pp'].append(hd5['continuous']['PPInterval'][0])\n",
    "    except:\n",
    "        print(f\"{df_dic['patient_id'][-1]} does not have PP measure tensorized\")\n",
    "        df_dic['pp'].append(np.nan)\n",
    "    time_pp = time.time()\n",
    "    try:\n",
    "        df_dic['pr'].append(hd5['continuous']['PQInterval'][0])\n",
    "        df_dic['paxis'].append(hd5['continuous']['PAxis'][0])\n",
    "    except:\n",
    "        print(f\"{df_dic['patient_id'][-1]} does not have P measures tensorized\")\n",
    "        df_dic['pr'].append(np.nan)\n",
    "        df_dic['paxis'].append(np.nan)\n",
    "    time_pr = time.time()\n",
    "    try:\n",
    "        df_dic['qrs'].append(hd5['continuous']['QRSDuration'][0])\n",
    "        df_dic['qt'].append(hd5['continuous']['QTInterval'][0])\n",
    "        df_dic['qtc'].append(hd5['continuous']['QTCInterval'][0])\n",
    "    except:\n",
    "        print(f\"{df_dic['patient_id'][-1]} does not have QRS measures tensorized\")\n",
    "        df_dic['qrs'].append(np.nan)\n",
    "        df_dic['qt'].append(np.nan)\n",
    "        df_dic['qtc'].append(np.nan)\n",
    "    time_qt = time.time()\n",
    "    try:\n",
    "        df_dic['raxis'].append(hd5['continuous']['RAxis'][0])\n",
    "        df_dic['taxis'].append(hd5['continuous']['TAxis'][0])\n",
    "    except:\n",
    "        print(f\"{df_dic['patient_id'][-1]} does not have R and T axis measures tensorized\")\n",
    "        df_dic['raxis'].append(np.nan)\n",
    "        df_dic['taxis'].append(np.nan)\n",
    "    time_axis = time.time()\n",
    "    hd5.close()\n",
    "    cnt += 1\n",
    "    #print(time_string-time_start, time_rr-time_start, time_pp-time_start, time_pr-time_start, time_qt-time_start, time_axis-time_start)\n",
    "    #if cnt == 1000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf\n",
    "# !pip install facets-overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the feature stats for the datasets and stringify it.\n",
    "# import base64\n",
    "# from facets_overview.generic_feature_statistics_generator import GenericFeatureStatisticsGenerator\n",
    "\n",
    "# gfsg = GenericFeatureStatisticsGenerator()\n",
    "# proto = gfsg.ProtoFromDataFrames([{'name': 'train', 'table': df}])\n",
    "# protostr = base64.b64encode(proto.SerializeToString()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the facets overview visualization for this data\n",
    "# from IPython.core.display import display, HTML\n",
    "\n",
    "# HTML_TEMPLATE = f\"\"\"\n",
    "#         <script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
    "#         <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\" >\n",
    "#         <facets-overview id=\"fo\"></facets-overview>\n",
    "#         <script>\n",
    "#           document.querySelector(\"#fo\").protoInput = \"{protostr}\";\n",
    "#         </script>\"\"\"\n",
    "# html = HTML_TEMPLATE.format(protostr=protostr)\n",
    "# display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the Dive visualization for this data\n",
    "# from IPython.core.display import display, HTML\n",
    "\n",
    "# sprite_size = 100\n",
    "# # Create Facets template  \n",
    "# HTML_TEMPLATE = \"\"\"<link rel=\"import\" href=\"/nbextensions/facets-dist/facets-jupyter.html\">\n",
    "#         <facets-dive sprite-image-width=\"{sprite_size}\" sprite-image-height=\"{sprite_size}\" id=\"elem\" height=\"600\"></facets-dive>\n",
    "#         <facets-overview id=\"fo\"></facets-overview>\n",
    "#         <script>\n",
    "#           document.querySelector(\"#elem\").data = {jsonstr};\n",
    "#           document.querySelector(\"#fo\").protoInput = \"{protostr}\";\n",
    "#         </script>\"\"\"\n",
    "\n",
    "# # Load the json dataset and the sprite_size into the template\n",
    "# html = HTML_TEMPLATE.format(jsonstr=jsonstr, sprite_size=sprite_size, protostr=protostr)\n",
    "\n",
    "# # Display the template\n",
    "# display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ecg_class:\n",
    "    def __init__(self, ecg_class_id, name=None):\n",
    "        self.id = ecg_class_id\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        self.children_ids = []\n",
    "        self.matching_strings = []\n",
    "        self.ncounts = 0\n",
    "        self.level = 0\n",
    "        self.patients = [] \n",
    "        self.class_df = None\n",
    "        self.class_parents = []\n",
    "    \n",
    "    def __getitem__(self, key):        \n",
    "        if key not in self.children_ids:\n",
    "            raise KeyError(f'Class {key} is not a member of {self.id}')\n",
    "        idx = self.children_ids.index(key)\n",
    "        return self.children[idx]\n",
    "\n",
    "    def __str__(self):\n",
    "        tabs = '   '*self.level+'|_____' \n",
    "        return f'{tabs}{self.name}: {self.ncounts} ({self.ncounts / 37623.0 * 100.0 :.2f}%)'\n",
    "\n",
    "    def __iter__(self):\n",
    "        for child_id in self.children_ids:\n",
    "            yield child_id\n",
    "\n",
    "    def __contains__(self, key):        \n",
    "        return key in self.children_ids\n",
    "    \n",
    "    def items(self):\n",
    "        return [(k, self[k]) for k in self.children_ids]\n",
    "    \n",
    "    def keys(self):\n",
    "        return self.children_ids\n",
    "    \n",
    "    def print_hierarchy(self):\n",
    "        for k, v in self.items():\n",
    "            print(v)\n",
    "            if isinstance(v, ecg_class):\n",
    "                v.print_hierarchy()\n",
    "    \n",
    "    def add_child(self, ecg_class):\n",
    "        if ecg_class.id in self.children_ids:\n",
    "            print(\"WARNING: class with same id already among subclasses. Skipping\")\n",
    "        else:\n",
    "            self.children.append(ecg_class)\n",
    "            self.children_ids.append(ecg_class.id)\n",
    "            self.children[-1].level = self.level+1\n",
    "            self.children[-1].class_parents = self.class_parents + [self.id]\n",
    "            \n",
    "    def add_matching_string(self, new_string):\n",
    "        self.matching_strings.append(new_string)\n",
    "        self.matching_strings = list(set(self.matching_strings))\n",
    "        \n",
    "    def make_children_exclusive(self, df):\n",
    "        if not self.children:\n",
    "            raise KeyError(f'Class {self.name} does not have subclasses. Use update_class_df instead')\n",
    "        for child in self.children:\n",
    "            if child.class_df is None:\n",
    "                child.update_class_df(df)\n",
    "        class_df = self.children[0].class_df\n",
    "        for c2 in self.children[1:]:                \n",
    "            inters = class_df.index.intersection(c2.class_df.index)\n",
    "            c2.class_df = c2.class_df.drop(inters)\n",
    "            c2.ncounts = len(c2.class_df)\n",
    "            class_df = pd.concat([class_df, c2.class_df])\n",
    "        self.class_df = class_df\n",
    "        self.ncounts = len(class_df)\n",
    "\n",
    "    def make_child_exclusive(self, child_id, df):\n",
    "        if child_id not in self.children_ids:\n",
    "            raise KeyError(f'Class {key} is not a member of {self.id}')\n",
    "        child_idx = self.children_ids.index(child_id)\n",
    "        child = self.children.pop(child_idx)\n",
    "        self.children.append(child)\n",
    "        class_df = self.children[0].class_df        \n",
    "        for c2 in self.children[1:]:\n",
    "            inters = class_df.index.intersection(c2.class_df.index)\n",
    "            c2_class_df = c2.class_df.drop(inters)\n",
    "            class_df = pd.concat([class_df, c2_class_df])\n",
    "        c2.class_df = c2_class_df\n",
    "        c2.ncounts = len(c2_class_df)    \n",
    "        \n",
    "    def update_children_df(self, df):\n",
    "        if not self.children:\n",
    "            raise KeyError(f'Class {self.name} does not have subclasses. Use update_class_df instead')\n",
    "        for child in self.children:\n",
    "            if child.class_df is None:\n",
    "                child.update_class_df(df)\n",
    "        class_df = self.children[0].class_df\n",
    "        for c2 in self.children[1:]:\n",
    "            inters = class_df.index.intersection(c2.class_df.index)\n",
    "            c2_class_df = c2.class_df.drop(inters)\n",
    "            class_df = pd.concat([class_df, c2_class_df])\n",
    "        self.class_df = class_df            \n",
    "        self.ncounts = len(class_df)\n",
    "            \n",
    "    def update_class_df(self, df):\n",
    "        if not self.matching_strings:\n",
    "            raise KeyError(f'Class {self.name} does not have matching string pattern to extract patients')\n",
    "        class_df = df[df['ecg_rest_text'].str.count(self.matching_strings[0]) > 0.5]\n",
    "        for matching_string in self.matching_strings[1:]:\n",
    "            df2 = df[df['ecg_rest_text'].str.count(matching_string) > 0.5]\n",
    "            inters = class_df.index.intersection(df2.index)\n",
    "            df2 = df2.drop(inters)\n",
    "            class_df = pd.concat([class_df, df2])\n",
    "        self.class_df = class_df\n",
    "        self.ncounts = len(class_df)  \n",
    "        \n",
    "    def hierarchical_tuples(self, tuples=None):        \n",
    "        if tuples is None:\n",
    "            tuples = []        \n",
    "        for k, v in self.items():            \n",
    "            if isinstance(v, ecg_class):\n",
    "                v.hierarchical_tuples(tuples)            \n",
    "        if len(self.children) == 0:\n",
    "            tuples.append(self.class_parents + [self.id])\n",
    "        return tuples\n",
    "    \n",
    "    def augment_df(self, df):\n",
    "        hierarchical_tuples = self.hierarchical_tuples()\n",
    "        old_tuples = [[old_col] for old_col in df]\n",
    "        new_cols = pd.MultiIndex.from_tuples(hierarchical_tuples+old_tuples)\n",
    "        new_df = pd.DataFrame(index=df.index, columns=new_cols)\n",
    "        for new_col in new_cols: \n",
    "            if new_col[0] in df:\n",
    "                new_df[new_col][:] = df[new_col[0]]\n",
    "            else:\n",
    "                this_class = self\n",
    "                for l, level in enumerate(new_col):\n",
    "                    if l == 0:\n",
    "                        continue\n",
    "                    if str(level) == 'nan':\n",
    "                        break\n",
    "                    this_class = this_class[level]\n",
    "                new_df[new_col][:] = False\n",
    "                if this_class.class_df is not None:\n",
    "                    new_df[new_col].iloc[this_class.class_df.index] = True\n",
    "        return new_df            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "classification = ecg_class('class', 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rhythm = ecg_class('rhythm', 'Rhythm')\n",
    "classification.add_child(rhythm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sinus_rhythm = ecg_class('sinus_rhythm', 'Sinus rhythm')\n",
    "classification['rhythm'].add_child(sinus_rhythm)\n",
    "sinus_rhythm_no_arr = ecg_class('no_arr', 'Sinus rhythm no arrhythmia')\n",
    "sinus_rhythm_yes_arr = ecg_class('yes_arr', 'Sinus rhythm with arrhythmia')\n",
    "classification['rhythm']['sinus_rhythm'].add_child(sinus_rhythm_no_arr)\n",
    "classification['rhythm']['sinus_rhythm'].add_child(sinus_rhythm_yes_arr)\n",
    "classification['rhythm']['sinus_rhythm']['no_arr'].add_matching_string(r'[sS]inus rhythm')\n",
    "classification['rhythm']['sinus_rhythm']['yes_arr'].add_matching_string(r'[sS]inus bradycardia')\n",
    "classification['rhythm']['sinus_rhythm']['yes_arr'].add_matching_string(r'[sS]inus tachycardia')\n",
    "classification['rhythm']['sinus_rhythm']['yes_arr'].add_matching_string(r'[sS]inus arrhythmia')\n",
    "classification['rhythm']['sinus_rhythm'].make_children_exclusive(df)\n",
    "print(classification['rhythm']['sinus_rhythm']['yes_arr'])\n",
    "print(classification['rhythm']['sinus_rhythm']['no_arr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ectopic_atrial = ecg_class('ectopic_atrial', 'Ectopic atrial rhythm')\n",
    "classification['rhythm'].add_child(ectopic_atrial)\n",
    "classification['rhythm']['ectopic_atrial'].add_matching_string(r'[Ee]ctopic atrial')\n",
    "classification['rhythm']['ectopic_atrial'].add_matching_string(r'[Uu]nusual P axis possible ectopic atrial tachycardia')\n",
    "classification['rhythm']['ectopic_atrial'].add_matching_string(r'[Uu]nusual P axis')\n",
    "classification['rhythm']['ectopic_atrial'].update_class_df(df)\n",
    "print(classification['rhythm']['ectopic_atrial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "atrial_fibrillation = ecg_class('atrial_fibrillation', 'Atrial fibrillation')\n",
    "classification['rhythm'].add_child(atrial_fibrillation)\n",
    "classification['rhythm']['atrial_fibrillation'].add_matching_string(r'Atrial fibrillation')\n",
    "classification['rhythm']['atrial_fibrillation'].update_class_df(df)\n",
    "print(classification['rhythm']['atrial_fibrillation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "atrial_flutter = ecg_class('atrial_flutter', 'Atrial flutter')\n",
    "classification['rhythm'].add_child(atrial_flutter)\n",
    "atrial_flutter_fixed = ecg_class('fixed', 'Atrial flutter with fixed block')\n",
    "atrial_flutter_variable = ecg_class('variable', 'Atrial flutter with variable block')\n",
    "atrial_flutter_unspec = ecg_class('unspec', 'Atrial flutter with unspecified block')\n",
    "classification['rhythm']['atrial_flutter'].add_child(atrial_flutter_fixed)\n",
    "classification['rhythm']['atrial_flutter'].add_child(atrial_flutter_variable)\n",
    "classification['rhythm']['atrial_flutter'].add_child(atrial_flutter_unspec)\n",
    "classification['rhythm']['atrial_flutter']['fixed'].add_matching_string(r'[aA]trial flutter with [0-9]:1 AV conduction')\n",
    "classification['rhythm']['atrial_flutter']['variable'].add_matching_string(r'[aA]trial flutter with variable AV block')\n",
    "classification['rhythm']['atrial_flutter']['unspec'].add_matching_string('r[aA]trial flutter')\n",
    "classification['rhythm']['atrial_flutter'].make_children_exclusive(df)\n",
    "print(classification['rhythm']['atrial_flutter'])\n",
    "print(classification['rhythm']['atrial_flutter']['fixed'])\n",
    "print(classification['rhythm']['atrial_flutter']['variable'])\n",
    "print(classification['rhythm']['atrial_flutter']['unspec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "undetermined_rhythm = ecg_class('undetermined', 'Undetermined rhythm')\n",
    "classification['rhythm'].add_child(undetermined_rhythm)\n",
    "classification['rhythm']['undetermined'].add_matching_string('Undetermined rhythm')\n",
    "classification['rhythm']['undetermined'].update_class_df(df)\n",
    "print(classification['rhythm']['undetermined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "junctional = ecg_class('junctional_rhythm', 'Junctional Rhythm')\n",
    "classification.add_child(junctional)\n",
    "classification['junctional_rhythm'].add_matching_string(r'[jJ]unctional rhythm')\n",
    "classification['junctional_rhythm'].add_matching_string(r'[jJ]unctional pacemaker')\n",
    "classification['junctional_rhythm'].add_matching_string(r'[jJ]unctional bradycardia')\n",
    "classification['junctional_rhythm'].add_matching_string(r'[jJ]unctional escape complexes')\n",
    "classification['junctional_rhythm'].update_class_df(df)\n",
    "print(classification['junctional_rhythm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ventricular = ecg_class('ventricular_rhythm', 'Ventricular Rhythm')\n",
    "classification.add_child(ventricular)\n",
    "classification['ventricular_rhythm'].add_matching_string(r'[vV]entricular escape complexes')\n",
    "classification['ventricular_rhythm'].update_class_df(df)\n",
    "print(classification['ventricular_rhythm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "av_block = ecg_class('av_block', 'AV Block')\n",
    "classification.add_child(av_block)\n",
    "first_deg_block = ecg_class('first_deg', '1st degree AV Block')\n",
    "second_deg_block = ecg_class('second_deg', '2nd degree AV Block')\n",
    "third_deg_block = ecg_class('third_deg', '3rd degree AV Block')\n",
    "dissoc_block = ecg_class('dissociation', 'AV dissociation')\n",
    "classification['av_block'].add_child(first_deg_block)\n",
    "classification['av_block']['first_deg'].add_matching_string('1st degree AV block')\n",
    "classification['av_block'].add_child(second_deg_block)\n",
    "classification['av_block']['second_deg'].add_matching_string('2nd degree AV block')\n",
    "mobitz_I  = ecg_class('mobitz_I', '2nd degree AV block (Mobitz I)')\n",
    "mobitz_II = ecg_class('mobitz_II', '2nd degree AV block (Mobitz II)')\n",
    "unspec_av_block = ecg_class('unspecified', '2nd degree AV block (unspecified)')\n",
    "classification['av_block']['second_deg'].add_child(mobitz_I)\n",
    "classification['av_block']['second_deg'].add_child(mobitz_II)\n",
    "classification['av_block']['second_deg'].add_child(unspec_av_block)\n",
    "classification['av_block']['second_deg']['mobitz_I'].add_matching_string('Mobitz I')\n",
    "classification['av_block']['second_deg']['mobitz_II'].add_matching_string('Mobitz II')\n",
    "classification['av_block']['second_deg']['unspecified'].add_matching_string('2nd degree AV block')\n",
    "classification['av_block'].add_child(third_deg_block)\n",
    "classification['av_block']['third_deg'].add_matching_string('3rd degree AV block')\n",
    "classification['av_block'].add_child(dissoc_block)\n",
    "classification['av_block']['dissociation'].add_matching_string('AV dissociation')\n",
    "classification['av_block']['second_deg'].make_children_exclusive(df)\n",
    "classification['av_block'].make_children_exclusive(df)\n",
    "print(classification['av_block'])\n",
    "print(classification['av_block']['first_deg'])\n",
    "print(classification['av_block']['second_deg'])\n",
    "print(classification['av_block']['second_deg']['mobitz_I'])\n",
    "print(classification['av_block']['second_deg']['mobitz_II'])\n",
    "print(classification['av_block']['second_deg']['unspecified'])\n",
    "print(classification['av_block']['third_deg'])\n",
    "print(classification['av_block']['dissociation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Subclasses of BBB can all occur at the same time\n",
    "bbb = ecg_class('bbb', 'Bundle branch block')\n",
    "classification.add_child(bbb)\n",
    "bbb_left = ecg_class('left', 'Left bundle branch block')\n",
    "bbb_right = ecg_class('right', 'Right bundle branch block')\n",
    "bbb_ivcd = ecg_class('ivcd', 'Intraventricular conduction delay')\n",
    "bbb_la_fascicular = ecg_class('la_fascicular', 'Left anterior fascicular block')\n",
    "bbb_lp_fascicular = ecg_class('lp_fascicular', 'Left posterior fascicular block')\n",
    "classification['bbb'].add_child(bbb_left)\n",
    "classification['bbb'].add_child(bbb_right)\n",
    "classification['bbb'].add_child(bbb_ivcd)\n",
    "classification['bbb'].add_child(bbb_la_fascicular)\n",
    "classification['bbb'].add_child(bbb_lp_fascicular)\n",
    "classification['bbb']['ivcd'].add_matching_string(r'intraventricular block')\n",
    "classification['bbb']['ivcd'].add_matching_string(r'intraventricular conduction delay')\n",
    "classification['bbb']['la_fascicular'].add_matching_string(r'[lL]eft anterior fascicular block')\n",
    "classification['bbb']['lp_fascicular'].add_matching_string(r'[lL]eft posterior fascicular block')\n",
    "classification['bbb']['right'].add_matching_string(r'[rR]ight bundle branch block')\n",
    "bbb_left_complete = ecg_class('complete', 'Complete left bundle branch block')\n",
    "bbb_left_incomplete = ecg_class('incomplete', 'Incomplete left bundle branch block')\n",
    "bbb_right_complete = ecg_class('complete', 'Complete right bundle branch block')\n",
    "bbb_right_incomplete = ecg_class('incomplete', 'Incomplete right bundle branch block')\n",
    "classification['bbb']['left'].add_child(bbb_left_incomplete)\n",
    "classification['bbb']['left'].add_child(bbb_left_complete)\n",
    "classification['bbb']['right'].add_child(bbb_right_complete)\n",
    "classification['bbb']['right'].add_child(bbb_right_incomplete)\n",
    "classification['bbb']['left']['incomplete'].add_matching_string(r'[Ii]ncomplete left bundle branch block')\n",
    "classification['bbb']['left']['complete'].add_matching_string(r'Left bundle branch block')\n",
    "classification['bbb']['right']['incomplete'].add_matching_string(r'[Ii]ncomplete right bundle branch block')\n",
    "classification['bbb']['right']['complete'].add_matching_string(r'Right bundle branch block')\n",
    "classification['bbb']['left'].make_children_exclusive(df)\n",
    "classification['bbb']['right'].make_children_exclusive(df)\n",
    "classification['bbb'].update_children_df(df)\n",
    "print(classification['bbb'])\n",
    "print(classification['bbb']['left'])\n",
    "print(classification['bbb']['left']['complete'])\n",
    "print(classification['bbb']['left']['incomplete'])\n",
    "print(classification['bbb']['la_fascicular'])\n",
    "print(classification['bbb']['lp_fascicular'])\n",
    "print(classification['bbb']['right'])\n",
    "print(classification['bbb']['right']['complete'])\n",
    "print(classification['bbb']['right']['incomplete'])\n",
    "print(classification['bbb']['ivcd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ectopy = ecg_class('ectopy', 'Ectopy')\n",
    "classification.add_child(ectopy)\n",
    "ectopy_pacs = ecg_class('pacs', 'Premature atrial complexes')\n",
    "ectopy_pvcs = ecg_class('pvcs', 'Premature ventricular complexes')\n",
    "classification['ectopy'].add_child(ectopy_pacs)\n",
    "classification['ectopy'].add_child(ectopy_pvcs)\n",
    "ectopy_pacs_isolated = ecg_class('isolated', 'Isolated premature atrial contractions')\n",
    "ectopy_pacs_bigeminy = ecg_class('atrial_bigeminy', 'Atrial bigeminy')\n",
    "ectopy_pacs_trigeminy = ecg_class('atrial_trigeminy', 'Atrial trigeminy')\n",
    "classification['ectopy']['pacs'].add_child(ectopy_pacs_bigeminy)\n",
    "classification['ectopy']['pacs'].add_child(ectopy_pacs_trigeminy)\n",
    "classification['ectopy']['pacs'].add_child(ectopy_pacs_isolated)\n",
    "classification['ectopy']['pacs']['atrial_bigeminy'].add_matching_string(r'atrial complexes in a pattern of bigeminy')\n",
    "classification['ectopy']['pacs']['atrial_trigeminy'].add_matching_string(r'atrial complexes in a pattern of trigeminy')\n",
    "classification['ectopy']['pacs']['isolated'].add_matching_string(r'[pP]remature atrial complexes')\n",
    "classification['ectopy']['pacs'].make_children_exclusive(df)\n",
    "ectopy_pvcs_isolated = ecg_class('isolated', 'Isolated premature ventricular contractions')\n",
    "ectopy_pvcs_bigeminy = ecg_class('ventricular_bigeminy', 'Ventricular bigeminy')\n",
    "ectopy_pvcs_trigeminy = ecg_class('ventricular_trigeminy', 'Ventricular trigeminy')\n",
    "classification['ectopy']['pvcs'].add_child(ectopy_pvcs_bigeminy)\n",
    "classification['ectopy']['pvcs'].add_child(ectopy_pvcs_trigeminy)\n",
    "classification['ectopy']['pvcs'].add_child(ectopy_pvcs_isolated)\n",
    "classification['ectopy']['pvcs']['ventricular_bigeminy'].add_matching_string(r'ventricular complexes in a pattern of bigeminy')\n",
    "classification['ectopy']['pvcs']['ventricular_trigeminy'].add_matching_string(r'ventricular complexes in a pattern of trigeminy')\n",
    "classification['ectopy']['pvcs']['isolated'].add_matching_string(r'[pP]remature ventricular complexes')\n",
    "classification['ectopy']['pvcs'].make_children_exclusive(df)\n",
    "classification['ectopy'].update_children_df(df)\n",
    "print(classification['ectopy'])\n",
    "print(classification['ectopy']['pacs'])\n",
    "print(classification['ectopy']['pacs']['atrial_bigeminy'])\n",
    "print(classification['ectopy']['pacs']['atrial_trigeminy'])\n",
    "print(classification['ectopy']['pacs']['isolated'])\n",
    "print(classification['ectopy']['pvcs'])\n",
    "print(classification['ectopy']['pvcs']['ventricular_bigeminy'])\n",
    "print(classification['ectopy']['pvcs']['ventricular_trigeminy'])\n",
    "print(classification['ectopy']['pvcs']['isolated'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Structural morphologies\n",
    "structural = ecg_class('structural', 'Structural morphologies')\n",
    "classification.add_child(structural)\n",
    "lae = ecg_class('lae', 'Left atrial enlargement')\n",
    "rae = ecg_class('rae', 'Right atrial enlargement')\n",
    "classification['structural'].add_child(lae)\n",
    "classification['structural'].add_child(rae)\n",
    "classification['structural']['lae'].add_matching_string('[lL]eft atrial enlargement')\n",
    "classification['structural']['lae'].add_matching_string('[bB]iatrial enlargement')\n",
    "classification['structural']['rae'].add_matching_string('[rR]ight atrial enlargement')\n",
    "classification['structural']['rae'].add_matching_string('[bB]iatrial enlargement')\n",
    "old_infarct = ecg_class('old_infarct', 'Old myocardial infarct')\n",
    "classification['structural'].add_child(old_infarct)\n",
    "old_infarct_septal = ecg_class('septal', 'Old myocardial infarct (septal)')\n",
    "old_infarct_anterior = ecg_class('anterior', 'Old myocardial infarct (anterior)')\n",
    "old_infarct_inferior = ecg_class('inferior', 'Old myocardial infarct (inferior)')\n",
    "old_infarct_lateral = ecg_class('lateral', 'Old myocardial infarct (lateral)')\n",
    "old_infarct_posterior = ecg_class('posterior', 'Old myocardial infarct (posterior)')\n",
    "old_infarct_unspec = ecg_class('unspec', 'Old myocardial infarct')\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_septal)\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_anterior)\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_inferior)\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_lateral)\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_posterior)\n",
    "classification['structural']['old_infarct'].add_child(old_infarct_unspec)\n",
    "classification['structural']['old_infarct']['septal'].add_matching_string('[sS]eptal infarct age undetermined')\n",
    "classification['structural']['old_infarct']['septal'].add_matching_string('[aA]nteroseptal infarct age undetermined')\n",
    "classification['structural']['old_infarct']['anterior'].add_matching_string('[sA]nterior infarct age undetermined')\n",
    "classification['structural']['old_infarct']['anterior'].add_matching_string('[sA]nteroseptal infarct age undetermined')\n",
    "classification['structural']['old_infarct']['anterior'].add_matching_string('[sA]nterolateral infarct age undetermined')\n",
    "classification['structural']['old_infarct']['inferior'].add_matching_string('[iI]nferior infarct age undetermined')\n",
    "classification['structural']['old_infarct']['inferior'].add_matching_string('[iI]nferior-posterior infarct age undetermined')\n",
    "classification['structural']['old_infarct']['posterior'].add_matching_string('[iI]nferior-posterior infarct age undetermined')\n",
    "classification['structural']['old_infarct']['posterior'].add_matching_string('[pP]osterior infarct age undetermined')\n",
    "classification['structural']['old_infarct']['lateral'].add_matching_string('[sA]nterolateral infarct age undetermined')\n",
    "classification['structural']['old_infarct']['lateral'].add_matching_string('[lL]ateral infarct age undetermined')\n",
    "classification['structural']['old_infarct']['unspec'].add_matching_string('[iI]nfarct age undetermined')\n",
    "classification['structural']['old_infarct'].update_children_df(df)\n",
    "classification['structural']['old_infarct'].make_child_exclusive('unspec', df)\n",
    "classification['structural'].update_children_df(df)\n",
    "print(classification['structural']['lae'])\n",
    "print(classification['structural']['rae'])\n",
    "print(classification['structural']['old_infarct'])\n",
    "print(classification['structural']['old_infarct']['septal'])\n",
    "print(classification['structural']['old_infarct']['anterior'])\n",
    "print(classification['structural']['old_infarct']['inferior'])\n",
    "print(classification['structural']['old_infarct']['posterior'])\n",
    "print(classification['structural']['old_infarct']['lateral'])\n",
    "print(classification['structural']['old_infarct']['unspec'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "acute_infarct = ecg_class('acute_infarct', 'Acute myocardial infarct')\n",
    "classification['structural'].add_child(acute_infarct)\n",
    "acute_infarct_septal = ecg_class('septal', 'Acute myocardial infarct (septal)')\n",
    "acute_infarct_anterior = ecg_class('anterior', 'Acute myocardial infarct (anterior)')\n",
    "acute_infarct_inferior = ecg_class('inferior', 'Acute myocardial infarct (inferior)')\n",
    "acute_infarct_lateral = ecg_class('lateral', 'Acute myocardial infarct (lateral)')\n",
    "acute_infarct_posterior = ecg_class('posterior', 'Acute myocardial infarct (posterior)')\n",
    "acute_infarct_unspec = ecg_class('unspec', 'Acute myocardial infarct')\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_septal)\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_anterior)\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_inferior)\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_lateral)\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_posterior)\n",
    "classification['structural']['acute_infarct'].add_child(acute_infarct_unspec)\n",
    "classification['structural']['acute_infarct']['septal'].add_matching_string('[sS]eptal infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['septal'].add_matching_string('[sS]eptal injury pattern')\n",
    "classification['structural']['acute_infarct']['septal'].add_matching_string('[aA]nteroseptal infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['anterior'].add_matching_string('ST elevation consider anterior injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['anterior'].add_matching_string('ST elevation consider anterolateral injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['anterior'].add_matching_string('[aA]nterior injury pattern')\n",
    "classification['structural']['acute_infarct']['anterior'].add_matching_string('[aA]nterior infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['anterior'].add_matching_string('[Aa]nteroseptal infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('ST elevation consider inferior injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('ST elevation consider inferolateral injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('[aA]cute inferior infarct')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('[iI]nferior injury pattern')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('[iI]nferior infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['inferior'].add_matching_string('[iI]nferior-posterior infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['posterior'].add_matching_string('[pP]osterior injury pattern')\n",
    "classification['structural']['acute_infarct']['posterior'].add_matching_string('[pP]osterior infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['posterior'].add_matching_string('[iI]nferior-posterior infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('[lL]ateral injury pattern')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('[lL]ateral infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('ST elevation consider lateral injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('ST elevation consider inferolateral injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('ST elevation consider anterolateral injury or acute infarct')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('[sA]nterolateral infarct possibly acute')\n",
    "classification['structural']['acute_infarct']['lateral'].add_matching_string('[lL]ateral infarct age possibly acute')\n",
    "classification['structural']['acute_infarct']['unspec'].add_matching_string('[aA][cC][uU][tT][eE] [mM][iI]')\n",
    "classification['structural']['acute_infarct'].update_children_df(df)\n",
    "classification['structural']['acute_infarct'].make_child_exclusive('unspec', df)\n",
    "classification['structural'].update_children_df(df)\n",
    "print(classification['structural']['acute_infarct'])\n",
    "print(classification['structural']['acute_infarct']['septal'])\n",
    "print(classification['structural']['acute_infarct']['anterior'])\n",
    "print(classification['structural']['acute_infarct']['inferior'])\n",
    "print(classification['structural']['acute_infarct']['posterior'])\n",
    "print(classification['structural']['acute_infarct']['lateral'])\n",
    "print(classification['structural']['acute_infarct']['unspec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "st_depression = ecg_class('st_depression', 'ST Depression')\n",
    "classification['structural'].add_child(st_depression)\n",
    "st_depression_unspec = ecg_class('unspec', 'Unspecified ST depression')\n",
    "classification['structural']['st_depression'].add_child(st_depression_unspec)\n",
    "classification['structural']['st_depression']['unspec'].add_matching_string('ST depression probably abnormal')\n",
    "classification['structural']['st_depression']['unspec'].add_matching_string('ST depression probably normal')\n",
    "classification['structural']['st_depression'].update_children_df(df)\n",
    "print(classification['structural']['st_depression'])\n",
    "print(classification['structural']['st_depression']['unspec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "st_abnormal = ecg_class('st_abnormality', 'ST segment abnormality')\n",
    "classification['structural'].add_child(st_abnormal)\n",
    "st_abnormal_septal = ecg_class('septal', 'ST abnormality localized septally')\n",
    "st_abnormal_lateral = ecg_class('lateral', 'ST abnormality localized laterally')\n",
    "st_abnormal_inferior = ecg_class('inferior', 'ST abnormality localized inferiorly')\n",
    "st_abnormal_anterior = ecg_class('anterior', 'ST abnormality localized anteriorly')\n",
    "st_abnormal_posterior = ecg_class('posterior', 'ST abnormality localized posteriorly')\n",
    "st_abnormal_unspec = ecg_class('unspec', 'Unspecified ST segment abnormality')\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_septal)\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_lateral)\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_inferior)\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_anterior)\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_posterior)\n",
    "classification['structural']['st_abnormality'].add_child(st_abnormal_unspec)\n",
    "classification['structural']['st_abnormality']['septal'].add_matching_string('ST abnormality consider septal ischemia')\n",
    "classification['structural']['st_abnormality']['septal'].add_matching_string('ST and T wave abnormality consider septal ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST abnormality consider lateral ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST abnormality consider anterolateral ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST abnormality consider inferolateral ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider lateral ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['st_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['st_abnormality']['inferior'].add_matching_string('ST abnormality consider inferior ischemia')\n",
    "classification['structural']['st_abnormality']['inferior'].add_matching_string('ST abnormality consider inferolateral ischemia')\n",
    "classification['structural']['st_abnormality']['inferior'].add_matching_string('ST and T wave abnormality consider inferior ischemia')\n",
    "classification['structural']['st_abnormality']['inferior'].add_matching_string('ST and T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['st_abnormality']['anterior'].add_matching_string('ST abnormality consider anterior ischemia')\n",
    "classification['structural']['st_abnormality']['anterior'].add_matching_string('ST abnormality consider anterolateral ischemia')\n",
    "classification['structural']['st_abnormality']['anterior'].add_matching_string('ST and T wave abnormality consider anterior ischemia')\n",
    "classification['structural']['st_abnormality']['anterior'].add_matching_string('ST and T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['st_abnormality']['posterior'].add_matching_string('ST abnormality consider posterior ischemia')\n",
    "classification['structural']['st_abnormality']['posterior'].add_matching_string('ST and T wave abnormality consider posterior ischemia')\n",
    "classification['structural']['st_abnormality']['unspec'].add_matching_string('ST and T wave abnormality')\n",
    "classification['structural']['st_abnormality']['unspec'].add_matching_string('ST abnormality')\n",
    "classification['structural']['st_abnormality'].update_children_df(df)\n",
    "classification['structural']['st_abnormality'].make_child_exclusive('unspec', df)\n",
    "print(classification['structural']['st_abnormality'])\n",
    "print(classification['structural']['st_abnormality']['septal'])\n",
    "print(classification['structural']['st_abnormality']['lateral'])\n",
    "print(classification['structural']['st_abnormality']['inferior'])\n",
    "print(classification['structural']['st_abnormality']['anterior'])\n",
    "print(classification['structural']['st_abnormality']['posterior'])\n",
    "print(classification['structural']['st_abnormality']['unspec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tw_abnormal = ecg_class('tw_abnormality', 'T wave abnormality')\n",
    "classification['structural'].add_child(tw_abnormal)\n",
    "tw_abnormal_septal = ecg_class('septal', 'T wave abnormality localized septally')\n",
    "tw_abnormal_lateral = ecg_class('lateral', 'T wave abnormality localized laterally')\n",
    "tw_abnormal_inferior = ecg_class('inferior', 'T wave abnormality localized inferiorly')\n",
    "tw_abnormal_anterior = ecg_class('anterior', 'T wave abnormality localized anteriorly')\n",
    "tw_abnormal_posterior = ecg_class('posterior', 'T wave abnormality localized posteriorly')\n",
    "tw_abnormal_unspec = ecg_class('unspec', 'Unspecified T wave segment abnormality')\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_septal)\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_lateral)\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_inferior)\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_anterior)\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_posterior)\n",
    "classification['structural']['tw_abnormality'].add_child(tw_abnormal_unspec)\n",
    "classification['structural']['tw_abnormality']['septal'].add_matching_string('T wave abnormality consider septal ischemia')\n",
    "classification['structural']['tw_abnormality']['septal'].add_matching_string('ST and T wave abnormality consider septal ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('T wave abnormality consider lateral ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider lateral ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['lateral'].add_matching_string('ST and T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['inferior'].add_matching_string('T wave abnormality consider inferior ischemia')\n",
    "classification['structural']['tw_abnormality']['inferior'].add_matching_string('T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['inferior'].add_matching_string('ST and T wave abnormality consider inferior ischemia')\n",
    "classification['structural']['tw_abnormality']['inferior'].add_matching_string('ST and T wave abnormality consider inferolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['anterior'].add_matching_string('T wave abnormality consider anterior ischemia')\n",
    "classification['structural']['tw_abnormality']['anterior'].add_matching_string('T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['anterior'].add_matching_string('ST and T wave abnormality consider anterior ischemia')\n",
    "classification['structural']['tw_abnormality']['anterior'].add_matching_string('ST and T wave abnormality consider anterolateral ischemia')\n",
    "classification['structural']['tw_abnormality']['posterior'].add_matching_string('T wave abnormality consider posterior ischemia')\n",
    "classification['structural']['tw_abnormality']['posterior'].add_matching_string('ST and T wave abnormality consider posterior ischemia')\n",
    "classification['structural']['tw_abnormality']['unspec'].add_matching_string('ST and T wave abnormality')\n",
    "classification['structural']['tw_abnormality']['unspec'].add_matching_string('T wave abnormality')\n",
    "classification['structural']['tw_abnormality'].update_children_df(df)\n",
    "classification['structural']['tw_abnormality'].make_child_exclusive('unspec', df)\n",
    "print(classification['structural']['tw_abnormality'])\n",
    "print(classification['structural']['tw_abnormality']['septal'])\n",
    "print(classification['structural']['tw_abnormality']['lateral'])\n",
    "print(classification['structural']['tw_abnormality']['inferior'])\n",
    "print(classification['structural']['tw_abnormality']['anterior'])\n",
    "print(classification['structural']['tw_abnormality']['posterior'])\n",
    "print(classification['structural']['tw_abnormality']['unspec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "st_elevation = ecg_class('st_elevation', 'ST elevation')\n",
    "classification['structural'].add_child(st_elevation)\n",
    "classification['structural']['st_elevation'].add_matching_string('ST elevation')\n",
    "classification['structural']['st_elevation'].update_class_df(df)\n",
    "print(classification['structural']['st_elevation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lvh = ecg_class('lvh', 'Left ventricular hypertrophy')\n",
    "rvh = ecg_class('rvh', 'Right ventricular hypertrophy')\n",
    "classification['structural'].add_child(lvh)\n",
    "classification['structural'].add_child(rvh)\n",
    "classification['structural']['lvh'].add_matching_string('[Ll][Vv][Hh]')\n",
    "classification['structural']['lvh'].add_matching_string('[Ll]eft ventricular hypertrophy')\n",
    "classification['structural']['lvh'].update_class_df(df)\n",
    "classification['structural']['rvh'].add_matching_string('[Rr][Vv][Hh]')\n",
    "classification['structural']['rvh'].add_matching_string('[Rr]ight ventricular hypertrophy')\n",
    "classification['structural']['rvh'].update_class_df(df)\n",
    "print(classification['structural']['lvh'])\n",
    "print(classification['structural']['rvh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "early_rep = ecg_class('early_rep', 'Early repolarization')\n",
    "classification['structural'].add_child(early_rep)\n",
    "classification['structural']['early_rep'].add_matching_string('[eE]arly repolarization')\n",
    "classification['structural']['early_rep'].update_class_df(df)\n",
    "print(classification['structural']['early_rep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "brugada = ecg_class('brugada', 'Brugada pattern')\n",
    "digitalis = ecg_class('digitalis', 'Digitalis effect')\n",
    "pericarditis = ecg_class('pericarditis', 'Acute pericarditis')\n",
    "classification['structural'].add_child(brugada)\n",
    "classification['structural'].add_child(digitalis)\n",
    "classification['structural'].add_child(pericarditis)\n",
    "classification['structural']['brugada'].add_matching_string('brugada')\n",
    "classification['structural']['digitalis'].add_matching_string('digitalis')\n",
    "classification['structural']['pericarditis'].add_matching_string('[Aa]cute pericarditis')\n",
    "classification['structural']['brugada'].update_class_df(df)\n",
    "classification['structural']['digitalis'].update_class_df(df)\n",
    "classification['structural']['pericarditis'].update_class_df(df)\n",
    "print(classification['structural']['brugada'])\n",
    "print(classification['structural']['digitalis'])\n",
    "print(classification['structural']['pericarditis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "counterclockwise_rotation = ecg_class('counterclockwise', 'Counter clockwise rotation')\n",
    "classification['structural'].add_child(counterclockwise_rotation)\n",
    "classification['structural']['counterclockwise'].add_matching_string('early transition')\n",
    "classification['structural']['counterclockwise'].update_class_df(df)\n",
    "print(classification['structural']['counterclockwise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pulmonary_disease = ecg_class('pulmonary', 'Pulmonary disease pattern')\n",
    "ventricular_preexcitation = ecg_class('ventricular_preexcitation', 'Ventricular pre-excitation')\n",
    "classification['structural'].add_child(pulmonary_disease)\n",
    "classification['structural'].add_child(ventricular_preexcitation)\n",
    "classification['structural']['pulmonary'].add_matching_string('[pP]ulmonary disease')\n",
    "classification['structural']['ventricular_preexcitation'].add_matching_string('[vV]entricular pre-excitation')\n",
    "classification['structural']['ventricular_preexcitation'].add_matching_string('Wolff-Parkinson-White')\n",
    "classification['structural']['ventricular_preexcitation'].add_matching_string('WPW')\n",
    "classification['structural']['pulmonary'].update_class_df(df)\n",
    "classification['structural']['ventricular_preexcitation'].update_class_df(df)\n",
    "print(classification['structural']['pulmonary'])\n",
    "print(classification['structural']['ventricular_preexcitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.print_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = classification.augment_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['class']['rhythm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = pd.MultiIndex.from_tuples(new_old_cols + tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_old_cols = [[old_col, ] for old_col in df]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_old_cols + tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_df(self, df):\n",
    "        hierarchical_tuples = self.hierarchical_tuples()\n",
    "        old_tuples = [[old_col] for old_col in df]\n",
    "        new_cols = pd.MultiIndex.from_tuples(hierarchical_tuples+old_tuples)\n",
    "        new_df = pd.DataFrame(index=df.index, columns=new_cols, dtype=float)\n",
    "        for new_col in new_cols:\n",
    "            if new_col[0] in df:\n",
    "                print(new_col)\n",
    "                new_df[new_col][:] = df[new_col[0]]\n",
    "            else:\n",
    "                this_class = self\n",
    "                for l, level in enumerate(new_col):\n",
    "                    if l == 0:\n",
    "                        continue\n",
    "                    if str(level) == 'nan':\n",
    "                        break\n",
    "                    this_class = this_class[level]\n",
    "                new_df[new_col][:] = False\n",
    "                if this_class.class_df is not None:\n",
    "                    new_df[new_col].iloc[this_class.class_df.index] = True\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = augment_df(classification, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "ecg_hierarchical_counts.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
