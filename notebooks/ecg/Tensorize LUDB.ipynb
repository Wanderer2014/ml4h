{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from ml4cvd.arguments import parse_args\n",
    "from ml4cvd.recipes import run\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# font = {'family' : 'Arial',\n",
    "#         'size'   : 30}\n",
    "# matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "from ml4cvd.arguments import _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap\n",
    "from ml4cvd.tensor_from_file import TMAPS\n",
    "\n",
    "import numpy as np\n",
    "USER = 'pdiachil'\n",
    "HOME_PATH = '/home/' + USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv = ['tensorize',\n",
    "#             '--mode', 'tensorize_ludb',\n",
    "#             '--xml_folder', f'{HOME_PATH}/ludb/',\n",
    "#             '--output_folder', f'{HOME_PATH}/ludb_tensors/',\n",
    "#             '--tensors', f'{HOME_PATH}/ludb_tensors/',\n",
    "#             '--min_sample_id', '1', \n",
    "#             '--max_sample_id', '201'\n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ECG_REST_LUDB_LEADS =  {'i': 0, 'ii': 1, 'iii': 2, 'v1': 3, 'v2': 4, 'v3': 5,\n",
    "                        'v4': 6, 'v5': 7, 'v6': 8, 'avf': 9, 'avl': 10, 'avr': 11}\n",
    "ECG_REST_LUDB_LEADS =  {'i': 0, 'ii': 1, 'iii': 2, 'v1': 3, 'v2': 4, 'v3': 5}\n",
    "\n",
    "for i in range(1, 200):\n",
    "    with h5py.File(f'{HOME_PATH}/ludb_tensors/{i}.hd5', 'r') as hd5:\n",
    "        f, ax = plt.subplots(len(ECG_REST_LUDB_LEADS), 1)\n",
    "        f.set_size_inches(16, 10)\n",
    "        for lead in ECG_REST_LUDB_LEADS:\n",
    "            ann = np.array(hd5[f'ecg_rest_annotation/annotation_{lead}'])\n",
    "            data = np.array(hd5[f'ecg_rest/strip_{lead}'])\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].plot(data, 'k', linewidth=5)\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].plot(ann, data[ann], 'r*', markersize=15)\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].set_xticklabels([])\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].set_xticks([0, 1000, 2000, 3000, 4000, 5000])\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].set_xlim([0, 5000])\n",
    "            ax[ECG_REST_LUDB_LEADS[lead]].tick_params(labelsize=30)\n",
    "        ax[ECG_REST_LUDB_LEADS[lead]].set_xticklabels(['0', '2', '4', '6', '8', '10'])\n",
    "        ax[0].set_title(str(i) + ' - ' + hd5['ecg_rest_text'][()][0][:60], size=35)\n",
    "        plt.tight_layout\n",
    "        f.savefig(f'/home/pdiachil/ludb_output/annotation_ludb_{i}.png')\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotation_to_segmentation(data, ann, shape = (5000,)):\n",
    "    cycle = ['QR', 'RS', 'ST1', 'T1T2', 'T2T3', 'T3P1', 'P1P2', 'P2P3', 'P3Q']\n",
    "    parsed_data = np.zeros(shape)\n",
    "    parsed_range = ann[-1] - ann[0]\n",
    "    parsed_data[:parsed_range] = data[ann[0]:ann[-1]]\n",
    "    segmented_data = np.zeros(shape, dtype=np.int)\n",
    "    ic = 0\n",
    "    for ia in range(len(ann)-1):\n",
    "        segmented_data[ann[ia]-ann[0]:ann[ia+1]-ann[0]] = ic\n",
    "        ic += 1\n",
    "        if ic == len(cycle):\n",
    "            ic = 0\n",
    "    return parsed_data, segmented_data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "segments = {0 : 'background', 1: 'qrs', 2: 'st', 3: 't', 4: 'tp', 5: 'p', 6: 'pq'}\n",
    "colors = {'background': 'black', 'qrs': 'red', 'st': 'blue', 't': 'cyan', 'tp': 'magenta', 'p': 'green', 'pq': 'yellow'}\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('Pastel1')\n",
    "cmap_float = np.linspace(0.0, 1.0, 7)\n",
    "\n",
    "colors = {'background': cmap(cmap_float[0]), 'qrs': cmap(cmap_float[1]), 'st': cmap(cmap_float[2]), 't': cmap(cmap_float[3]), \n",
    "          'tp': cmap(cmap_float[4]), 'p': cmap(cmap_float[5]), 'pq': cmap(cmap_float[6])}\n",
    "\n",
    "def plot_segmented_ecg(input_tensor, output_tensor):\n",
    "    for ecg in range(input_tensor.shape[0]):\n",
    "        f, ax = plt.subplots(8,1)\n",
    "        f.set_size_inches(16, 9)           \n",
    "        \n",
    "        for lead in range(input_tensor.shape[2]):\n",
    "            ax[lead].plot(input_tensor[ecg, :, lead, 0])\n",
    "            ax[lead].set_xlim([0, input_tensor.shape[1]])\n",
    "            segmented = np.argmax(output_tensor[ecg, :, lead, :], axis=1) \n",
    "            change_indices = np.where(segmented[:-1] != segmented[1:])[0]\n",
    "            previous_change_index = 0\n",
    "            for change_index in change_indices:\n",
    "                ax[lead].axvspan(previous_change_index, change_index, \n",
    "                                 facecolor=colors[segments[segmented[change_index]]],\n",
    "                                 alpha=1.0)\n",
    "                previous_change_index = change_index\n",
    "                previous_segment = segmented[previous_change_index]                                 \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from matplotlib import cm\n",
    "hd5_paths = glob.glob(f'{HOME_PATH}/ludb_tensors/*.hd5')\n",
    "for hd5_path in hd5_paths:\n",
    "    with h5py.File(hd5_path, 'r') as hd5:        \n",
    "        ann = np.array(hd5['ecg_rest_annotation/annotation_i'])\n",
    "        data = np.array(hd5['ecg_rest/strip_i'])\n",
    "        parsed, segmented = annotation_to_segmentation(data, ann)\n",
    "        f, ax = plt.subplots()\n",
    "        f.set_size_inches(16, 4)\n",
    "        ax.scatter(range(len(parsed)), parsed, c=cm.hot(segmented/8.0))\n",
    "        ax.set_title(hd5_path)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from ml4cvd.arguments import _get_tmap\n",
    "hd5_paths = glob.glob(f'{HOME_PATH}/ludb_tensors/*.hd5')\n",
    "tm_data = _get_tmap('ecg_rest_ludb')\n",
    "tm_segmentation = _get_tmap('ecg_rest_ludb_segmentation_weighted')\n",
    "for hd5_path in hd5_paths:\n",
    "    with h5py.File(hd5_path, 'r') as hd5:\n",
    "        data = tm_data.tensor_from_file(tm_data, hd5)\n",
    "        segmentation = tm_segmentation.tensor_from_file(tm_segmentation, hd5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sys.argv = ['train',\n",
    "#             '--mode', 'train',\n",
    "#             '--output_folder', f'{HOME_PATH}/ludb_output/',\n",
    "#             '--tensors', f'{HOME_PATH}/ludb_tensors/',\n",
    "#             '--input_tensors', 'ecg_rest_ludb',\n",
    "#             '--output_tensors', 'ecg_rest_ludb_segmentation_coarse',\n",
    "#             '--id', 'test_ludb_segmentation_unet',\n",
    "#             '--num_workers', '0',\n",
    "#             '--u_connect',\n",
    "#             '--inspect_model',\n",
    "#             '--training_steps', '14',\n",
    "#             '--validation_steps', '2',\n",
    "#             '--test_steps', '2',\n",
    "#             '--batch_size', '4',\n",
    "#             '--epochs', '100'\n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmaps_by_sample_id(tensor_folder: str, sample_id: str, tmaps: List[TensorMap], dependent_tmap):\n",
    "    path = os.path.join(tensor_folder, sample_id + '.hd5')\n",
    "    result_dict = defaultdict(lambda: None)\n",
    "    dependents = defaultdict(lambda: None)\n",
    "    if os.path.isfile(path):\n",
    "            with h5py.File(path, 'r') as hd5:\n",
    "                for tmap in tmaps:\n",
    "                    try:\n",
    "                        result_dict[tmap] = tmap.tensor_from_file(tmap, hd5, dependents)\n",
    "                        for dependent in dependents:\n",
    "                            result_dict[dependent] = np.array(dependents[dependent])\n",
    "                    except (IndexError, KeyError, ValueError, OSError, RuntimeError):\n",
    "                        continue\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def tmaps_with_properties(tensor_folder: str, tmap_properties: Dict[TensorMap, Callable[[np.ndarray], bool]], search_size=100, dependent_tmap=None):\n",
    "    all_ids = [file.strip('.hd5') for file in sorted(os.listdir(tensor_folder))[:search_size]]\n",
    "    results = map(lambda sample_id: tmaps_by_sample_id(tensor_folder, sample_id, tmap_properties.keys(), dependent_tmap), all_ids)\n",
    "    return {\n",
    "        sample_id: result\n",
    "        for sample_id, result in zip(all_ids, results)\n",
    "        if all(\n",
    "            result[tmap] is not None and tmap_properties[tmap](result[tmap])\n",
    "            for tmap in tmap_properties.keys()\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "def tmaps_with_properties_from_keys(tensor_folder: str, tmap_properties: Dict[str, Callable[[np.ndarray], bool]], search_size=100, dependent_tmap=None):\n",
    "    return tmaps_with_properties(\n",
    "        tensor_folder,\n",
    "        {_get_tmap(key): prop for key, prop in tmap_properties.items()},\n",
    "        search_size, dependent_tmap\n",
    "    )\n",
    "\n",
    "def tmap_dic_to_dic(tmap_dic):\n",
    "    sample_id = []\n",
    "    tmaps = []\n",
    "    tmap_names = []\n",
    "    tmap_subcols = []\n",
    "    out_dic = {'sample_id': []}\n",
    "        \n",
    "    for i, entry in enumerate(tmap_dic):\n",
    "        for t in tmap_dic[entry]:\n",
    "            nsubcols = np.prod(t.shape)\n",
    "            for n in range(nsubcols):\n",
    "                out_dic[t.name + '_' + str(n)] = np.zeros(len(tmap_dic))\n",
    "        break\n",
    "    \n",
    "    for i, entry in enumerate(tmap_dic):\n",
    "        out_dic['sample_id'].append(entry)\n",
    "        for t in tmap_dic[entry]:   \n",
    "            nsubcols = np.prod(t.shape)\n",
    "            for n in range(nsubcols):\n",
    "                out_dic[t.name + '_' + str(n)][i] = tmap_dic[entry][t].ravel()[n]\n",
    "    return out_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tmaps_by_sample_id('/home/pdiachil/ludb_tensors/', '1', [_get_tmap('ecg_rest_ludb')], _get_tmap('ecg_rest_ludb_segmentation_coarse'))\n",
    "\n",
    "b = tmaps_with_properties_from_keys(\n",
    "    '/home/pdiachil/ludb_tensors/', \n",
    "    {\n",
    "        'ecg_rest_ludb': lambda x: True,\n",
    "    },\n",
    "    search_size = 20,\n",
    "    dependent_tmap = _get_tmap('ecg_rest_ludb_segmentation_coarse')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = tmap_dic_to_dic(b)\n",
    "df = pd.DataFrame(dd)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [f'ecg_rest_ludb_segmentation_{i}' for i in range(0, 40000, 2)]\n",
    "# df[cols].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2900000.0 / df[cols].apply(pd.Series.value_counts).sum(axis=1)/20.390944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.argv = ['train',\n",
    "            '--mode', 'train',\n",
    "            '--output_folder', f'{HOME_PATH}/ludb_output/',\n",
    "            '--tensors', f'{HOME_PATH}/ludb_tensors/',\n",
    "            '--input_tensors', 'ecg_rest_ludb',\n",
    "            '--output_tensors', 'ecg_rest_ludb_segmentation_coarse',\n",
    "            '--id', 'test_ludb_coarse_segmentation_no3d',\n",
    "            '--num_workers', '0',\n",
    "            '--u_connect', \n",
    "            '--inspect_model',\n",
    "            '--training_steps', '15',\n",
    "            '--validation_steps', '5',\n",
    "            '--test_steps', '5',\n",
    "            '--batch_size', '8',\n",
    "            '--epochs', '400',\n",
    "            '--patience', '40'            \n",
    "           ]\n",
    "args = parse_args()\n",
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tmaps_with_properties_from_keys(\n",
    "    '/mnt/disks/ecg-rest-37k-tensors/2019-11-04/', \n",
    "    {\n",
    "        'ecg_rest_random_lead': lambda x: True,\n",
    "    },\n",
    "    search_size = 20,\n",
    "    dependent_tmap = _get_tmap('ecg_lead_detection')\n",
    ")\n",
    "dd = tmap_dic_to_dic(b)\n",
    "df = pd.DataFrame(dd)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer segmentation on rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ml4cvd.models import make_multimodal_multitask_model\n",
    "# from ml4cvd.tensor_generators import test_train_valid_tensor_generators\n",
    "# sys.argv = ['train',\n",
    "#             '--mode', 'train',\n",
    "#             '--output_folder', f'{HOME_PATH}/ukbb_output/',\n",
    "#             '--tensors', f'/home/pdiachil/ludb_tensors/',\n",
    "#             '--test_modulo', '0',\n",
    "#             '--num_workers', '0',\n",
    "#             '--valid_ratio', '0.0001',\n",
    "#             '--test_ratio', '0.0001',\n",
    "#             '--batch_size', '1',\n",
    "#             '--input_tensors', 'ecg_rest_ludb',\n",
    "#             '--output_tensors', 'ecg_rest_ludb_segmentation_coarse',\n",
    "#             '--model_file', f'{HOME_PATH}/ludb_output/test_ludb_coarse_segmentation_roll_scale_shift_bylead/test_ludb_coarse_segmentation_roll_scale_shift_bylead.hd5',\n",
    "#             '--id', 'ludb_coarse_segmentation_roll_scale_inferred_on_ecg_rest'\n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# model = make_multimodal_multitask_model(**args.__dict__)\n",
    "# generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "segments = {0 : 'background', 1: 'qrs', 2: 'st', 3: 't', 4: 'tp', 5: 'p', 6: 'pq'}\n",
    "colors = {'background': 'black', 'qrs': 'red', 'st': 'blue', 't': 'cyan', 'tp': 'magenta', 'p': 'green', 'pq': 'yellow'}\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('Pastel1')\n",
    "cmap_float = np.linspace(0.0, 1.0, 7)\n",
    "\n",
    "colors = {'background': cmap(cmap_float[0]), 'qrs': cmap(cmap_float[1]), 'st': cmap(cmap_float[2]), 't': cmap(cmap_float[3]), \n",
    "          'tp': cmap(cmap_float[4]), 'p': cmap(cmap_float[5]), 'pq': cmap(cmap_float[6])}\n",
    "\n",
    "def plot_segmented_ecg(input_tensor, output_tensor):\n",
    "    for ecg in range(input_tensor.shape[0]):\n",
    "        f, ax = plt.subplots(8,1)\n",
    "        f.set_size_inches(16, 12)           \n",
    "        \n",
    "        for lead in range(input_tensor.shape[2]):\n",
    "            ax[lead].plot(input_tensor[ecg, :, lead, 0], linewidth=3)\n",
    "            ax[lead].set_xlim([0, input_tensor.shape[1]])\n",
    "            ax[lead].tick_params(labelsize=25)\n",
    "            ax[lead].set_xticklabels([])\n",
    "            ax[lead].set_yticklabels([])\n",
    "            segmented = np.argmax(output_tensor[ecg, :, lead, :], axis=1) \n",
    "            change_indices = np.where(segmented[:-1] != segmented[1:])[0]\n",
    "            previous_change_index = 0\n",
    "            for change_index in change_indices:\n",
    "                ax[lead].axvspan(previous_change_index, change_index, \n",
    "                                 facecolor=colors[segments[segmented[change_index]]],\n",
    "                                 alpha=1.0)\n",
    "                previous_change_index = change_index\n",
    "                previous_segment = segmented[previous_change_index]    \n",
    "        f.savefig('/home/pdiachil/')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a, b = next(generate_train)\n",
    "    input_tensor = a['input_ecg_rest_ludb_ecg_rest_ludb'].reshape((1, 5000, -1, 1))\n",
    "    output_tensor = model.predict(input_tensor)\n",
    "    plot_segmented_ecg(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ml4cvd.models import make_multimodal_multitask_model\n",
    "# from ml4cvd.tensor_generators import test_train_valid_tensor_generators\n",
    "# sys.argv = ['train',\n",
    "#             '--mode', 'train',\n",
    "#             '--output_folder', f'{HOME_PATH}/ukbb_output/',\n",
    "#             '--tensors', f'/mnt/disks/ecg-rest-37k-tensors/2019-11-04/',\n",
    "#             '--test_modulo', '0',\n",
    "#             '--num_workers', '0',\n",
    "#             '--valid_ratio', '0.0001',\n",
    "#             '--test_ratio', '0.0001',\n",
    "#             '--batch_size', '1',\n",
    "#             '--input_tensors', 'ecg_rest',\n",
    "#             '--output_tensors', 'ecg_rest_ludb_segmentation_coarse',\n",
    "#             '--model_file', f'{HOME_PATH}/ludb_output/test_ludb_coarse_segmentation_roll_scale_shift_bylead/test_ludb_coarse_segmentation_roll_scale_shift_bylead.hd5',\n",
    "#             '--id', 'ludb_coarse_segmentation_roll_scale_inferred_on_ecg_rest'\n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# model = make_multimodal_multitask_model(**args.__dict__)\n",
    "# generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    a, b = next(generate_train)\n",
    "    input_tensor = a['input_strip_ecg_rest'].reshape((1, 5000, -1, 1))\n",
    "    output_tensor = model.predict(input_tensor)\n",
    "    plot_segmented_ecg(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval predictions for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv = ['train',\n",
    "#             '--mode', 'train',\n",
    "#             '--output_folder', f'{HOME_PATH}/ukbb_output/',\n",
    "#             '--tensors', f'/mnt/disks/ecg-rest-37k-tensors/2019-11-04/',\n",
    "#             '--input_tensors', 'ecg_rest',\n",
    "#             '--output_tensors', 'ventricular-rate', 'qrs-duration', 'pp-interval', 'pq-interval', 'p-duration',\n",
    "#             'qt-interval',\n",
    "#             '--id', 'ecg_lead_detection_raw',\n",
    "#             '--inspect_model',\n",
    "#             '--training_steps', '810',\n",
    "#             '--validation_steps', '115',\n",
    "#             '--conv_z', '2',\n",
    "#             '--test_steps', '230',\n",
    "#             '--batch_size', '32',\n",
    "#             '--epochs', '50',\n",
    "#             '--patience', '12'            \n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# run(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lead detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv = ['train',\n",
    "#             '--mode', 'train',\n",
    "#             '--output_folder', f'{HOME_PATH}/ukbb_output/',\n",
    "#             '--tensors', f'/mnt/disks/ecg-rest-37k-tensors/2019-11-04/',\n",
    "#             '--input_tensors', 'ecg_rest_random_lead',\n",
    "#             '--output_tensors', 'ecg_lead_detection',\n",
    "#             '--id', 'ecg_lead_detection_raw',\n",
    "#             '--inspect_model',\n",
    "#             '--training_steps', '810',\n",
    "#             '--validation_steps', '115',\n",
    "#             '--conv_z', '2',\n",
    "#             '--test_steps', '230',\n",
    "#             '--batch_size', '32',\n",
    "#             '--epochs', '50',\n",
    "#             '--patience', '12'            \n",
    "#            ]\n",
    "# args = parse_args()\n",
    "# run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
